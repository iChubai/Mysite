{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Welcome to HouJiadong's Site! \ud83c\udf89  <p>  My frineds! /  About Me /   Academic Page /  Statistics </p> <li>Website Operating Time: </li> <li>Total Visitors:  people</li> <li>Total Visits:  times</li>"},{"location":"academy/","title":"Jiadong Hou(\u4faf\u5609\u680b)","text":""},{"location":"academy/#jiadong-hou","title":"Jiadong Hou(\u4faf\u5609\u680b)","text":"<p> Work Email: 2311671 [at] mail [at] nankai [dot] edu [dot] cn</p> <p> Personal Email: 2506676943 [at] qq [dot] com</p> <p> CV: Click Here</p> <p> </p>"},{"location":"academy/#bio","title":"Bio","text":"<p>I am a second-year undergraduate student majoring in Computer Science at  Nankai University (NKU). Currently, I am an intern at Hvision, under the guidance of Prof. Qibin Hou.</p>"},{"location":"academy/#research-interest","title":"Research Interest","text":"<ul> <li>Computer Vision: I am committed to the CV field, especially in the field of visual object tracking and kownledge distillation.</li> </ul>"},{"location":"academy/#education","title":"Education","text":""},{"location":"academy/#college-of-computer-science-nankai-university","title":"College of Computer Science, Nankai University","text":"<p>Sept. 2023 -- Present</p>"},{"location":"academy/#publications-manuscripts","title":"Publications &amp; Manuscripts","text":"<p>Coming soon...</p>"},{"location":"academy/#experience","title":"Experience","text":"<p>VCIP</p> <p>Dec. 2024 - Present</p> <p>Research Intern</p>"},{"location":"academy/#projects","title":"Projects","text":"<p>Coming soon...</p>"},{"location":"academy/#media-exposures","title":"Media Exposures","text":"<p>I write articles and share my thinkings on Zhihu regularly and have 200+ followers so far!</p>"},{"location":"academy/#honors","title":"Honors","text":"<ul> <li>Scholarship of Public Interests and All-Round Capability, 2024 </li> <li>Second Prize of the National College Students Mathematical Modeling Contest (Tianjin Division)</li> <li>First prize of the 16<sup>th</sup> Chinese Mathematics Competitions and first prize of the  Tianjin Mathematics Competitions(2024)</li> </ul>"},{"location":"about/","title":"About","text":""},{"location":"about/#about","title":"About \ud83e\udd73","text":"<p> \u7ea6 70 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> \u4e2d\u6587English <p>\u6211\u662f\u5357\u5f00\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u4e0e\u6280\u672f\u4e13\u4e1a\u7684\u5927\u4e8c\u672c\u79d1\u751f\uff0c\u76ee\u524d\u611f\u5174\u8da3\u7684\u65b9\u5411\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u3002\u591a\u591a\u6307\u6559~    </p> <p>I am a sophomore in Nankai University majoring in Computer Science and Technology. My interests are in computer vision (CV). Thank you for your guidance!</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":"<p> \u7ea6 1 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"blogs/","title":"index","text":""},{"location":"blogs/#blogs","title":"Blogs \u270d","text":"<p>Abstract</p> <p>\u4e2a\u4eba\u535a\u5ba2\uff0c\u4e3b\u8981\u8bb0\u5f55</p> <ul> <li>\u5728\u8ba1\u7b97\u673a\u3001\u4eba\u5de5\u667a\u80fd\u3001\u6570\u5b66\u76f8\u5173\u65b9\u9762\u7684\u5b66\u4e60\uff0c\u4e5f\u4f1a\u63ba\u6742\u4e00\u4e9b\u5176\u5b83\u7684\u9886\u57df\uff1b</li> <li>\u8bfb\u4e66\u6458\u5f55\uff0c\u53ef\u80fd\u4f1a\u6709\u4e00\u4e9b\u7b14\u8bb0\uff1b</li> <li>\u4e00\u4e9b\u6742\u8c08\u3002</li> </ul> <p>\u4e00\u4e9b\u6bd4\u8f83\u6210\u4f53\u7cfb\u7684\u7b14\u8bb0\u4f1a\u8bb0\u5f55\u5728 Notes \u4e2d\u3002</p> <p>\u672c\u90e8\u5206\u5185\u5bb9\uff08\u9664\u7279\u522b\u58f0\u660e\u5916\uff09\u91c7\u7528 \u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u4fdd\u6301\u4e00\u81f4 4.0 \u56fd\u9645 (CC BY-NC-SA 4.0) \u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p>"},{"location":"blogs/#archives","title":"Archives","text":"<p>\u5982\u679c\u5bfb\u627e\u4e0d\u65b9\u4fbf\u7684\u8bdd\uff0c\u4e0d\u59a8\u8bd5\u8bd5\u641c\u7d22\u6216\u8005\u524d\u5f80 Tags \u9875\u9762</p> <p>{{ blog_content }}</p>"},{"location":"links/","title":"Links","text":""},{"location":"links/#links","title":"Links \ud83e\udd70","text":"<p>Abstract</p> <p>My friends!</p> Kinnariya Mama Tanha's Blogs \u5927\u4f6c(\u5d07\u62dc\u8138qwq) <p>\u5728\u4e0b\u65b9\u7559\u8a00\u7533\u8bf7\u52a0\u5165\u6211\u7684\u53cb\u94fe\uff0c\u6309\u5982\u4e0b\u683c\u5f0f\u63d0\u4f9b\u4fe1\u606f\uff1a</p> <ul><li>\u540d\u79f0\uff1aKinnari's Site</li><li>\u7b80\u4ecb\uff1aKinnariya Mama Tanha</li><li>\u94fe\u63a5\uff1ahttps://kinnariyamamatanha.github.io/</li><li>\u56fe\u7247\uff1aLink of your avatar</li></ul>"},{"location":"notes/","title":"index","text":""},{"location":"notes/#notes","title":"Notes \ud83d\udcda","text":"<p>Abstract</p> <p>\u4e00\u4e9b\u6bd4\u8f83\u6210\u4f53\u7cfb\u7684\u7b14\u8bb0\u90fd\u505a\u5728\u8fd9\u91cc\uff0c\u65b9\u4fbf\u67e5\u9605\u3002</p> <p>\u672c\u90e8\u5206\u5185\u5bb9\uff08\u9664\u7279\u522b\u58f0\u660e\u5916\uff09\u91c7\u7528 \u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u4fdd\u6301\u4e00\u81f4 4.0 \u56fd\u9645 (CC BY-NC-SA 4.0) \u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p>"},{"location":"notes/Awesome-Blogs/AI/","title":"AI","text":"<ul> <li>\u5f52\u4e00\u53161</li> </ul> <p> \u7ea6 8 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <ul> <li>PostNorm&amp;&amp;PreNorm</li> <li>PostNorm&amp;&amp;&amp;&amp;PreNorm </li> </ul>"},{"location":"notes/Awesome-Blogs/CV/","title":"CV","text":"<p> \u7ea6 0 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/Awesome-Blogs/NLP/","title":"NLP","text":""},{"location":"notes/Awesome-Blogs/NLP/#nlp","title":"\ud83e\ude84 NLP\u4f18\u8d28\u535a\u5ba2\u5e93","text":"<p> \u7ea6 14 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/Awesome-Blogs/NLP/#-deepseekmlamtpmoe","title":"- Deepseek\u76f8\u5173\u6280\u672f(MLA,MTP,MOE)","text":""},{"location":"notes/Awesome-Blogs/RL/","title":"RL","text":"<p> \u7ea6 0 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/","title":"2 Modern multicore processors","text":""},{"location":"notes/CMU15418/modernmulticoreprocessors/#lecture-2-a-modern-multi-core-processor","title":"Lecture 2: A Modern Multi-Core Processor","text":"<p> \u7ea6 274 \u4e2a\u5b57  49 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>CMU 15-418/15-618, Fall 2018 </p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#key-concepts","title":"Key Concepts","text":"<ol> <li>Parallel Execution    - Multi-core processing    - SIMD (Single Instruction, Multiple Data)    - Instruction-Level Parallelism (ILP)  </li> <li>Memory Access Challenges    - Latency vs. Bandwidth    - Caching, Prefetching, Multi-threading  </li> </ol>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#part-1-parallel-execution","title":"Part 1: Parallel Execution","text":""},{"location":"notes/CMU15418/modernmulticoreprocessors/#example-computing-sinx-using-taylor-expansion","title":"Example: Computing \\(\\sin(x)\\) Using Taylor Expansion","text":"<p>Formula: \\(\\(\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\ldots\\)\\) </p> <p>Serial Code: </p>C<pre><code>void sinx(int N, int terms, float* x, float* result) {  \n    for (int i = 0; i &lt; N; i++) {  \n        float value = x[i];  \n        float numer = x[i] * x[i] * x[i];  \n        int denom = 6;  // 3!  \n        int sign = -1;  \n        for (int j = 1; j &lt;= terms; j++) {  \n            value += sign * numer / denom;  \n            numer *= x[i] * x[i];  \n            denom *= (2*j+2) * (2*j+3);  \n            sign *= -1;  \n        }  \n        result[i] = value;  \n    }  \n}  \n</code></pre> <p>Problem: No parallelism \u2192 Slower on multi-core (0.75x speedup per core).  </p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#parallelizing-with-pthreads","title":"Parallelizing with Pthreads","text":"<p>Data-Parallel Approach: </p>C<pre><code>void sinx(int N, int terms, float* x, float* result) {  \n    forall(int i from 0 to N-1) {  // Independent iterations  \n        float value = x[i];  \n        float numer = x[i] * x[i] * x[i];  \n        int denom = 6;  \n        int sign = -1;  \n        for (int j = 1; j &lt;= terms; j++) {  \n            value += sign * numer / denom;  \n            numer *= x[i] * x[i];  \n            denom *= (2*j+2) * (2*j+3);  \n            sign *= -1;  \n        }  \n        result[i] = value;  \n    }  \n}  \n</code></pre> Compiler Hint: Use <code>forall</code> to declare independent loop iterations."},{"location":"notes/CMU15418/modernmulticoreprocessors/#multi-core-scaling","title":"Multi-Core Scaling","text":"Cores Performance 1 1x 2 1.5x 4 3x 16 12x <p>Example Architectures: - Intel Core i7 (6 cores) - NVIDIA GTX 1080 (20 SMs) - Apple A9 (2 cores)  </p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#simd-vectorization","title":"SIMD Vectorization","text":"<p>AVX Intrinsics Example: </p>C<pre><code>#include &lt;immintrin.h&gt;  \nvoid sinx(int N, int terms, float* x, float* result) {  \n    float three_fact = 6;  \n    for (int i = 0; i &lt; N; i += 8) {  \n        __m256 origx = _mm256_load_ps(&amp;x[i]);  \n        __m256 value = origx;  \n        __m256 numer = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx));  \n        __m256 denom = _mm256_broadcast_ss(&amp;three_fact);  \n        int sign = -1;  \n        for (int j = 1; j &lt;= terms; j++) {  \n            __m256 tmp = _mm256_div_ps(_mm256_mul_ps(_mm256_set1_ps(sign), numer), denom);  \n            value = _mm256_add_ps(value, tmp);  \n            numer = _mm256_mul_ps(numer, _mm256_mul_ps(origx, origx));  \n            denom = _mm256_mul_ps(denom, _mm256_broadcast_ss((2*j+2)*(2*j+3)));  \n            sign *= -1;  \n        }  \n        _mm256_store_ps(&amp;result[i], value);  \n    }  \n}  \n</code></pre> Effect: 8 elements processed per instruction \ud83d\ude80."},{"location":"notes/CMU15418/modernmulticoreprocessors/#part-2-memory-access","title":"Part 2: Memory Access","text":""},{"location":"notes/CMU15418/modernmulticoreprocessors/#latency-vs-bandwidth","title":"Latency vs. Bandwidth","text":"<ul> <li>Latency: Time to service a memory request (e.g., 100 cycles).  </li> <li>Bandwidth: Data transfer rate (e.g., 20 GB/s).  </li> </ul>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#techniques-to-mitigate-latency","title":"Techniques to Mitigate Latency","text":"<ol> <li>Caching: Reduce access time for frequently used data.  </li> <li>Prefetching: Predict and load data before it\u2019s needed.  </li> <li>Multi-threading: Hide latency by switching threads.  </li> </ol>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#multi-threading-trade-offs","title":"Multi-Threading Trade-offs","text":"Scenario Pros Cons Single Thread Simple Frequent stalls 4 Hardware Threads Better ALU utilization Increased cache pressure 16 SIMD Cores High throughput Requires massive parallelism <p>Example: NVIDIA GTX 480 (15 cores, 32 ALUs/core, 1.3 TFLOPS).  </p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#gpu-vs-cpu-memory-hierarchy","title":"GPU vs. CPU Memory Hierarchy","text":"<p> - CPU: Large caches, low latency. - GPU: High bandwidth, optimized for throughput.  </p>"},{"location":"notes/CMU15418/modernmulticoreprocessors/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Parallel Execution Forms:    - Multi-core (thread-level)    - SIMD (data-level)    - Superscalar (ILP)  </li> <li>Memory Challenges:    - Bandwidth-bound programs need high arithmetic intensity.    - Optimize for data reuse and locality.  </li> <li>Hardware Trends:    - Simpler cores + more parallelism &gt; complex cores.    - GPUs push throughput to extremes.  </li> </ol> <p>\ud83d\udd0d Pro Tip: Use <code>forall</code> and vectorization to exploit parallelism!  </p>"},{"location":"notes/CMU15418/progbasics/","title":"3 progbasics","text":""},{"location":"notes/CMU15418/progbasics/#lecture-4-parallel-programming-basics","title":"Lecture 4: Parallel Programming Basics \ud83d\udcda","text":"<p> \u7ea6 298 \u4e2a\u5b57  25 \u884c\u4ee3\u7801  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/CMU15418/progbasics/#parallel-programming-models","title":"Parallel Programming Models \ud83d\udda5\ufe0f","text":""},{"location":"notes/CMU15418/progbasics/#1-shared-address-space","title":"1. Shared Address Space","text":"<ul> <li>Communication: Implicit via loads/stores (unstructured).</li> <li>Pros: Natural programming model.</li> <li>Cons: Risk of poor performance due to unstructured communication.</li> <li>Example: C<pre><code>// Threads access shared variables directly\nfloat* A = allocate_shared(N);\nA[i] = A[j] + 1; // No explicit communication\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#2-message-passing","title":"2. Message Passing","text":"<ul> <li>Communication: Explicit via send/receive.</li> <li>Pros: Structured communication aids scalability.</li> <li>Cons: Harder to implement initially.</li> <li>Example: C<pre><code>send(buffer, dest); // Explicit message\nrecv(buffer, src);  // Explicit receive\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#3-data-parallel","title":"3. Data Parallel","text":"<ul> <li>Structure: Map operations over collections (e.g., arrays).</li> <li>Limitation: Restricted inter-iteration communication.</li> <li>Modern Use: CUDA/OpenCL allow limited shared-memory sync.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#hybrid-models","title":"Hybrid Models \ud83c\udf10","text":"<ul> <li>Shared memory within a node + message passing between nodes.</li> <li>Example: MPI + OpenMP.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#example-applications","title":"Example Applications \ud83c\udf0a","text":""},{"location":"notes/CMU15418/progbasics/#ocean-current-simulation","title":"Ocean Current Simulation","text":"<ul> <li>Grid-based 3D discretization:</li> <li>Dependencies within a single time step: </li> <li>Exploit data parallelism within grids.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#galaxy-evolution-barnes-hut-algorithm","title":"Galaxy Evolution (Barnes-Hut Algorithm) \ud83c\udf0c","text":"<ul> <li>N-body problem with \\(O(N \\log N)\\) complexity.</li> <li>Quad-tree spatial decomposition: </li> <li>Approximate far-field forces using aggregate mass in tree nodes.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#creating-a-parallel-program","title":"Creating a Parallel Program \ud83d\udee0\ufe0f","text":""},{"location":"notes/CMU15418/progbasics/#key-steps","title":"Key Steps:","text":"<ol> <li>Decomposition: Break into parallel tasks.</li> <li>Assignment: Map tasks to workers (threads/cores).</li> <li>Orchestration: Manage sync, communication, and data locality.</li> </ol>"},{"location":"notes/CMU15418/progbasics/#amdahls-law","title":"Amdahl's Law \u2696\ufe0f","text":"<ul> <li>Formula:  \\(\\(\\text{Speedup} \\leq \\frac{1}{S + \\frac{(1-S)}{P}}\\)\\)</li> <li>\\(S\\): Fraction of serial work.</li> <li>Example: </li> <li>Step 1 (parallel): \\(N^2/P\\) time.</li> <li>Step 2 (serial): \\(N^2\\) time.</li> <li>Speedup \\(\\leq 2\\) for \\(P\\) processors if Step 2 remains serial.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#case-study-2d-grid-solver","title":"Case Study: 2D Grid Solver \ud83d\udd22","text":""},{"location":"notes/CMU15418/progbasics/#gauss-seidel-iteration","title":"Gauss-Seidel Iteration","text":"<ul> <li>Sequential Code: C<pre><code>while (!done) {\n  diff = 0;\n  for (i, j) in grid {\n    prev = A[i][j];\n    A[i][j] = 0.2*(A[i-1][j] + A[i][j-1] + ...);\n    diff += abs(A[i][j] - prev);\n  }\n  if (diff/N\u00b2 &lt; TOL) done = true;\n}\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#parallelization-challenges","title":"Parallelization Challenges \u26a0\ufe0f","text":"<ul> <li>Dependencies:  </li> <li>Solution: Red-Black Coloring \ud83c\udfa8</li> <li>Update all red cells \u2192 sync \u2192 update all black cells. </li> </ul>"},{"location":"notes/CMU15418/progbasics/#synchronization-primitives","title":"Synchronization Primitives \ud83d\udd12","text":""},{"location":"notes/CMU15418/progbasics/#1-locks","title":"1. Locks","text":"<ul> <li>Usage: C<pre><code>lock(myLock);\ncritical_section();\nunlock(myLock);\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#2-barriers","title":"2. Barriers","text":"<ul> <li>Usage: C<pre><code>compute_phase1();\nbarrier(all_threads);\ncompute_phase2();\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#3-message-passing","title":"3. Message Passing","text":"<ul> <li>Deadlock Avoidance: C<pre><code>if (tid % 2 == 0) {\n  sendUp(); recvUp(); // Even threads send first\n} else {\n  recvUp(); sendUp(); // Odd threads receive first\n}\n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progbasics/#assignment-strategies","title":"Assignment Strategies \ud83d\udccb","text":""},{"location":"notes/CMU15418/progbasics/#static-vs-dynamic","title":"Static vs. Dynamic","text":"<ul> <li>Blocked Assignment:</li> <li>Thread 1: Rows 1\u2013100; Thread 2: Rows 101\u2013200.</li> <li>Interleaved Assignment:</li> <li>Thread 1: Rows 1, 3, 5...; Thread 2: Rows 2, 4, 6...</li> </ul>"},{"location":"notes/CMU15418/progbasics/#performance-trade-offs","title":"Performance Trade-offs","text":"<ul> <li>Blocked: Better locality, less communication.</li> <li>Interleaved: Better load balance for irregular workloads.</li> </ul>"},{"location":"notes/CMU15418/progbasics/#summary","title":"Summary \ud83d\udccc","text":"<ul> <li>Amdahl's Law limits speedup based on serial fractions.</li> <li>Decomposition is key to exposing parallelism.</li> <li>Hybrid Models (shared memory + message passing) dominate practice.</li> <li>Synchronization must balance correctness and overhead.</li> </ul> <p>\ud83d\ude80 Next Lecture: CUDA/OpenCL for GPU parallelism!</p>"},{"location":"notes/CMU15418/progmodels/","title":"4 progmodels","text":""},{"location":"notes/CMU15418/progmodels/#lecture-3-parallel-programming-abstractions-implementations","title":"Lecture 3: Parallel Programming Abstractions &amp; Implementations","text":"<p> \u7ea6 440 \u4e2a\u5b57  45 \u884c\u4ee3\u7801  11 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>CMU 15-418/15-618, Fall 2018 </p>"},{"location":"notes/CMU15418/progmodels/#theme-abstraction-vs-implementation","title":"\ud83d\udccc Theme: Abstraction vs. Implementation","text":"<p>Key Idea: Conflating abstraction with implementation causes confusion.  </p>"},{"location":"notes/CMU15418/progmodels/#example-programming-with-ispc","title":"\ud83d\udda5\ufe0f Example: Programming with ISPC","text":""},{"location":"notes/CMU15418/progmodels/#intel-spmd-program-compiler-ispc","title":"Intel SPMD Program Compiler (ISPC)","text":"<ul> <li>SPMD: Single Program Multiple Data.  </li> <li>Goal: Compute \\(\\sin(x)\\) using Taylor expansion: \\(\\(\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\dots\\)\\) </li> </ul>"},{"location":"notes/CMU15418/progmodels/#c-code-main-program","title":"C++ Code (Main Program)","text":"C++<pre><code>#include \"sinx_ispc.h\"  \nint N = 1024;  \nint terms = 5;  \nfloat* x = new float[N];  \nfloat* result = new float[N];  \n// Initialize x  \nsinx(N, terms, x, result);  \n</code></pre>"},{"location":"notes/CMU15418/progmodels/#ispc-code-sinxispc","title":"ISPC Code (<code>sinx.ispc</code>)","text":"<p> Key Concepts: - <code>programCount</code>: Number of program instances (uniform value). - <code>programIndex</code>: ID of the current instance (non-uniform, \"varying\"). - <code>uniform</code>: Type modifier for variables shared across instances.  </p>"},{"location":"notes/CMU15418/progmodels/#assignment-strategies","title":"Assignment Strategies","text":"<ol> <li> <p>Interleaved Assignment:    - Elements assigned to instances in a round-robin fashion.    - Efficient for contiguous memory access (uses SIMD packed loads). </p> </li> <li> <p>Blocked Assignment:    - Each instance processes a contiguous block of elements.    - Requires \"gather\" instructions (costlier on non-contiguous data). </p> </li> </ol>"},{"location":"notes/CMU15418/progmodels/#ispc-foreach-construct","title":"ISPC <code>foreach</code> Construct","text":"Text Only<pre><code>export void absolute_value(uniform int N, uniform float* x, uniform float* y) {  \n    foreach (i = 0 ... N) {  \n        if (x[i] &lt; 0) y[i] = -x[i];  \n        else y[i] = x[i];  \n    }  \n}  \n</code></pre> Behavior: - Parallel loop iterations split across program instances. - Static interleaved assignment by default."},{"location":"notes/CMU15418/progmodels/#three-parallel-programming-models","title":"\ud83d\udcca Three Parallel Programming Models","text":""},{"location":"notes/CMU15418/progmodels/#1-shared-address-space","title":"1. Shared Address Space","text":"<p>Abstraction: - Threads communicate via shared variables (implicit) and synchronization primitives (e.g., locks). Example: </p>C++<pre><code>void foo(int* x, lock* my_lock) {  \n    my_lock-&gt;lock();  \n    x++;  \n    my_lock-&gt;unlock();  \n    print(x);  \n}  \n</code></pre> HW Implementations: - SMP (Symmetric Multi-Processor): Uniform memory access (UMA).  - NUMA (Non-Uniform Memory Access): Scalable but requires locality awareness."},{"location":"notes/CMU15418/progmodels/#2-message-passing","title":"2. Message Passing","text":"<p>Abstraction: - Threads communicate via explicit <code>send</code>/<code>receive</code> operations. Implementation: - MPI (Message Passing Interface) on clusters. Example: </p>Python<pre><code># Node 1  \nsend(data, destination=2)  \n\n# Node 2  \nreceive(data, source=1)  \n</code></pre>"},{"location":"notes/CMU15418/progmodels/#3-data-parallel","title":"3. Data Parallel","text":"<p>Abstraction: - Apply the same operation to all elements of a collection (e.g., <code>map</code> function). ISPC Example: </p>Text Only<pre><code>export void shift_negative(uniform int N, uniform float* x, uniform float* y) {  \n    foreach (i = 0 ... N) {  \n        if (i &gt;= 1 &amp;&amp; x[i] &lt; 0) y[i-1] = x[i];  \n        else y[i] = x[i];  \n    }  \n}  \n</code></pre> Hardware Support: - SIMD instructions (AVX2/AVX512) for vectorization. - Gather/Scatter operations for non-contiguous data."},{"location":"notes/CMU15418/progmodels/#modern-hybrid-models","title":"\ud83d\udee0\ufe0f Modern Hybrid Models","text":"<ul> <li>Shared Address Space within a multi-core node.  </li> <li>Message Passing between nodes in a cluster. Example: LANL Roadrunner (2008 World's Fastest Supercomputer). </li> </ul>"},{"location":"notes/CMU15418/progmodels/#summary","title":"\ud83d\udcdd Summary","text":"Model Communication Pros Cons Shared Address Space Implicit (loads/stores) Natural extension of sequential Scalability challenges (NUMA) Message Passing Explicit (<code>send</code>/<code>receive</code>) Structured, scalable Verbose, harder to debug Data Parallel Implicit (element-wise) Predictable performance Rigid structure <p>Key Takeaway: Choose abstractions that align with hardware capabilities and program requirements.  </p> <p>\ud83d\udca1 Self-Test: If you understand why <code>reduce_add()</code> in ISPC maps to AVX intrinsics, you've mastered the gang abstraction! </p>C++<pre><code>// AVX equivalent of ISPC reduction  \nfloat sumall2(int N, float* x) {  \n    __m256 partial = _mm256_broadcast_ss(0.0f);  \n    for (int i=0; i&lt;N; i+=8)  \n        partial = _mm256_add_ps(partial, _mm256_load_ps(&amp;x[i]));  \n    float tmp;  \n    _mm256_store_ps(tmp, partial);  \n    float sum = 0.f;  \n    for (int i=0; i&lt;8; i++) sum += tmp[i];  \n    return sum;  \n}  \n</code></pre>"},{"location":"notes/CMU15418/progmodels/#advanced-topics","title":"\ud83e\udde9 Advanced Topics","text":""},{"location":"notes/CMU15418/progmodels/#ispc-tasks","title":"ISPC Tasks","text":"<ul> <li>Gang Abstraction: Implemented via SIMD instructions on a single core.  </li> <li>Multi-Core Execution: Requires the <code>task</code> abstraction (not covered here).  </li> </ul>"},{"location":"notes/CMU15418/progmodels/#stream-programming","title":"Stream Programming","text":"<ul> <li>Kernels: Side-effect-free functions applied to collections (streams).  </li> <li>Optimizations: Prefetching and locality exploitation via compiler analysis. C++<pre><code>// Stream programming example  \nstream&lt;float&gt; input(N);  \nstream&lt;float&gt; output(N);  \nabsolute_value(input, output);  // Kernel applied element-wise  \n</code></pre></li> </ul>"},{"location":"notes/CMU15418/progmodels/#gatherscatter-operations","title":"Gather/Scatter Operations","text":"<ul> <li>Gather: Load non-contiguous data into a SIMD register.  </li> <li>Scatter: Store SIMD register to non-contiguous memory locations. </li> </ul>"},{"location":"notes/CMU15418/progmodels/#implementation-details","title":"\ud83d\udd0d Implementation Details","text":""},{"location":"notes/CMU15418/progmodels/#sgi-altix-uv-1000","title":"SGI Altix UV 1000","text":"<ul> <li>4096 cores with a fat-tree interconnect.  </li> <li>Shared address space across 256 blades. </li> </ul>"},{"location":"notes/CMU15418/progmodels/#15-418618-latedays-cluster","title":"15-418/618 \"Latedays\" Cluster","text":"<ul> <li>Hybrid architecture with CPUs, GPUs, and Xeon Phi coprocessors.  </li> <li>Peak performance: 105 TFLOPS.  </li> </ul>"},{"location":"notes/CMU15418/progmodels/#final-notes","title":"\ud83c\udfaf Final Notes","text":"<ul> <li>Abstraction Distance: Balance between flexibility and predictable performance.  </li> <li>Mixed Models: Use shared memory within nodes + message passing between nodes.  </li> <li>Functional vs. Imperative: Data-parallel systems trade safety for familiarity.  </li> </ul>"},{"location":"notes/CMU15418/progperf1/","title":"5 progperf1","text":""},{"location":"notes/CMU15418/progperf1/#lecture-5-performance-optimization-part-1-work-distribution-and-scheduling","title":"Lecture 5: Performance Optimization Part 1 - Work Distribution and Scheduling","text":"<p> \u7ea6 361 \u4e2a\u5b57  32 \u884c\u4ee3\u7801  10 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>CMU 15-418/618, Fall 2018 </p>"},{"location":"notes/CMU15418/progperf1/#key-goals-of-parallel-program-optimization","title":"Key Goals of Parallel Program Optimization \ud83c\udfaf","text":"<ol> <li>Balance workload across execution resources.  </li> <li>Reduce communication to avoid stalls.  </li> <li>Minimize overhead from parallelism management.  </li> </ol> <p>TIP #1: Always start with the simplest solution, then measure performance.  </p> <p>\"My solution scales\" = Your code scales as needed for your target hardware. </p>"},{"location":"notes/CMU15418/progperf1/#balancing-the-workload","title":"Balancing the Workload \u2696\ufe0f","text":"<p>Ideal Scenario: All processors compute simultaneously and finish at the same time.  </p>"},{"location":"notes/CMU15418/progperf1/#amdahls-law-impact","title":"Amdahl\u2019s Law Impact","text":"<ul> <li>Example: If P4 does 20% more work \u2192 P4 takes 20% longer \u2192 20% of runtime becomes serial execution.  </li> <li>Serialized section (S) = 5% of total work \u2192 Limits maximum speedup.  </li> </ul>"},{"location":"notes/CMU15418/progperf1/#static-assignment","title":"Static Assignment \ud83d\udd27","text":"<p>Definition: Pre-determine work-to-thread mapping (may depend on runtime parameters).  </p>"},{"location":"notes/CMU15418/progperf1/#example-grid-solver","title":"Example: Grid Solver","text":"<ul> <li>Assign equal grid cells to each thread.  </li> <li>Strategies:  </li> <li>Blocked: Contiguous chunks.  </li> <li>Interleaved: Cyclic distribution.  </li> </ul>"},{"location":"notes/CMU15418/progperf1/#when-to-use-static-assignment","title":"When to Use Static Assignment?","text":"<ol> <li>Predictable work cost (e.g., uniform task durations).  </li> <li>Known statistics (e.g., average execution time).  </li> </ol> <p>Example: 12 tasks with equal cost \u2192 Assign 3 tasks to each of 4 processors.  </p> <p> </p>"},{"location":"notes/CMU15418/progperf1/#semi-static-assignment","title":"Semi-Static Assignment \ud83d\udd04","text":"<ul> <li>Periodic profiling to adjust assignments.  </li> <li>Example: Particle simulation redistributes particles as they move slowly.  </li> </ul>"},{"location":"notes/CMU15418/progperf1/#dynamic-assignment","title":"Dynamic Assignment \ud83d\ude80","text":"<p>Use Case: Unpredictable task execution time/number.  </p>"},{"location":"notes/CMU15418/progperf1/#shared-counter-example-prime-testing","title":"Shared Counter Example (Prime Testing)","text":"C++<pre><code>int N = 1024;\nint* x = new int[N];\nbool* is_prime = new bool[N];\nLOCK counter_lock;\nint counter = 0;\n\nwhile (1) {\n    int i;\n    lock(counter_lock);\n    i = counter++;\n    unlock(counter_lock);\n    if (i &gt;= N) break;\n    is_prime[i] = test_primality(x[i]);\n}\n</code></pre> Problem: High synchronization overhead due to frequent lock contention."},{"location":"notes/CMU15418/progperf1/#task-granularity-adjustment","title":"Task Granularity Adjustment \ud83e\udde9","text":"<p>Coarse Granularity: Reduce synchronization by grouping tasks. </p>C++<pre><code>const int GRANULARITY = 10;\n...\ncounter += GRANULARITY;\nfor (int j = i; j &lt; end; j++) {\n    is_prime[j] = test_primality(x[j]);\n}\n</code></pre> <p>Trade-off: - Small tasks \u2192 Better load balance. - Large tasks \u2192 Lower overhead.  </p>"},{"location":"notes/CMU15418/progperf1/#smarter-task-scheduling","title":"Smarter Task Scheduling \ud83e\udde0","text":""},{"location":"notes/CMU15418/progperf1/#problem-load-imbalance","title":"Problem: Load Imbalance","text":"<p>Solutions: 1. Split long tasks into smaller subtasks. 2. Schedule long tasks first to minimize \"slop\".  </p> <p> </p>"},{"location":"notes/CMU15418/progperf1/#distributed-work-queues","title":"Distributed Work Queues \ud83d\uddc3\ufe0f","text":"<p>Design: - Each thread has its own work queue. - Work stealing when local queue is empty.  </p> <p> </p> <p>Advantages: - Reduced synchronization. - Improved locality (producer-consumer pattern).  </p>"},{"location":"notes/CMU15418/progperf1/#fork-join-parallelism-with-cilk-plus","title":"Fork-Join Parallelism with Cilk Plus \ud83d\udee0\ufe0f","text":""},{"location":"notes/CMU15418/progperf1/#key-constructs","title":"Key Constructs:","text":"<ul> <li><code>cilk_spawn</code>: Fork a task.  </li> <li><code>cilk_sync</code>: Join all spawned tasks.  </li> </ul> <p>Example: Parallel QuickSort </p>C++<pre><code>void quick_sort(int* begin, int* end) {\n    if (begin &gt;= end - PARALLEL_CUTOFF) std::sort(begin, end);\n    else {\n        int* middle = partition(begin, end);\n        cilk_spawn quick_sort(begin, middle);\n        quick_sort(middle + 1, end);\n    }\n}\n</code></pre>"},{"location":"notes/CMU15418/progperf1/#work-stealing-scheduler","title":"Work Stealing Scheduler \ud83d\udd75\ufe0f","text":"<ul> <li>Continuation Stealing: Run child task first, leave continuation for stealing.  </li> <li>Greedy Policy: Idle threads steal work immediately.  </li> </ul> <p>Example: Loop with <code>cilk_spawn</code> </p>C++<pre><code>for (int i = 0; i &lt; N; i++) {\n    cilk_spawn foo(i);\n}\ncilk_sync;\n</code></pre>"},{"location":"notes/CMU15418/progperf1/#summary","title":"Summary \ud83d\udcdd","text":"<ol> <li>Load Balance: Critical for maximizing resource utilization.  </li> <li>Assignment Strategies:    - Static: Predictable workloads.    - Dynamic: Unpredictable workloads (use work queues).  </li> <li>Fork-Join: Natural for divide-and-conquer (Cilk Plus uses work stealing).  </li> <li>Granularity: Balance task size to minimize overhead and ensure parallelism.  </li> </ol> <p>Key Insight: Use workload knowledge to choose the right strategy! \ud83d\ude80  </p>"},{"location":"notes/CMU15418/whyparallelism/","title":"1 why parallelism","text":""},{"location":"notes/CMU15418/whyparallelism/#historical-context-of-parallel-computing","title":"\ud83d\udd70\ufe0f Historical Context of Parallel Computing","text":"<p> \u7ea6 165 \u4e2a\u5b57  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/CMU15418/whyparallelism/#1970s2000s-supercomputers-databases","title":"\u25a0 1970s\u20132000s: Supercomputers &amp; Databases","text":"<ul> <li>C.mmp at CMU (1971): 16 PDP-11 processors. </li> <li>Cray XMP (1984): 4 vector processors. </li> <li>Sun Enterprise 10000 (1997): 16 UltraSPARC-II processors. </li> </ul>"},{"location":"notes/CMU15418/whyparallelism/#inflection-point-2004","title":"\u25a0 Inflection Point (2004)","text":"<ul> <li>Power Density Wall: Intel abandons frequency scaling, shifts to multi-core CPUs. </li> </ul>"},{"location":"notes/CMU15418/whyparallelism/#key-concepts","title":"\ud83d\udca1 Key Concepts","text":""},{"location":"notes/CMU15418/whyparallelism/#speedup-formula","title":"\u25a0 Speedup Formula","text":"\\[\\text{Speedup}(P) = \\frac{\\text{Execution Time (1 processor)}}{\\text{Execution Time (P processors)}}\\] <p>Demo Observations: 1. Demo 1: Communication limits speedup. 2. Demo 2: Work imbalance reduces efficiency. 3. Demo 3: Communication dominates computation.  </p>"},{"location":"notes/CMU15418/whyparallelism/#modern-parallel-hardware","title":"\ud83d\udda5\ufe0f Modern Parallel Hardware","text":""},{"location":"notes/CMU15418/whyparallelism/#apple-products","title":"\u25a0 Apple Products","text":"<ul> <li>Mac Pro: 12-core Intel Xeon E5.  </li> <li>iPad Retina: 2 Swift cores. </li> </ul>"},{"location":"notes/CMU15418/whyparallelism/#supercomputers","title":"\u25a0 Supercomputers","text":"<ul> <li>Titan (#2 Supercomputer): 18,688 AMD CPUs + 18,688 NVIDIA GPUs. </li> </ul>"},{"location":"notes/CMU15418/whyparallelism/#course-themes","title":"\ud83e\udde9 Course Themes","text":"<ol> <li>Scaling Parallel Programs:    - Decomposition, work assignment, communication.  </li> <li>Hardware Efficiency:    - Performance vs. cost vs. power.  </li> <li>Post-2004 Shift:    - Maximize performance per Watt instead of raw speed.  </li> </ol>"},{"location":"notes/CMU15418/whyparallelism/#key-takeaways","title":"\ud83d\udea8 Key Takeaways","text":"<ul> <li>Single-thread performance growth is stagnant \u2192 Parallelism is essential.  </li> <li>Writing parallel code is challenging but unlocks immense computational power.  </li> <li>Efficiency matters: 2x speedup on 1010 processors is not impressive.  </li> </ul> <p>\ud83d\udce2 Welcome to 15-418! </p>"},{"location":"notes/CMU15445/memory/","title":"4 memory","text":""},{"location":"notes/CMU15445/memory/#lecture-04-memory-disk-management","title":"Lecture 04: Memory &amp; Disk Management","text":"<p> \u7ea6 558 \u4e2a\u5b57  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-445/645 Database Systems (Spring 2025) Carnegie Mellon University Prof. Jignesh Patel </p>"},{"location":"notes/CMU15445/memory/#key-concepts","title":"\ud83d\udccc Key Concepts","text":""},{"location":"notes/CMU15445/memory/#1-disk-oriented-dbms","title":"1. Disk-Oriented DBMS","text":"<ul> <li>Primary Storage: Persistent storage (HDD/SSD).  </li> <li>Buffer Pool Manager: Moves data between disk and memory.  </li> <li>Illusion: Database appears fully in memory, even if larger than available RAM.  </li> </ul> <p>Optimization Goals: 1. Spatial Control: Keep related pages physically close on disk (improves prefetching). 2. Temporal Control: Minimize disk I/O stalls by managing when pages are loaded/evicted.  </p> <p> </p>"},{"location":"notes/CMU15445/memory/#2-buffer-pool-organization","title":"2. Buffer Pool Organization","text":"<ul> <li>Structure: Array of fixed-size frames (each holds a page copy).  </li> <li>Write-Back Cache: Dirty pages are buffered, not immediately written to disk.  </li> <li>Page Table: In-memory hash table mapping page IDs \u2192 buffer pool frames.  </li> </ul> <p>Meta-Data per Page: - Dirty Flag: Indicates if modified (needs write-back). - Pin/Reference Counter: Tracks active accesses (pinned pages cannot be evicted). - Access Tracking: Used for replacement policies (e.g., LRU timestamps).  </p> <p> </p>"},{"location":"notes/CMU15445/memory/#3-locks-vs-latches","title":"3. Locks vs. Latches","text":"Locks \ud83d\udd12 Latches \ud83d\udd29 Protect logical DB content (e.g., tuples). Protect internal data structures (e.g., hash tables). Held for transaction duration. Held for operation duration. Support rollbacks. No rollback needed. Example: Row-level locks. Example: Mutexes for page table access."},{"location":"notes/CMU15445/memory/#4-page-table-vs-page-directory","title":"4. Page Table vs. Page Directory","text":"<ul> <li>Page Directory: On-disk mapping of page IDs \u2192 physical locations.  </li> <li>Page Table: In-memory mapping of page IDs \u2192 buffer pool frames.  </li> </ul> <p>Example: - Page Directory entry: <code>Page#5 \u2192 Disk Block 1023</code>. - Page Table entry: <code>Page#5 \u2192 Frame#7 (Dirty: True, Pin Count: 2)</code>.  </p>"},{"location":"notes/CMU15445/memory/#5-why-not-use-os-mmap","title":"5. Why Not Use OS mmap? \ud83d\udea8","text":"<p>Problems: 1. Transaction Safety: OS may flush dirty pages prematurely. 2. I/O Stalls: Threads stall on page faults (DBMS can\u2019t predict which pages are in memory). 3. Error Handling: SIGBUS errors on invalid page access. 4. Performance: TLB shootdowns and OS contention.  </p> <p>DBMS Advantages: - Control over flushing order, prefetching, replacement policies, and thread scheduling.  </p> <p>OS Workarounds (e.g., <code>madvise</code>, <code>mlock</code>, <code>msync</code>) are as complex as manual management.  </p>"},{"location":"notes/CMU15445/memory/#buffer-replacement-policies","title":"\ud83d\udd04 Buffer Replacement Policies","text":""},{"location":"notes/CMU15445/memory/#goals","title":"Goals:","text":"<ul> <li>Correctness: Avoid evicting pinned/dirty pages.  </li> <li>Accuracy: Predict future access patterns.  </li> <li>Speed: Low overhead.  </li> <li>Low Meta-Data: Minimal per-page storage.  </li> </ul>"},{"location":"notes/CMU15445/memory/#1-least-recently-used-lru","title":"1. Least Recently Used (LRU)","text":"<ul> <li>Mechanism: Track last access timestamp; evict oldest page.  </li> <li>Implementation: Sorted list or priority queue.  </li> <li>Example:  </li> <li>Pages: <code>[A (ts=10), B (ts=5), C (ts=15)]</code> \u2192 Evict B.  </li> </ul> <p>Weakness: - Sequential Flooding: Scans pollute the buffer pool (e.g., <code>SELECT * FROM table</code> evicts useful pages).  </p> <p> </p>"},{"location":"notes/CMU15445/memory/#2-clock-approximate-lru","title":"2. CLOCK (Approximate LRU)","text":"<ul> <li>Mechanism:  </li> <li>Each page has a reference bit (1 if accessed recently).  </li> <li>Clock hand sweeps frames; evicts pages with reference bit = 0.  </li> <li>Example:  </li> <li>Pages: <code>[A (ref=1), B (ref=0), C (ref=1)]</code> \u2192 Evict B.  </li> </ul>"},{"location":"notes/CMU15445/memory/#3-lru-k","title":"3. LRU-K","text":"<ul> <li>Mechanism: Track last K accesses to predict future use.  </li> <li>Example:  </li> <li><code>K=2</code>: Page A accessed at times <code>[t=5, t=10]</code> \u2192 Interval = 5.  </li> <li>Prefer evicting pages with longer intervals (less frequently accessed).  </li> </ul> <p>Tradeoff: Higher meta-data overhead.  </p>"},{"location":"notes/CMU15445/memory/#handling-dirty-pages","title":"\ud83e\udde9 Handling Dirty Pages","text":"<ul> <li>Fast Path: Non-dirty pages are simply dropped.  </li> <li>Slow Path: Dirty pages must be written to disk before eviction.  </li> </ul> <p>Optimization: - Background Writing: Periodically flush dirty pages to reduce eviction latency.  </p>"},{"location":"notes/CMU15445/memory/#buffer-pool-optimizations","title":"\ud83d\ude80 Buffer Pool Optimizations","text":""},{"location":"notes/CMU15445/memory/#1-multiple-buffer-pools","title":"1. Multiple Buffer Pools","text":"<ul> <li>Purpose: Reduce contention (e.g., separate pools for indexes and tables).  </li> <li>Mapping: Use hashing or object IDs to assign pages to pools.  </li> </ul>"},{"location":"notes/CMU15445/memory/#2-pre-fetching","title":"2. Pre-Fetching","text":"<ul> <li>Mechanism: Load pages needed for future operations (e.g., sequential scans).  </li> <li>Example:  </li> <li>During a <code>B+Tree</code> index scan, prefetch sibling leaf pages.  </li> </ul>"},{"location":"notes/CMU15445/memory/#3-scan-sharing","title":"3. Scan Sharing","text":"<ul> <li>Mechanism: Multiple queries reuse a single scan cursor.  </li> <li>Example:  </li> <li>Query 1 scans <code>Table X</code>; Query 2 attaches to the same scan.  </li> </ul>"},{"location":"notes/CMU15445/memory/#key-takeaways","title":"\u26a0\ufe0f Key Takeaways","text":"<ul> <li>Avoid OS mmap: DBMS needs full control over memory management.  </li> <li>Replacement Policies: Balance accuracy and overhead (CLOCK &gt; LRU for large pools).  </li> <li>Optimize I/O: Use Direct I/O, prefetching, and multiple pools.  </li> </ul> <p>\ud83d\udcca Final Thought: The OS is not your friend! \ud83d\uded1  </p>"},{"location":"notes/CMU15445/modern_sql/","title":"2 Modern SQL","text":""},{"location":"notes/CMU15445/modern_sql/#lecture-02-modern-sql","title":"Lecture 02: Modern SQL \ud83d\udcda","text":"<p> \u7ea6 341 \u4e2a\u5b57  41 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-445/645 Database Systems (Spring 2025) Carnegie Mellon University | Prof. Jignesh Patel </p>"},{"location":"notes/CMU15445/modern_sql/#1-sql-history","title":"1. SQL History \ud83d\udcdc","text":"<ul> <li>Origins:  </li> <li>Developed in the 1970s as part of IBM\u2019s System R project.  </li> <li>Originally called SEQUEL (Structured English Query Language).  </li> <li> <p>Renamed SQL (Structured Query Language) in the 1980s.  </p> </li> <li> <p>Standards:  </p> </li> <li>SQL-92: Minimum standard for claiming SQL support.  </li> <li>Major updates:     | Version | Key Features |     |---------|--------------|     | SQL:1999 | Regular Expressions, Triggers |     | SQL:2003 | XML, Windows, Sequences |     | SQL:2008 | Truncation, Fancy Sorting |     | SQL:2011 | Temporal DBs, Pipelined DML |     | SQL:2016 | JSON, Polymorphic Tables |     | SQL:2023 | Property Graph Queries, Multi-Dim. Arrays |  </li> </ul>"},{"location":"notes/CMU15445/modern_sql/#2-relational-languages","title":"2. Relational Languages \ud83d\udee0\ufe0f","text":"<ul> <li>Categories:  </li> <li>DML (Data Manipulation): <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>.  </li> <li>DDL (Data Definition): Schema definitions (tables, indexes).  </li> <li>DCL (Data Control): Security, access controls.  </li> <li> <p>Others: Views, constraints, transactions.  </p> </li> <li> <p>Key Difference:  </p> </li> <li>Relational Algebra uses sets (no duplicates).  </li> <li>SQL uses bags (allows duplicates).  </li> </ul>"},{"location":"notes/CMU15445/modern_sql/#3-example-database","title":"3. Example Database \ud83d\uddc3\ufe0f","text":"<p>Tables:  </p>"},{"location":"notes/CMU15445/modern_sql/#student","title":"<code>student</code>","text":"sid name login age gpa 53666 RZA rza@cs 55 4.0 53688 Taylor swift@cs 27 3.9 53655 Tupac shakur@cs 25 3.5"},{"location":"notes/CMU15445/modern_sql/#course","title":"<code>course</code>","text":"cid name 15-445 Database Systems 15-721 Advanced Database Systems 15-826 Data Mining 15-799 Special Topics in Databases"},{"location":"notes/CMU15445/modern_sql/#enrolled","title":"<code>enrolled</code>","text":"sid cid grade 53666 15-445 C 53688 15-721 A 53688 15-826 B 53655 15-445 B 53666 15-721 C"},{"location":"notes/CMU15445/modern_sql/#4-aggregates","title":"4. Aggregates \ud83e\uddee","text":"<p>Functions: <code>AVG</code>, <code>MIN</code>, <code>MAX</code>, <code>SUM</code>, <code>COUNT</code>.  </p>"},{"location":"notes/CMU15445/modern_sql/#example-1-count-students-with-cs-login","title":"Example 1: Count Students with \"@cs\" Login","text":"SQL<pre><code>SELECT COUNT(login) AS cnt  \nFROM student  \nWHERE login LIKE '%@cs';  \n</code></pre> Output: <code>cnt = 3</code>."},{"location":"notes/CMU15445/modern_sql/#example-2-multiple-aggregates","title":"Example 2: Multiple Aggregates","text":"SQL<pre><code>SELECT AVG(gpa), COUNT(sid)  \nFROM student  \nWHERE login LIKE '%@cs';  \n</code></pre> Output: | AVG(gpa) | COUNT(sid) | |----------|------------| | 3.8      | 3          |"},{"location":"notes/CMU15445/modern_sql/#example-3-group-by-having","title":"Example 3: Group By + HAVING","text":"SQL<pre><code>SELECT AVG(s.gpa), e.cid  \nFROM enrolled AS e  \nJOIN student AS s ON e.sid = s.sid  \nGROUP BY e.cid  \nHAVING AVG(s.gpa) &gt; 3.9;  \n</code></pre> Output: | AVG(s.gpa) | cid     | |------------|---------| | 3.9        | 15-721  |"},{"location":"notes/CMU15445/modern_sql/#5-string-operations","title":"5. String Operations \ud83d\udcdd","text":"<ul> <li>Case Sensitivity: SQL-92 is case-sensitive.  </li> <li>Pattern Matching: Use <code>LIKE</code>, <code>%</code> (any substring), <code>_</code> (single character).  </li> </ul>"},{"location":"notes/CMU15445/modern_sql/#example","title":"Example:","text":"SQL<pre><code>SELECT *  \nFROM student  \nWHERE UPPER(name) = UPPER('TuPaC');  \n</code></pre> Output: Tupac\u2019s record."},{"location":"notes/CMU15445/modern_sql/#6-output-control","title":"6. Output Control \ud83c\udf9b\ufe0f","text":"<ul> <li>Sorting: SQL<pre><code>SELECT sid, grade  \nFROM enrolled  \nWHERE cid = '15-721'  \nORDER BY grade DESC;  \n</code></pre></li> <li>Limits: SQL<pre><code>SELECT sid, name  \nFROM student  \nLIMIT 2;  \n</code></pre></li> </ul>"},{"location":"notes/CMU15445/modern_sql/#7-window-functions","title":"7. Window Functions \ud83e\ude9f","text":"<p>Concept: Compute values over a \"window\" of rows.  </p>"},{"location":"notes/CMU15445/modern_sql/#example-rank-students-by-grade","title":"Example: Rank Students by Grade","text":"SQL<pre><code>SELECT *, RANK() OVER (PARTITION BY cid ORDER BY grade)  \nFROM enrolled;  \n</code></pre> Output: | sid   | cid     | grade | rank | |-------|---------|-------|------| | 53655 | 15-445  | B     | 1    | | 53666 | 15-445  | C     | 2    |"},{"location":"notes/CMU15445/modern_sql/#8-nested-queries","title":"8. Nested Queries \ud83d\udd04","text":""},{"location":"notes/CMU15445/modern_sql/#example-find-students-enrolled-in-15-445","title":"Example: Find Students Enrolled in 15-445","text":"SQL<pre><code>SELECT name  \nFROM student  \nWHERE sid IN (  \n    SELECT sid  \n    FROM enrolled  \n    WHERE cid = '15-445'  \n);  \n</code></pre> Output: RZA and Tupac."},{"location":"notes/CMU15445/modern_sql/#9-lateral-joins","title":"9. Lateral Joins \ud83d\udd17","text":"<p>Use Case: Reference outer query columns in subqueries.  </p>"},{"location":"notes/CMU15445/modern_sql/#example-course-stats","title":"Example: Course Stats","text":"SQL<pre><code>SELECT c.cid, t1.cnt, t2.avg_gpa  \nFROM course AS c  \nLATERAL (SELECT COUNT(*) AS cnt FROM enrolled WHERE cid = c.cid) AS t1  \nLATERAL (SELECT AVG(gpa) AS avg_gpa FROM student s  \n         JOIN enrolled e ON s.sid = e.sid WHERE e.cid = c.cid) AS t2;  \n</code></pre>"},{"location":"notes/CMU15445/modern_sql/#10-common-table-expressions-ctes","title":"10. Common Table Expressions (CTEs) \ud83d\udce6","text":""},{"location":"notes/CMU15445/modern_sql/#example-recursive-counter","title":"Example: Recursive Counter","text":"SQL<pre><code>WITH RECURSIVE cteSource (counter) AS (  \n    SELECT 1  \n    UNION  \n    SELECT counter + 1 FROM cteSource WHERE counter &lt; 10  \n)  \nSELECT * FROM cteSource;  \n</code></pre> Output: Numbers 1 to 10.    <p>Key Takeaways \ud83d\ude80 - SQL evolves with new standards (e.g., SQL:2023). - Master aggregates, window functions, and CTEs for advanced queries. - Use LATERAL and nested queries for complex joins.  </p>"},{"location":"notes/CMU15445/relation_module/","title":"1 Relation Module","text":""},{"location":"notes/CMU15445/relation_module/#lecture-01-relational-model-algebra","title":"Lecture 01: Relational Model &amp; Algebra","text":"<p> \u7ea6 518 \u4e2a\u5b57  22 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-445/645 Database Systems (Spring 2025) Carnegie Mellon University Prof. Jignesh Patel </p>"},{"location":"notes/CMU15445/relation_module/#course-overview","title":"\ud83d\udcda Course Overview","text":"<ul> <li>Focuses on design/implementation of DBMSs (not using/administering DBMSs).  </li> <li>Textbook: Database System Concepts, 7<sup>th</sup> Ed. by Silberschatz, Korth, &amp; Sudarshan.  </li> <li>Grading:  </li> <li>Homeworks (15%)  </li> <li>Projects (45%)  </li> <li>Midterm (20%)  </li> <li>Final Exam (20%)  </li> </ul> <p>\u26a0\ufe0f Plagiarism Warning: All work must be original. Code copying is strictly prohibited.  </p>"},{"location":"notes/CMU15445/relation_module/#what-is-a-database","title":"\ud83d\uddc4\ufe0f What is a Database?","text":"<ul> <li>Database: Organized collection of inter-related data modeling real-world aspects (e.g., digital music store tracking artists/albums).  </li> <li>DBMS: Software managing the database (e.g., MySQL, Oracle).  </li> </ul>"},{"location":"notes/CMU15445/relation_module/#flat-file-strawman","title":"\ud83e\udde9 Flat File Strawman","text":"<p>Storing data in CSV files leads to issues:  </p>"},{"location":"notes/CMU15445/relation_module/#example-artists-and-albums","title":"Example: Artists and Albums","text":"<p><code>artists.csv</code> </p>Text Only<pre><code>\"Wu-Tang Clan\",1992,\"USA\"\n\"Notorious BIG\",1992,\"USA\"\n\"GZA\",1990,\"USA\"\n</code></pre> <p><code>albums.csv</code> </p>Text Only<pre><code>\"Enter the Wu-Tang\",\"Wu-Tang Clan\",1993\n\"St. Ides Mix Tape\",\"Wu-Tang Clan\",1994\n\"Liquid Swords\",\"GZA\",1995\n</code></pre>"},{"location":"notes/CMU15445/relation_module/#issues-with-flat-files","title":"\u26a0\ufe0f Issues with Flat Files","text":"<ol> <li>Data Integrity:    - No enforcement of artist-album relationships.    - Invalid data types (e.g., string instead of year).  </li> <li>Implementation:    - No concurrency control (e.g., simultaneous writes).  </li> <li>Durability:    - Risk of data loss during crashes.  </li> </ol>"},{"location":"notes/CMU15445/relation_module/#relational-model","title":"\ud83d\udee0\ufe0f Relational Model","text":"<p>Proposed by Ted Codd (IBM, 1969) to decouple logical and physical layers.  </p>"},{"location":"notes/CMU15445/relation_module/#key-tenets","title":"Key Tenets","text":"<ol> <li>Structure: Relations (tables) define data independently of storage.  </li> <li>Integrity: Constraints (e.g., primary keys, foreign keys).  </li> <li>Manipulation: High-level querying (e.g., SQL).  </li> </ol>"},{"location":"notes/CMU15445/relation_module/#example-artists-table","title":"Example: Artists Table","text":"<code>id</code> <code>name</code> <code>year</code> <code>country</code> 101 Wu-Tang Clan 1992 USA 102 Notorious BIG 1992 USA 103 GZA 1990 USA"},{"location":"notes/CMU15445/relation_module/#constraints","title":"Constraints","text":"<ul> <li>Primary Key: Uniquely identifies a tuple (e.g., <code>id</code>).  </li> <li>Foreign Key: Links to another relation (e.g., <code>artist_id</code> in <code>albums</code>).  </li> <li>User-Defined: SQL<pre><code>CREATE TABLE Artist (\n  name VARCHAR NOT NULL,\n  year INT CHECK (year &gt; 1900)\n);\n</code></pre></li> </ul>"},{"location":"notes/CMU15445/relation_module/#relational-algebra","title":"\ud83d\udd0d Relational Algebra","text":"<p>Fundamental operations to manipulate relations.  </p>"},{"location":"notes/CMU15445/relation_module/#1-select","title":"1. Select (\u03c3)","text":"<p>Filters tuples based on a predicate. Syntax: \\(\\sigma_{\\text{predicate}}(R)\\) </p> <p>Example: - Relation <code>R</code>:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a1     | 101    |   | a2     | 102    |   | a2     | 103    |   | a3     | 104    |  </p> <ul> <li>Query: \\(\\sigma_{a\\_id='a2'}(R)\\) Result:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a2     | 102    |   | a2     | 103    |  </li> </ul> <p>SQL Equivalent: </p>SQL<pre><code>SELECT * FROM R WHERE a_id = 'a2';\n</code></pre>"},{"location":"notes/CMU15445/relation_module/#2-projection","title":"2. Projection (\u03c0)","text":"<p>Selects specific attributes. Syntax: \\(\\pi_{\\text{attributes}}(R)\\) </p> <p>Example: - Query: \\(\\pi_{b\\_id-100, a\\_id}(\\sigma_{a\\_id='a2'}(R))\\) Result:   | <code>b_id-100</code> | <code>a_id</code> |   |------------|--------|   | 2          | a2     |   | 3          | a2     |  </p> <p>SQL Equivalent: </p>SQL<pre><code>SELECT b_id-100, a_id FROM R WHERE a_id = 'a2';\n</code></pre>"},{"location":"notes/CMU15445/relation_module/#3-union","title":"3. Union (\u222a)","text":"<p>Combines tuples from two relations. Syntax: \\(R \\cup S\\) </p> <p>Example: - Relation <code>R</code>:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a1     | 101    |   | a2     | 102    |  </p> <ul> <li> <p>Relation <code>S</code>:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a2     | 102    |   | a3     | 103    |  </p> </li> <li> <p>Result:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a1     | 101    |   | a2     | 102    |   | a3     | 103    |  </p> </li> </ul> <p>SQL Equivalent: </p>SQL<pre><code>(SELECT * FROM R) UNION (SELECT * FROM S);\n</code></pre>"},{"location":"notes/CMU15445/relation_module/#4-join","title":"4. Join (\u22c8)","text":"<p>Combines tuples with matching attributes. Syntax: \\(R \\bowtie S\\) </p> <p>Example: - Relation <code>R</code>:   | <code>a_id</code> | <code>b_id</code> |   |--------|--------|   | a1     | 101    |   | a2     | 102    |  </p> <ul> <li> <p>Relation <code>S</code>:   | <code>a_id</code> | <code>b_id</code> | <code>val</code> |   |--------|--------|-------|   | a2     | 102    | XXX   |   | a3     | 103    | YYY   |  </p> </li> <li> <p>Result:   | <code>a_id</code> | <code>b_id</code> | <code>val</code> |   |--------|--------|-------|   | a2     | 102    | XXX   |  </p> </li> </ul> <p>SQL Equivalent: </p>SQL<pre><code>SELECT * FROM R NATURAL JOIN S;\n</code></pre>"},{"location":"notes/CMU15445/relation_module/#document-data-model","title":"\ud83d\udcc4 Document Data Model","text":"<ul> <li>Stores hierarchical data (e.g., JSON/XML).  </li> <li>Example: JSON<pre><code>{\n  \"name\": \"GZA\",\n  \"year\": 1990,\n  \"albums\": [\n    { \"name\": \"Liquid Swords\", \"year\": 1995 },\n    { \"name\": \"Beneath the Surface\", \"year\": 1999 }\n  ]\n}\n</code></pre></li> </ul> <p>\u26a0\ufe0f Issues: Similar to flat files (data integrity, duplication).  </p>"},{"location":"notes/CMU15445/relation_module/#vector-data-model","title":"\ud83d\udd22 Vector Data Model","text":"<ul> <li>Represents data as vectors for ML applications (e.g., semantic search).  </li> <li>Example:   | <code>id</code> | <code>name</code>               | <code>year</code> | <code>embedding</code>              |   |------|---------------------|--------|--------------------------|   | 11   | Enter the Wu-Tang   | 1993   | [0.2, 0.5, ..., 0.7]     |   | 22   | St. Ides Mix Tape   | 1994   | [0.1, 0.8, ..., 0.3]     |  </li> </ul> <p>Use Case: Nearest-neighbor search for embeddings (e.g., ChatGPT).  </p>"},{"location":"notes/CMU15445/relation_module/#project-0-p0-skip-list","title":"\ud83d\udee0\ufe0f Project 0 (P0): Skip List","text":"<ul> <li>Goal: Implement a thread-safe Skip List in C++.  </li> <li>Key Features:  </li> <li>Average \\(O(\\log n)\\) search/insert/delete.  </li> <li>Due: Jan 26 @ 11:59 PM (No late days!).  </li> </ul> <p>\u26a0\ufe0f Warning: Failure to score 100% results in automatic withdrawal.  </p>"},{"location":"notes/CMU15445/relation_module/#key-takeaways","title":"\ud83d\udcc5 Key Takeaways","text":"<ol> <li>Relational Model abstracts storage details and ensures data integrity.  </li> <li>Relational Algebra provides foundational query operations.  </li> <li>Alternative Models (Document, Vector) address niche use cases but inherit flat-file issues.  </li> </ol> <p>\ud83d\ude80 Next: Dive into SQL and Query Optimization!  </p>"},{"location":"notes/CMU15445/storage1/","title":"3 storage1","text":""},{"location":"notes/CMU15445/storage1/#lecture-03-database-storage-part-i","title":"Lecture #03: Database Storage (Part I)","text":"<p> \u7ea6 429 \u4e2a\u5b57  1 \u884c\u4ee3\u7801  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-445/645 Database Systems (Spring 2025) Carnegie Mellon University Prof. Jignesh Patel </p>"},{"location":"notes/CMU15445/storage1/#1-storage-hierarchy","title":"1. Storage Hierarchy","text":""},{"location":"notes/CMU15445/storage1/#key-concepts","title":"Key Concepts:","text":"<ul> <li>Disk-Oriented DBMS: Primary storage is non-volatile disk.  </li> <li>Volatile vs. Non-Volatile Devices:  </li> <li>Volatile (Memory):  <ul> <li>\ud83d\udea8 Data lost on power loss (e.g., DRAM).  </li> <li>Byte-addressable, fast random access.  </li> </ul> </li> <li>Non-Volatile (Disk):  <ul> <li>\ud83d\udcbe Data retained on power loss (e.g., HDD, SSD).  </li> <li>Block/page addressable (e.g., read 4KB pages).  </li> <li>Optimized for sequential access.  </li> </ul> </li> </ul>"},{"location":"notes/CMU15445/storage1/#latency-comparison-humanized-scale","title":"Latency Comparison (Humanized Scale):","text":"<ul> <li>If L1 Cache = 1 second:  </li> <li>SSD read \u2248 4.4 hours </li> <li>HDD read \u2248 3.3 weeks </li> </ul>"},{"location":"notes/CMU15445/storage1/#2-disk-oriented-dbms-architecture","title":"2. Disk-Oriented DBMS Architecture","text":""},{"location":"notes/CMU15445/storage1/#components","title":"Components:","text":"<ol> <li>Buffer Pool: Manages data movement between disk and memory.  </li> <li>Execution Engine: Executes queries by requesting pages from the buffer pool.  </li> </ol>"},{"location":"notes/CMU15445/storage1/#key-design-goals","title":"Key Design Goals:","text":"<ul> <li>Handle databases larger than memory.  </li> <li>Minimize disk stalls (optimize sequential access).  </li> </ul>"},{"location":"notes/CMU15445/storage1/#3-dbms-vs-os","title":"3. DBMS vs. OS","text":""},{"location":"notes/CMU15445/storage1/#why-dbms-avoids-os-virtual-memory-mmap","title":"Why DBMS Avoids OS Virtual Memory (mmap):","text":"<ul> <li>\ud83d\udeab Page Faults Block Execution: DBMS loses control over I/O scheduling.  </li> <li>Better Alternatives:  </li> <li><code>madvise()</code>: Hint OS about future page accesses.  </li> <li><code>mlock()</code>: Prevent OS from swapping pages.  </li> <li><code>msync()</code>: Force flush pages to disk.  </li> </ul> <p>Lesson: \"The OS is not your friend.\" </p>"},{"location":"notes/CMU15445/storage1/#4-file-storage","title":"4. File Storage","text":""},{"location":"notes/CMU15445/storage1/#basics","title":"Basics:","text":"<ul> <li>DBMS stores databases as files (single or multiple).  </li> <li>Storage Manager:  </li> <li>Manages files as a collection of pages.  </li> <li>Tracks free space, read/write status, and page types.  </li> </ul>"},{"location":"notes/CMU15445/storage1/#example-sqlite","title":"Example: SQLite","text":"<ul> <li>Uses a single file for simplicity.  </li> </ul>"},{"location":"notes/CMU15445/storage1/#5-database-pages","title":"5. Database Pages","text":""},{"location":"notes/CMU15445/storage1/#types-of-pages","title":"Types of Pages:","text":"<ol> <li>Hardware Page: 4KB (atomic write guarantee).  </li> <li>OS Page: 4KB (or 2MB/1GB for x64).  </li> <li>Database Page: 1KB\u201332KB (configurable).  </li> </ol>"},{"location":"notes/CMU15445/storage1/#page-id-management","title":"Page ID Management:","text":"<ul> <li>Unique page ID per page.  </li> <li>Indirection layer maps IDs to file paths/offsets.  </li> </ul> <p>Default Page Sizes: - PostgreSQL: 8KB - MySQL: 16KB - SQLite: 4KB  </p> <p> </p>"},{"location":"notes/CMU15445/storage1/#6-heap-file-organization","title":"6. Heap File Organization","text":""},{"location":"notes/CMU15445/storage1/#definition","title":"Definition:","text":"<ul> <li>Unordered collection of pages (tuples stored randomly).  </li> </ul>"},{"location":"notes/CMU15445/storage1/#page-tracking-methods","title":"Page Tracking Methods:","text":"<ol> <li>Linked List:    - Header page tracks free/data pages.    - Sequential scan required for page lookup.  </li> <li>Page Directory:    - Special directory pages track data page locations and metadata.  </li> </ol>"},{"location":"notes/CMU15445/storage1/#7-page-layout","title":"7. Page Layout","text":""},{"location":"notes/CMU15445/storage1/#slotted-pages-most-common","title":"Slotted Pages (Most Common):","text":"<ul> <li>Structure:  </li> <li>Header tracks slot count and free space offset.  </li> <li>Slot Array maps slots to tuple offsets.  </li> <li>Tuples grow from the end backward; slots grow forward.  </li> </ul> <p>Example: - Adding a new tuple:   1. Allocate slot in the slot array.   2. Write tuple data from the end of the page. - Deleting a tuple:   - Mark slot as unused; free space can be reused.  </p>"},{"location":"notes/CMU15445/storage1/#8-tuple-layout","title":"8. Tuple Layout","text":""},{"location":"notes/CMU15445/storage1/#components_1","title":"Components:","text":"<ol> <li>Header:    - Visibility info (concurrency control).    - NULL bitmap.  </li> <li>Data: Attributes stored in schema order.  </li> </ol> <p>Example: </p>Text Only<pre><code>| Header (Visibility, NULL bits) | a (INT) | b (DOUBLE) | c (VARCHAR) | ...\n</code></pre>"},{"location":"notes/CMU15445/storage1/#denormalized-tuples","title":"Denormalized Tuples:","text":"<ul> <li>Pre-join: Store related tuples (e.g., joined tables) in the same page.  </li> <li>Pros: Fewer I/O operations for common queries.  </li> <li>Cons: Updates become more complex.  </li> </ul>"},{"location":"notes/CMU15445/storage1/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Disk vs. Memory: Optimize for sequential access to minimize latency.  </li> <li>Page Management: Slotted pages dominate for flexibility.  </li> <li>DBMS Control: Avoid OS interference for performance and correctness.  </li> </ul> <p>Next Lecture: Log-Structured Storage, Index-Organized Storage, and Catalogs \ud83d\udcda  </p>"},{"location":"notes/CMU15445/storage2/","title":"5 storage2","text":""},{"location":"notes/CMU15445/storage2/#lecture-05-database-storage-part-ii","title":"Lecture 05: Database Storage (Part II)","text":"<p> \u7ea6 470 \u4e2a\u5b57  9 \u884c\u4ee3\u7801  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-445/645 Database Systems (Spring 2025) Carnegie Mellon University Prof. Jignesh Patel </p>"},{"location":"notes/CMU15445/storage2/#1-log-structured-storage","title":"1. Log-Structured Storage","text":""},{"location":"notes/CMU15445/storage2/#problems-with-slotted-page-architecture","title":"Problems with Slotted-Page Architecture","text":"<ol> <li>Fragmentation: Deletion leaves gaps in pages, reducing space utilization.  </li> <li>Useless Disk I/O: Entire block must be fetched to update a single tuple.  </li> <li>Random Disk I/O: Updating multiple tuples across different pages is slow.  </li> </ol> <p>Solution: Log-Structured Storage (append-only model, e.g., HDFS, Google Colossus).  </p>"},{"location":"notes/CMU15445/storage2/#log-structured-storage-overview","title":"Log-Structured Storage Overview","text":"<ul> <li>MemTable: In-memory structure (e.g., sorted key-value store) for fast writes.  </li> <li>SSTable (Sorted String Table): Immutable on-disk files storing sorted log entries.  </li> <li>Each entry contains:  <ul> <li>Tuple\u2019s unique identifier  </li> <li>Operation type (<code>PUT</code>/<code>DELETE</code>)  </li> <li>Tuple contents (for <code>PUT</code>)  </li> </ul> </li> </ul> <p>Workflow: 1. Writes are appended to the MemTable. 2. When MemTable fills, it\u2019s flushed to disk as an SSTable (sorted by key). 3. Reads check MemTable first, then SSTables from newest to oldest.  </p> <p> </p>"},{"location":"notes/CMU15445/storage2/#compaction","title":"Compaction","text":"<ul> <li>Purpose: Merge SSTables to reduce redundancy and improve read performance.  </li> <li>Methods:  </li> <li>Level Compaction: Merge smaller SSTables into larger ones (hierarchical tiers).  </li> <li>Universal Compaction: Merge any SSTables regardless of size.  </li> </ul> <p>Example: - Input SSTables:   - <code>PUT(key101,a1)</code>, <code>PUT(key102,b1)</code>, <code>DEL(key103)</code>, <code>PUT(key104,d2)</code> - After Compaction: Only keep the latest value for each key.  </p> <p> </p>"},{"location":"notes/CMU15445/storage2/#tradeoffs","title":"Tradeoffs","text":"<p>\u2705 Pros: - Fast sequential writes (ideal for append-only storage). - Reduced random I/O.  </p> <p>\u274c Cons: - Slow reads (may require scanning multiple SSTables). - Write amplification (multiple physical writes per logical write). - Compaction is resource-intensive.  </p>"},{"location":"notes/CMU15445/storage2/#2-index-organized-storage","title":"2. Index-Organized Storage","text":"<ul> <li>Key Idea: Store table tuples directly within an index structure (e.g., B+Tree).  </li> <li>Page Layout: Similar to slotted pages, but tuples are sorted by key.  </li> </ul> <p>Comparison: - B+Tree: Pay maintenance costs upfront (splits/merges). - LSM-Tree: Pay costs during compaction.  </p> <p> </p>"},{"location":"notes/CMU15445/storage2/#3-data-representation","title":"3. Data Representation","text":""},{"location":"notes/CMU15445/storage2/#tuple-structure","title":"Tuple Structure","text":"<ul> <li>Header: Metadata (e.g., null bitmap, transaction visibility).  </li> <li>Data: Byte array interpreted via schema.  </li> </ul> <p>Word Alignment: - Ensure attributes align with CPU word boundaries (4/8 bytes). - Methods:   - Padding: Add empty bits after attributes.   - Reordering: Rearrange attributes physically.  </p> <p>Example: </p>SQL<pre><code>CREATE TABLE foo (  \n  id INT PRIMARY KEY,        -- 32 bits  \n  cdate TIMESTAMP,          -- 64 bits  \n  color CHAR(2),            -- 16 bits  \n  zipcode INT                -- 32 bits  \n);  \n</code></pre> Reordered Layout: <code>id (32) \u2192 zipcode (32) \u2192 color (16 + 16 padding) \u2192 cdate (64)</code> <p> </p>"},{"location":"notes/CMU15445/storage2/#data-types","title":"Data Types","text":"<ol> <li>Integers: Fixed-length (e.g., <code>INT</code>, <code>BIGINT</code>).  </li> <li>Variable-Precision Numbers: IEEE-754 floats (fast but inexact).  </li> <li>Fixed-Precision Numbers: Exact decimal/NUMERIC (stored as variable-length binary).  </li> <li>Variable-Length Data:    - Header + data (e.g., <code>VARCHAR</code>, <code>BLOB</code>).    - Overflow pages for large values.  </li> <li>Dates/Times: Stored as microseconds since Unix epoch.  </li> </ol> <p>NULL Representation: - Null Bitmap: Centralized header indicating null attributes. - Special Values: e.g., <code>INT32_MIN</code> for NULL.  </p>"},{"location":"notes/CMU15445/storage2/#4-system-catalogs","title":"4. System Catalogs","text":"<ul> <li>Metadata: Tables, columns, indexes, users, permissions, statistics.  </li> <li>Storage: Catalog tables within the DBMS itself.  </li> </ul> <p>Querying Catalogs: </p>SQL<pre><code>-- List all tables  \nSELECT * FROM INFORMATION_SCHEMA.TABLES  \nWHERE table_catalog = 'current_db';  \n</code></pre> <p>Schema Changes: - Add Column: Copy tuples (NSM) or create new segment (DSM). - Drop Column: Mark deprecated or free space.  </p>"},{"location":"notes/CMU15445/storage2/#5-large-values-external-storage","title":"5. Large Values &amp; External Storage","text":"<ul> <li>Overflow Pages: Used when tuple size exceeds page limit (e.g., PostgreSQL TOAST).  </li> <li>External Files:  </li> <li>Stored as BLOBs (e.g., Oracle BFILE).  </li> <li>Drawbacks: No durability/transaction guarantees.  </li> </ul>"},{"location":"notes/CMU15445/storage2/#conclusion","title":"Conclusion","text":"<ul> <li>Log-Structured Storage: Optimized for write-heavy workloads.  </li> <li>Index-Organized Storage: Sorted storage with upfront maintenance.  </li> <li>Data Alignment: Critical for CPU efficiency.  </li> <li>System Catalogs: Centralized metadata management.  </li> </ul> <p>\ud83d\ude80 Key Takeaway: Storage architecture choices depend on workload (read vs. write-heavy) and performance tradeoffs.  </p>"},{"location":"notes/CSAPP/bits-bytes-ints/","title":"2 bits-bytes-ints","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#bits-bytes-and-integers","title":"Bits, Bytes, and Integers","text":"<p> \u7ea6 419 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/14-513/15-513: Introduction to Computer Systems 2<sup>nd</sup> Lecture, Aug 29, 2024 </p>"},{"location":"notes/CSAPP/bits-bytes-ints/#1-binary-representation","title":"1. Binary Representation","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#key-concepts","title":"Key Concepts:","text":"<ul> <li>Binary (Base-2) System:  </li> <li><code>0</code> represents <code>0</code>, <code>1</code> represents <code>1</code>.  </li> <li>Each position corresponds to a power of 2 (e.g., <code>1011\u2082 = 1\u00b72\u00b3 + 0\u00b72\u00b2 + 1\u00b72\u00b9 + 1\u00b72\u2070 = 11\u2081\u2080</code>).  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#examples","title":"Examples:","text":"Binary Decimal Calculation Decimal Value <code>000</code> <code>0\u00b72\u00b2 + 0\u00b72\u00b9 + 0\u00b72\u2070</code> <code>0</code> <code>001</code> <code>0\u00b72\u00b2 + 0\u00b72\u00b9 + 1\u00b72\u2070</code> <code>1</code> <code>010</code> <code>0\u00b72\u00b2 + 1\u00b72\u00b9 + 0\u00b72\u2070</code> <code>2</code> <code>011</code> <code>0\u00b72\u00b2 + 1\u00b72\u00b9 + 1\u00b72\u2070</code> <code>3</code> <code>100</code> <code>1\u00b72\u00b2 + 0\u00b72\u00b9 + 0\u00b72\u2070</code> <code>4</code>"},{"location":"notes/CSAPP/bits-bytes-ints/#2-hexadecimal-octal","title":"2. Hexadecimal &amp; Octal","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#hexadecimal-base-16","title":"Hexadecimal (Base-16):","text":"<ul> <li>Digits: <code>0-9</code>, <code>A-F</code> (e.g., <code>1A2B\u2081\u2086 = 1\u00b716\u00b3 + 10\u00b716\u00b2 + 2\u00b716\u00b9 + 11\u00b716\u2070 = 6699\u2081\u2080</code>).  </li> <li>C notation: <code>0xFA1D37B</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#octal-base-8","title":"Octal (Base-8):","text":"<ul> <li>Less dense than hexadecimal.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#3-boolean-algebra-bit-level-operations","title":"3. Boolean Algebra &amp; Bit-Level Operations","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#operations-in-c","title":"Operations in C:","text":"Operator Meaning Example (Char) Result <code>&amp;</code> AND <code>0x69 &amp; 0x55</code> \u2192 <code>0x41</code> <code>01000001</code> <code>|</code> OR <code>0x69 | 0x55</code> \u2192 <code>0x7D</code> <code>01111101</code> <code>~</code> NOT <code>~0x41</code> \u2192 <code>0xBE</code> <code>10111110</code> <code>^</code> XOR <code>0x69 ^ 0x55</code> \u2192 <code>0x3C</code> <code>00111100</code>"},{"location":"notes/CSAPP/bits-bytes-ints/#logic-vs-bitwise-operations","title":"Logic vs. Bitwise Operations:","text":"<ul> <li>Logic Operators (<code>&amp;&amp;</code>, <code>||</code>, <code>!</code>): Return <code>0</code> or <code>1</code>.  </li> <li>Example: <code>!0x41</code> \u2192 <code>0x00</code> (False), <code>!!0x41</code> \u2192 <code>0x01</code> (True).  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#4-shift-operations","title":"4. Shift Operations","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#left-shift-x-y","title":"Left Shift (<code>x &lt;&lt; y</code>):","text":"<ul> <li>Fill right with <code>0</code>s.  </li> <li>Example: <code>01100010 &lt;&lt; 3</code> \u2192 <code>00010000</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#right-shift-x-y","title":"Right Shift (<code>x &gt;&gt; y</code>):","text":"<ul> <li>Logical Shift: Fill left with <code>0</code>s.  </li> <li>Example: <code>10100010 &gt;&gt; 2</code> \u2192 <code>00101000</code>.  </li> <li>Arithmetic Shift: Replicate sign bit.  </li> <li>Example: <code>10100010 &gt;&gt; 2</code> \u2192 <code>11101000</code>.  </li> </ul> <p>\u26a0\ufe0f Undefined Behavior: Shift amount <code>&lt; 0</code> or <code>\u2265</code> word size.  </p>"},{"location":"notes/CSAPP/bits-bytes-ints/#5-integer-representation","title":"5. Integer Representation","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#twos-complement","title":"Two\u2019s Complement:","text":"<ul> <li>Encoding Negative Numbers:  </li> <li><code>-x = ~x + 1</code> (e.g., <code>-5</code> in 4-bit: <code>0101</code> \u2192 <code>1010 + 1 = 1011</code>).  </li> <li>Ranges:  </li> <li>Unsigned: <code>0</code> to <code>2^w - 1</code>.  </li> <li>Signed (2\u2019s complement): <code>-2^(w-1)</code> to <code>2^(w-1) - 1</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#example-16-bit","title":"Example (16-bit):","text":"Type Decimal Hex Binary UMax 65535 <code>FF FF</code> <code>11111111 11111111</code> TMax 32767 <code>7F FF</code> <code>01111111 11111111</code> TMin -32768 <code>80 00</code> <code>10000000 00000000</code>"},{"location":"notes/CSAPP/bits-bytes-ints/#6-conversion-casting","title":"6. Conversion &amp; Casting","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#sign-extension","title":"Sign Extension:","text":"<ul> <li>Replicate sign bit to expand width (e.g., <code>1010</code> \u2192 <code>11111010</code>).  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#truncation","title":"Truncation:","text":"<ul> <li>Drop higher-order bits (e.g., <code>0xFA1D37B</code> truncated to 16 bits \u2192 <code>0xD37B</code>).  </li> </ul> <p>\u26a0\ufe0f Casting Pitfalls: - Mixing signed/unsigned in expressions \u2192 implicit casting to unsigned!  </p>"},{"location":"notes/CSAPP/bits-bytes-ints/#7-addition-multiplication","title":"7. Addition &amp; Multiplication","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#unsigned-addition-uadd_w","title":"Unsigned Addition (<code>UAdd_w</code>):","text":"<ul> <li>Modular Arithmetic: <code>UAdd_w(u, v) = (u + v) mod 2^w</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#twos-complement-addition","title":"Two\u2019s Complement Addition:","text":"<ul> <li>Same bit-level behavior as unsigned addition.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#multiplication","title":"Multiplication:","text":"<ul> <li>Equivalent to <code>(x * y) mod 2^w</code>.  </li> <li>Shift-Multiply Trick: <code>(x &lt;&lt; 5) - (x &lt;&lt; 3)</code> \u2192 <code>x * 24</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#8-byte-ordering","title":"8. Byte Ordering","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#endianness","title":"Endianness:","text":"<ul> <li>Big Endian: Most significant byte at lowest address.  </li> <li>Example: <code>0x01234567</code> \u2192 <code>01 23 45 67</code>.  </li> <li>Little Endian: Least significant byte at lowest address.  </li> <li>Example: <code>0x01234567</code> \u2192 <code>67 45 23 01</code>.  </li> </ul>"},{"location":"notes/CSAPP/bits-bytes-ints/#9-practice-problems","title":"9. Practice Problems","text":""},{"location":"notes/CSAPP/bits-bytes-ints/#example-1","title":"Example 1:","text":"<p>Q: Convert <code>FA1D37B\u2081\u2086</code> to binary. A: - <code>F</code>\u2192<code>1111</code>, <code>A</code>\u2192<code>1010</code>, <code>1</code>\u2192<code>0001</code>, <code>D</code>\u2192<code>1101</code>, <code>3</code>\u2192<code>0011</code>, <code>7</code>\u2192<code>0111</code>, <code>B</code>\u2192<code>1011</code>. - Result: <code>1111 1010 0001 1101 0011 0111 1011</code>.  </p>"},{"location":"notes/CSAPP/bits-bytes-ints/#example-2","title":"Example 2:","text":"<p>Q: Compute <code>0x69 &amp; 0x55</code> and interpret as a set intersection. A: - <code>0x69</code> = <code>01101001</code>, <code>0x55</code> = <code>01010101</code>. - <code>&amp;</code> \u2192 <code>01000001</code> = <code>{0, 6}</code>.  </p> <p>\ud83d\udcd8 Further Reading: Bryant and O\u2019Hallaron, Computer Systems: A Programmer\u2019s Perspective, Third Edition </p>"},{"location":"notes/CSAPP/cache-memories/","title":"10 cache-memories","text":""},{"location":"notes/CSAPP/cache-memories/#cache-memories","title":"Cache Memories","text":"<p> \u7ea6 464 \u4e2a\u5b57  17 \u884c\u4ee3\u7801  7 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/14-513/15-513: Introduction to Computer Systems 10<sup>th</sup> Lecture, Sept 26, 2024 </p>"},{"location":"notes/CSAPP/cache-memories/#todays-topics","title":"Today\u2019s Topics \ud83c\udfaf","text":"<ol> <li>Cache organization and operation </li> <li>Performance impact of caches    - Rearranging loops to improve spatial locality    - Using blocking to improve temporal locality  </li> <li>Case studies: Matrix multiplication optimizations  </li> </ol>"},{"location":"notes/CSAPP/cache-memories/#general-cache-concepts","title":"General Cache Concepts \ud83d\udca1","text":""},{"location":"notes/CSAPP/cache-memories/#cache-basics","title":"Cache Basics","text":"<ul> <li>Smaller, faster, more expensive memory that stores a subset of data blocks from main memory.  </li> <li>Data transferred in block-sized units.  </li> <li>Memory is partitioned into blocks.  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#cache-hit-vs-miss","title":"Cache Hit vs. Miss","text":"<ul> <li>Hit: Requested data block is in the cache. </li> <li>Miss: Block not in cache. Requires fetching from memory.  </li> <li>Placement policy: Determines where the block is stored.  </li> <li>Replacement policy: Decides which block to evict (e.g., LRU). </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#types-of-cache-misses","title":"Types of Cache Misses \u2744\ufe0f","text":"<ol> <li>Cold (Compulsory) Miss:    - First access to a block.    - Occurs even with an infinitely large cache.  </li> <li>Capacity Miss:    - Cache size is smaller than the working set.  </li> <li>Conflict Miss:    - Too many blocks map to the same cache set.  </li> </ol>"},{"location":"notes/CSAPP/cache-memories/#cache-organization","title":"Cache Organization \ud83c\udfd7\ufe0f","text":""},{"location":"notes/CSAPP/cache-memories/#parameters","title":"Parameters","text":"<ul> <li>S: Number of sets  </li> <li>E: Number of lines per set (associativity)  </li> <li>B: Block size (bytes)  </li> <li>Address breakdown:  </li> <li>Tag: Identifies the block within a set.  </li> <li>Set index: Determines the set.  </li> <li>Block offset: Selects the byte within the block.  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#example-direct-mapped-cache-e1","title":"Example: Direct-Mapped Cache (E=1)","text":"<ul> <li>1 line per set.  </li> <li>Address trace analysis:  </li> <li>Block size = 8 bytes.  </li> <li>4-bit address space (M=16 bytes).  </li> <li>Misses: Cold, conflict. </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#set-associative-cache-e2","title":"Set-Associative Cache (E=2) \ud83d\udd04","text":"<ul> <li>2 lines per set.  </li> <li>Replacement policies: LRU, random.  </li> <li>Example: 4-bit addresses, S=2 sets, B=2 bytes/block. </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#cache-write-policies","title":"Cache Write Policies \u270d\ufe0f","text":""},{"location":"notes/CSAPP/cache-memories/#write-hit","title":"Write-Hit","text":"<ul> <li>Write-through: Immediately write to memory.  </li> <li>Write-back: Defer write until block is replaced (uses dirty bit).  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#write-miss","title":"Write-Miss","text":"<ul> <li>Write-allocate: Load block into cache, then write.  </li> <li>No-write-allocate: Write directly to memory.  </li> </ul> <p>Typical Combinations: - Write-through + No-write-allocate - Write-back + Write-allocate  </p>"},{"location":"notes/CSAPP/cache-memories/#cache-performance-metrics","title":"Cache Performance Metrics \ud83d\udcca","text":"<ol> <li>Miss Rate = Misses / Accesses    - L1: 3-10%, L2: &lt;1%  </li> <li>Hit Time: Time to access cache (L1: ~4 cycles, L2: ~10 cycles).  </li> <li>Miss Penalty: Time to fetch from memory (50-200 cycles).  </li> </ol>"},{"location":"notes/CSAPP/cache-memories/#example-hit-vs-miss-impact","title":"Example: Hit vs. Miss Impact","text":"<ul> <li>97% hit rate:   Avg access time = \\(1 + 0.03 \\times 100 = 4\\) cycles  </li> <li>99% hit rate:   Avg access time = \\(1 + 0.01 \\times 100 = 2\\) cycles  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#matrix-multiplication-cache-optimization","title":"Matrix Multiplication &amp; Cache Optimization \ud83e\uddee","text":""},{"location":"notes/CSAPP/cache-memories/#problem-setup","title":"Problem Setup","text":"<ul> <li>Multiply \\(N \\times N\\) matrices of doubles (8 bytes each).  </li> <li>Block size = 32B (holds 4 doubles).  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#loop-order-analysis","title":"Loop Order Analysis","text":""},{"location":"notes/CSAPP/cache-memories/#ijkjik-order","title":"ijk/jik Order","text":"C<pre><code>for (i=0; i&lt;n; i++) {  \n  for (j=0; j&lt;n; j++) {  \n    sum = 0.0;  \n    for (k=0; k&lt;n; k++) {  \n      sum += a[i][k] * b[k][j];  \n    }  \n    c[i][j] = sum;  \n  }  \n}  \n</code></pre> - Miss rates per iteration:   | A | B | C |   |---|---|---|   |0.25|1.0|0.0|"},{"location":"notes/CSAPP/cache-memories/#kijikj-order","title":"kij/ikj Order","text":"C<pre><code>for (k=0; k&lt;n; k++) {  \n  for (i=0; i&lt;n; i++) {  \n    r = a[i][k];  \n    for (j=0; j&lt;n; j++) {  \n      c[i][j] += r * b[k][j];  \n    }  \n  }  \n}  \n</code></pre> - Miss rates per iteration:   | A | B | C |   |---|---|---|   |0.0|0.25|0.25|"},{"location":"notes/CSAPP/cache-memories/#blocking-technique","title":"Blocking Technique \ud83e\uddf1","text":"<ul> <li>Split matrices into B x B blocks.  </li> <li>Total misses: Reduced from \\( \\frac{9}{8}n^3 \\) to \\( \\frac{n^3}{4B} \\).  </li> <li>Key: Maximize temporal locality by reusing blocks.  </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#core-i7-cache-example","title":"Core i7 Cache Example \ud83d\udda5\ufe0f","text":"<ul> <li>L1 Data Cache:  </li> <li>32KB, 8-way set associative.  </li> <li>64B blocks.  </li> <li>Address breakdown:  <ul> <li>Tag: 35 bits  </li> <li>Set index: 6 bits  </li> <li>Block offset: 6 bits  </li> </ul> </li> </ul>"},{"location":"notes/CSAPP/cache-memories/#key-takeaways","title":"Key Takeaways \ud83d\ude80","text":"<ol> <li>Cache-friendly code:    - Focus on inner loops.    - Maximize spatial locality (stride-1 access).    - Maximize temporal locality (reuse data).  </li> <li>Blocking dramatically reduces cache misses by exploiting temporal locality.  </li> <li>Loop reordering can significantly impact performance (e.g., ijk vs. kij).  </li> </ol>"},{"location":"notes/CSAPP/design-debugging/","title":"8 design-debugging","text":""},{"location":"notes/CSAPP/design-debugging/#design-and-debugging","title":"Design and Debugging","text":"<p> \u7ea6 363 \u4e2a\u5b57  17 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/15-513: Introduction to Computer Systems 8<sup>th</sup> Lecture, Sept. 19, 2024 Instructors: Brian Railing, Mohamed Farag </p>"},{"location":"notes/CSAPP/design-debugging/#after-this-lecture-you-will-be-able-to","title":"\ud83d\udcda After This Lecture, You Will Be Able To:","text":"<ol> <li>Describe the steps to debug complex code failures.  </li> <li>Identify ways to manage complexity when programming.  </li> <li>State guidelines for communicating the intention of the code.  </li> </ol>"},{"location":"notes/CSAPP/design-debugging/#outline","title":"\ud83d\udcdd Outline","text":""},{"location":"notes/CSAPP/design-debugging/#debugging","title":"Debugging","text":"<ul> <li>Defects and Failures  </li> <li>Scientific Debugging  </li> <li>Tools  </li> </ul>"},{"location":"notes/CSAPP/design-debugging/#design","title":"Design","text":"<ul> <li>Managing Complexity  </li> <li>Communication (Naming, Comments)  </li> </ul>"},{"location":"notes/CSAPP/design-debugging/#debugging_1","title":"\ud83d\udee0 Debugging","text":""},{"location":"notes/CSAPP/design-debugging/#defects-errors-failures","title":"Defects, Errors, &amp; Failures","text":"<ol> <li>Defect: Programmer creates a fault.  </li> <li>Error: Defect causes wrong results in data/control signals.  </li> <li>Error Propagation: Erroneous state spreads.  </li> <li>Failure: System/component fails to produce intended result.  </li> </ol> <p>\ud83d\udd0d Why errors \u2260 failures? Errors can be masked (e.g., ECC memory) or detected.  </p>"},{"location":"notes/CSAPP/design-debugging/#scientific-debugging","title":"\ud83e\uddea Scientific Debugging","text":"<ol> <li>Hypothesis: Propose a defect explanation.  </li> <li>Prediction: What happens if the hypothesis is true?  </li> <li>Experiment: Test under controlled conditions.  </li> <li>Observation: Collect data to confirm/refute the hypothesis.  </li> <li>Fix &amp; Confirm: Apply fix and validate.  </li> </ol>"},{"location":"notes/CSAPP/design-debugging/#example-atlas-centaur-rocket-failure","title":"Example: Atlas-Centaur Rocket Failure","text":"<ul> <li>First Failure: Clogged turbopumps due to plastic remnants.  </li> <li>Fix: Bake off plastic.  </li> <li>Second Failure: Leaking valve pushed to failure by efficiency demands.  </li> <li>Lesson: Reproduce the failure to diagnose.  </li> </ul>"},{"location":"notes/CSAPP/design-debugging/#code-example-buggy-fibonacci","title":"\ud83d\udc1b Code Example: Buggy Fibonacci","text":"C<pre><code>int fib(int n) {\n    int $f, f 0=1, f 1=1$;\n    while $(n&gt;1)$ {\n        $$n=n-1;$$\n        $f=f 0+f 1$;\n        $f 0=f 1$;\n        f1=f;\n    }\n    return $f;\n}\n</code></pre> Failure: <code>fib(1)</code> returns garbage (e.g., <code>134513905</code>)."},{"location":"notes/CSAPP/design-debugging/#hypothesis-table","title":"\ud83d\udd0d Hypothesis Table","text":"Code Snippet Hypothesis <code>while(n&gt;1)</code> Loop condition incorrect for <code>n=1</code> <code>int f;</code> <code>f</code> is uninitialized"},{"location":"notes/CSAPP/design-debugging/#fix-initialize-f","title":"\ud83d\udee0 Fix: Initialize <code>f</code>","text":"C<pre><code>int fib(int n) {\n    int f = 1; // Initialize f\n    ...\n}\n</code></pre>"},{"location":"notes/CSAPP/design-debugging/#experiment-results","title":"\ud83e\uddea Experiment Results","text":"<ul> <li>Without Fix: <code>fib(1) = 0</code> (uninitialized value).  </li> <li>With Fix: <code>fib(1) = 1</code> (correct).  </li> </ul>"},{"location":"notes/CSAPP/design-debugging/#tools-for-debugging","title":"\ud83d\udee0 Tools for Debugging","text":"<ol> <li>Compiler Flags: Bash<pre><code>gcc -Wall -Werror -O3 -o fib fib.c  # Catch uninitialized variables\n</code></pre></li> <li>Valgrind: Detect memory leaks/uninitialized accesses.  </li> <li>GDB: Step-through execution to trace state.  </li> </ol>"},{"location":"notes/CSAPP/design-debugging/#design_1","title":"\ud83c\udfa8 Design","text":""},{"location":"notes/CSAPP/design-debugging/#managing-complexity","title":"Managing Complexity","text":"<ul> <li>Techniques:  </li> <li>Separation of Concerns  </li> <li>Modularity  </li> <li>Abstraction  </li> <li>DRY (Don\u2019t Repeat Yourself)  </li> </ul>"},{"location":"notes/CSAPP/design-debugging/#example-cache-access-steps","title":"Example: Cache Access Steps","text":"<ol> <li>Convert address \u2192 tag, set index, block offset.  </li> <li>Look up set.  </li> <li>Check tag match.  </li> <li>Handle hit/miss (evict LRU, load new line).  </li> </ol>"},{"location":"notes/CSAPP/design-debugging/#naming-guidelines","title":"\ud83d\udcdb Naming Guidelines","text":"<ol> <li>Avoid meaningless names:    - \u274c <code>tmp</code>, <code>data</code>, <code>foo</code>    - \u2705 <code>employeeSalary</code>, <code>cacheLine</code> </li> <li>Use domain terms:    - In a cache lab: <code>line</code>, <code>tag</code>, <code>setIndex</code>.  </li> <li>Limit word count:    - \u274c <code>arraysOfSetsOfLinesOfBlocks</code>    - \u2705 <code>cache</code> </li> </ol>"},{"location":"notes/CSAPP/design-debugging/#comments","title":"\ud83d\udcac Comments","text":"<ul> <li>Don\u2019ts:  </li> <li>\u274c Explain what code does (<code>i++ // increment i</code>).  </li> <li>\u274c Apologize for bad code.  </li> <li>Dos:  </li> <li>\u2705 Explain why (e.g., magic numbers): C<pre><code>// MAX_ADDRESS_LENGTH = 17 for 64-bit addresses (16 hex chars + null)\nconst int MAX_ADDRESS_LENGTH = 17;\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/design-debugging/#summary","title":"\ud83d\udcca Summary","text":"<ol> <li>Debugging: Systematic hypothesis-driven process. \u2705  </li> <li>Design: Manage complexity via modularity, naming, and clear communication. \ud83d\udce6  </li> <li>Tools: Use <code>-Wall</code>, Valgrind, and debuggers to catch issues early. \ud83d\udee0  </li> </ol> <p>\"Testing shows the presence, not the absence, of defects.\" \u2013 Dijkstra </p> <p>\ud83d\udd17 Resources: - The Space Review: Atlas-Centaur Failure - Computer Systems: A Programmer\u2019s Perspective, 3<sup>rd</sup> Ed. </p>"},{"location":"notes/CSAPP/machine-advanced/","title":"7 machine-advanced","text":""},{"location":"notes/CSAPP/machine-advanced/#machine-level-programming-v-advanced-topics","title":"Machine-Level Programming V: Advanced Topics","text":"<p> \u7ea6 261 \u4e2a\u5b57  44 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/15-513/14-513: Introduction to Computer Systems 7<sup>th</sup> Lecture, Sept 17, 2024 Instructors: Brian Railing, Mohamed Farag  </p>"},{"location":"notes/CSAPP/machine-advanced/#memory-layout","title":"\ud83d\udcda Memory Layout","text":""},{"location":"notes/CSAPP/machine-advanced/#x86-64-linux-memory-layout","title":"x86-64 Linux Memory Layout","text":"<ul> <li>Stack: Runtime stack (8MB limit), e.g., local variables.  </li> <li>Heap: Dynamically allocated (via <code>malloc</code>, <code>calloc</code>, <code>new</code>).  </li> <li>Data: Statically allocated data (global vars, static vars, string constants).  </li> <li>Text/Shared Libraries: Executable machine instructions (read-only).  </li> </ul> <p>Example Address Ranges (x86-64): | Variable/Function    | Address (Hex)               | |-----------------------|-----------------------------| | <code>local</code>               | <code>0x00007ffe4d3be87c</code>        | | <code>phuge1</code>              | <code>0x00007f7262a1e010</code>        | | <code>main()</code>              | <code>0x0000000000400590</code>        | (Exact values may vary) </p>"},{"location":"notes/CSAPP/machine-advanced/#buffer-overflow","title":"\ud83d\udea8 Buffer Overflow","text":""},{"location":"notes/CSAPP/machine-advanced/#vulnerability-example","title":"Vulnerability Example","text":"C<pre><code>typedef struct { \n    int a; \n    double d; \n} struct_t;\n\ndouble fun(int i) { \n    volatile struct_t s; \n    s.d = 3.14; \n    s.a[i] = 1073741824; // Out-of-bounds access\n    return s.d; \n}\n</code></pre> Results: | Call      | Output                  | |-----------|-------------------------| | <code>fun(0)</code>  | <code>3.1400000000</code>          | | <code>fun(3)</code>  | <code>2.0000006104</code>          | | <code>fun(6)</code>  | Stack smashing detected | | <code>fun(8)</code>  | Segmentation fault      |   <p>Explanation: - Overwriting memory beyond <code>a</code> corrupts adjacent data (e.g., <code>d</code> or return addresses).  </p>"},{"location":"notes/CSAPP/machine-advanced/#protection-mechanisms","title":"\ud83d\udee1\ufe0f Protection Mechanisms","text":"<ol> <li> <p>Avoid Overflow Vulnerabilities    - Use <code>fgets</code> instead of <code>gets</code>, <code>strncpy</code> instead of <code>strcpy</code>. </p>C<pre><code>void echo() { \n    char buf; \n    fgets(buf, 4, stdin); // Safer input\n    puts(buf); \n}\n</code></pre> </li> <li> <p>System-Level Protections    - Stack Randomization: Randomize stack offsets at program start.    - Non-Executable Memory: Mark stack/heap as non-executable (NX bit).  </p> </li> <li> <p>Stack Canaries    - Insert a \"canary\" value between buffer and return address. </p>Text Only<pre><code>echo:\n    sub    $0x18, %rsp\n    mov    %fs:0x28, %rax     ; Load canary\n    mov    %rax, 0x8(%rsp)    ; Store canary\n    ...\n    callq  gets\n    mov    0x8(%rsp), %rax    ; Check canary\n    xor    %fs:0x28, %rax\n    je     safe_exit\n    callq  stack_chk_fail     ; Crash if tampered\n</code></pre> </li> </ol>"},{"location":"notes/CSAPP/machine-advanced/#bypassing-protections","title":"\u2694\ufe0f Bypassing Protections","text":""},{"location":"notes/CSAPP/machine-advanced/#return-oriented-programming-rop","title":"Return-Oriented Programming (ROP)","text":"<ul> <li>Attack Strategy: Chain existing code snippets (\"gadgets\") ending in <code>ret</code>. Text Only<pre><code>Gadget 1: \n    add %rdx, %rdi \n    ret          ; 0xc3\n\nGadget 2: \n    mov %rax, %rdi \n    ret          ; 0xc3\n</code></pre> Crafted Attack String: Text Only<pre><code>303132333435363738393031323334353637383930313233c806400000000000\n</code></pre></li> <li>Overwrites return address to jump to <code>smash()</code>: C<pre><code>void smash() { \n    printf(\"I've been smashed!\\n\"); \n    exit(0); \n}\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-advanced/#unions","title":"\ud83d\udd04 Unions","text":""},{"location":"notes/CSAPP/machine-advanced/#memory-allocation-usage","title":"Memory Allocation &amp; Usage","text":"<ul> <li>Allocate space for the largest member. C<pre><code>typedef union { \n    char c;     // 8 bytes\n    short s;    // 8 bytes\n    int i;      // 8 bytes\n    long l;     // 8 bytes\n} UnionExample;\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-advanced/#byte-ordering","title":"Byte Ordering","text":"<ul> <li>Little Endian (x86-64): LSB at lowest address.  </li> <li>Big Endian (Sparc): MSB at lowest address.  </li> </ul> <p>Example (x86-64): | Data      | Bytes (Hex)               | |-----------|---------------------------| | <code>long l</code>  | <code>0xf7f6f5f4f3f2f1f0</code>     | | <code>int i</code>| <code>0xf3f2f1f0</code>              | | <code>short s</code> | <code>0xf1f0</code>              |  </p>"},{"location":"notes/CSAPP/machine-advanced/#summary","title":"\ud83e\udde9 Summary","text":"<ul> <li>Buffer Overflow: Major security threat via unchecked memory access.  </li> <li>Protections: Stack canaries, randomization, non-executable memory.  </li> <li>Unions: Flexible memory usage but require careful handling.  </li> <li>Byte Ordering: Critical for data portability across architectures.  </li> </ul> <p>Bryant and O'Hallaron, Computer Systems: A Programmer's Perspective, Third Edition \ud83d\udcd6</p>"},{"location":"notes/CSAPP/machine-basics/","title":"3 machine-basics","text":""},{"location":"notes/CSAPP/machine-basics/#machine-level-programming-i-basics","title":"Machine-Level Programming I: Basics \ud83d\udda5\ufe0f","text":"<p> \u7ea6 587 \u4e2a\u5b57  40 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/14-513/15-513: Introduction to Computer Systems 3<sup>rd</sup> Lecture, Sept 3, 2024  </p>"},{"location":"notes/CSAPP/machine-basics/#pre-class-setup","title":"Pre-Class Setup \ud83d\udee0\ufe0f","text":"<p>Login to a Shark machine and run: </p>Bash<pre><code>wget http://www.cs.cmu.edu/~213/activities/gdb-and-assembly.pdf  \nwget http://www.cs.cmu.edu/~213/activities/gdb-and-assembly.tar  \ntar xf gdb-and-assembly.tar  \ncd gdb-and-assembly  \n</code></pre>"},{"location":"notes/CSAPP/machine-basics/#announcements","title":"Announcements \ud83d\udce2","text":"<ul> <li>Lab 0 due today at midnight (no grace days).  </li> <li>If lab takes &gt;10 hours, consider dropping or studying C intensively.  </li> <li>Submit via Autolab.  </li> <li>Lab 1 (DataLab) due Tue, Sept 10.  </li> <li>Lab 2 (Bomb Lab) released Thu, Sept 5; due Thu, Sept 19.  </li> <li>Written Assignment 1 out Wed, Sept 4 (via Canvas); due Wed, Sept 11.  </li> <li>Bootcamp 2 (Debugging &amp; GDB) on Sun, Sept 8 (details on Piazza).  </li> </ul>"},{"location":"notes/CSAPP/machine-basics/#todays-topics","title":"Today\u2019s Topics \ud83d\udccc","text":"<ol> <li>History of Intel processors and architectures (CSAPP 3.1)  </li> <li>Assembly Basics: Registers, operands, <code>mov</code> (CSAPP 3.3-3.4)  </li> <li>Arithmetic &amp; logical operations (CSAPP 3.5)  </li> <li>C, assembly, machine code (CSAPP 3.2)  </li> </ol>"},{"location":"notes/CSAPP/machine-basics/#intel-x86-processors","title":"Intel x86 Processors \ud83c\udfed","text":""},{"location":"notes/CSAPP/machine-basics/#key-features","title":"Key Features:","text":"<ul> <li>Dominates laptop/desktop/server markets.  </li> <li>CISC (Complex Instruction Set Computer):  </li> <li>Thousands of instructions with varied formats.  </li> <li>Only a subset used in Linux programs.  </li> <li>Evolutionary design: Backward compatible since 1978 (8086).  </li> <li>Recent shift to x86-64 (64-bit architecture).  </li> </ul>"},{"location":"notes/CSAPP/machine-basics/#comparison-with-risc","title":"Comparison with RISC:","text":"CISC (x86) RISC (ARM, RISC-V) Many instructions Fewer instructions Variable formats Fixed formats Complex hardware Simpler hardware Legacy support Modern low-power focus"},{"location":"notes/CSAPP/machine-basics/#intel-x86-evolution-timeline","title":"Intel x86 Evolution Timeline \ud83d\udd70\ufe0f","text":""},{"location":"notes/CSAPP/machine-basics/#milestones","title":"Milestones:","text":"Name Year Transistors Clock (MHz) Key Contribution 8086 1978 29K 5-10 First 16-bit CPU, 1MB address space 386 1985 275K 16-33 First 32-bit (IA32), flat addressing Pentium 4E 2004 125M 2800-3800 First 64-bit (x86-64) Core 2 2006 291M 1060-3333 First multi-core Core i7 2008 731M 1600-4400 Quad-core (Shark machines)"},{"location":"notes/CSAPP/machine-basics/#x86-64-integer-registers","title":"x86-64 Integer Registers \ud83e\uddee","text":""},{"location":"notes/CSAPP/machine-basics/#16-general-purpose-registers","title":"16 General-Purpose Registers:","text":"64-bit 32-bit 16-bit 8-bit Purpose <code>%rax</code> <code>%eax</code> <code>%ax</code> <code>%al</code> Return value <code>%rbx</code> <code>%ebx</code> <code>%bx</code> <code>%bl</code> Callee-saved <code>%rcx</code> <code>%ecx</code> <code>%cx</code> <code>%cl</code> 4<sup>th</sup> argument <code>%rdx</code> <code>%edx</code> <code>%dx</code> <code>%dl</code> 3<sup>rd</sup> argument <code>%rsp</code> <code>%esp</code> <code>%sp</code> - Stack pointer <code>%rbp</code> <code>%ebp</code> <code>%bp</code> - Base pointer ... ... ... ... ... <p>Note: <code>%rsp</code> is reserved for stack operations.  </p>"},{"location":"notes/CSAPP/machine-basics/#assembly-operations","title":"Assembly Operations \u2699\ufe0f","text":""},{"location":"notes/CSAPP/machine-basics/#data-movement","title":"Data Movement:","text":"<p><code>movq Source, Dest</code> - Operand Types:   - Immediate: <code>$0x400</code>, <code>$-533</code> (constant values).   - Register: <code>%rax</code>, <code>%r13</code>.   - Memory: <code>(%rax)</code> (dereference address in <code>%rax</code>).  </p> <p>Examples: | Instruction          | C Equivalent        | |----------------------|---------------------| | <code>movq $0x4, %rax</code>    | <code>temp = 0x4;</code>       | | <code>movq %rax, (%rdx)</code>  | <code>*p = temp;</code>        | | <code>movq 8(%rbp), %rdx</code> | <code>temp = *(p + 8);</code>  |  </p> <p>Rule: No memory-to-memory transfers in one instruction!  </p>"},{"location":"notes/CSAPP/machine-basics/#swap-function-example","title":"Swap Function Example \ud83d\udd04","text":""},{"location":"notes/CSAPP/machine-basics/#c-code","title":"C Code:","text":"C<pre><code>void swap(long *xp, long *yp) {  \n    long t0 = *xp;  \n    long t1 = *yp;  \n    *xp = t1;  \n    *yp = t0;  \n}  \n</code></pre>"},{"location":"notes/CSAPP/machine-basics/#assembly-implementation","title":"Assembly Implementation:","text":"Text Only<pre><code>swap:  \n    movq (%rdi), %rax   # t0 = *xp  \n    movq (%rsi), %rdx   # t1 = *yp  \n    movq %rdx, (%rdi)   # *xp = t1  \n    movq %rax, (%rsi)   # *yp = t0  \n    ret  \n</code></pre>"},{"location":"notes/CSAPP/machine-basics/#step-by-step-execution","title":"Step-by-Step Execution:","text":"<ol> <li>Load <code>*xp</code> into <code>%rax</code>.  </li> <li>Load <code>*yp</code> into <code>%rdx</code>.  </li> <li>Store <code>%rdx</code> into <code>*xp</code>.  </li> <li>Store <code>%rax</code> into <code>*yp</code>.  </li> </ol>"},{"location":"notes/CSAPP/machine-basics/#addressing-modes","title":"Addressing Modes \ud83d\uddfa\ufe0f","text":""},{"location":"notes/CSAPP/machine-basics/#general-form-drb-ri-s","title":"General Form: <code>D(Rb, Ri, S)</code>","text":"<ul> <li>Address = <code>Rb + S * Ri + D</code> </li> <li><code>D</code>: Displacement (1, 2, or 4 bytes).  </li> <li><code>Rb</code>: Base register.  </li> <li><code>Ri</code>: Index register (not <code>%rsp</code>).  </li> <li><code>S</code>: Scale (1, 2, 4, 8).  </li> </ul> <p>Examples: | Expression          | Computation                | Address (Hex) | |----------------------|----------------------------|---------------| | <code>0x8(%rdx)</code>          | <code>0xf000 + 0x8</code>             | <code>0xf008</code>      | | <code>(%rdx, %rcx, 4)</code>   | <code>0xf000 + 4*0x100</code>         | <code>0xf400</code>      | | <code>0x80(,%rdx,2)</code>      | <code>2*0xf000 + 0x80</code>          | <code>0x1e080</code>     |  </p>"},{"location":"notes/CSAPP/machine-basics/#arithmetic-operations","title":"Arithmetic Operations \u2795\u2796","text":""},{"location":"notes/CSAPP/machine-basics/#two-operand-instructions","title":"Two-Operand Instructions:","text":"Instruction Effect Example <code>addq S,D</code> <code>D = D + S</code> <code>addq %rax, %rbx</code> <code>subq S,D</code> <code>D = D - S</code> <code>subq $4, %rsp</code> <code>imulq S,D</code> <code>D = D * S</code> <code>imulq %rcx, %rdx</code> <code>salq S,D</code> <code>D = D &lt;&lt; S</code> <code>salq $3, %rax</code>"},{"location":"notes/CSAPP/machine-basics/#one-operand-instructions","title":"One-Operand Instructions:","text":"Instruction Effect Example <code>incq D</code> <code>D = D + 1</code> <code>incq %rdi</code> <code>negq D</code> <code>D = -D</code> <code>negq %rax</code>"},{"location":"notes/CSAPP/machine-basics/#compiling-c-to-assembly","title":"Compiling C to Assembly \ud83d\udd04","text":""},{"location":"notes/CSAPP/machine-basics/#example-arithmetic-expression","title":"Example: Arithmetic Expression","text":"<p>C Code: </p>C<pre><code>long arith(long x, long y, long z) {  \n    long t1 = x + y;  \n    long t2 = z + t1;  \n    long t3 = x + 4;  \n    long t4 = y * 48;  \n    long t5 = t3 + t4;  \n    return t2 * t5;  \n}  \n</code></pre> <p>Compiled Assembly: </p>Text Only<pre><code>arith:  \n    leaq (%rdi,%rsi), %rax   # t1 = x + y  \n    addq %rdx, %rax          # t2 = z + t1  \n    leaq (%rsi,%rsi,2), %rdx  \n    salq $4, %rdx            # t4 = y * 48  \n    leaq 4(%rdi,%rdx), %rcx  # t5 = x + 4 + t4  \n    imulq %rcx, %rax         # return t2 * t5  \n    ret  \n</code></pre> <p>Key Instructions: - <code>leaq</code>: Compute address without memory access. - <code>salq</code>: Shift left for multiplication by 16 (<code>y*48 = y*3*16</code>).  </p>"},{"location":"notes/CSAPP/machine-basics/#disassembling-object-code","title":"Disassembling Object Code \ud83d\udd0d","text":""},{"location":"notes/CSAPP/machine-basics/#example-sumstore-function","title":"Example: <code>sumstore</code> Function","text":"<p>Object Code (Hex): </p>Text Only<pre><code>53 48 89 d3 e8 f2 ff ff ff 48 89 03 5b c3  \n</code></pre> <p>Disassembled Output: </p>Text Only<pre><code>0000000000400595 &lt;sumstore&gt;:  \n   400595: 53                   push   %rbx  \n   400596: 48 89 d3             mov    %rdx,%rbx  \n   400599: e8 f2 ff ff ff       callq  400590 &lt;plus&gt;  \n   40059e: 48 89 03             mov    %rax,(%rbx)  \n   4005a1: 5b                   pop    %rbx  \n   4005a2: c3                   retq  \n</code></pre> <p>Steps: 1. Push <code>%rbx</code> to save it. 2. Move argument <code>z</code> (<code>%rdx</code>) to <code>%rbx</code>. 3. Call <code>plus</code> function. 4. Store result (<code>%rax</code>) into <code>*dest</code> (<code>%rbx</code>). 5. Restore <code>%rbx</code> and return.  </p>"},{"location":"notes/CSAPP/machine-basics/#key-takeaways","title":"Key Takeaways \ud83c\udfaf","text":"<ol> <li>x86-64 Architecture: Evolutionary design with CISC legacy.  </li> <li>Registers &amp; Memory: 16 GP registers; memory addressed via modes like <code>D(Rb,Ri,S)</code>.  </li> <li>Assembly Basics: <code>mov</code>, arithmetic, and control flow instructions.  </li> <li>Compilation Pipeline: C \u2192 Assembly \u2192 Object Code \u2192 Executable.  </li> <li>Debugging Tools: <code>objdump</code> and GDB for disassembly.  </li> </ol>"},{"location":"notes/CSAPP/machine-control/","title":"4 machine-control","text":""},{"location":"notes/CSAPP/machine-control/#machine-level-programming-ii-control","title":"Machine-Level Programming II: Control","text":"<p> \u7ea6 376 \u4e2a\u5b57  70 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/14-513/15-513: Introduction to Computer Systems 4<sup>th</sup> Lecture, Sept 5, 2024 </p>"},{"location":"notes/CSAPP/machine-control/#overview","title":"\ud83d\udccc Overview","text":"<ul> <li>Key Topics:  </li> <li>Condition Codes (EFLAGS)  </li> <li>Conditional Branches &amp; Loops  </li> <li>Switch Statements  </li> <li>References: CSAPP 3.6.1\u20133.6.8  </li> </ul>"},{"location":"notes/CSAPP/machine-control/#review-machine-instructions-addressing-modes","title":"\ud83d\udd0d Review: Machine Instructions &amp; Addressing Modes","text":""},{"location":"notes/CSAPP/machine-control/#1-movq-instruction","title":"1\ufe0f\u20e3 <code>movq</code> Instruction","text":"<ul> <li>C Code: <code>*dest = t;</code> </li> <li>Assembly: <code>movq %rax, (%rbx)</code> </li> <li>Moves 8-byte value from <code>%rax</code> to memory location <code>M[%rbx]</code>.  </li> <li>Operands:  <ul> <li><code>t</code>: Register <code>%rax</code> </li> <li><code>dest</code>: Memory <code>M[%rbx]</code> </li> </ul> </li> </ul>"},{"location":"notes/CSAPP/machine-control/#2-general-addressing-mode","title":"2\ufe0f\u20e3 General Addressing Mode","text":"<ul> <li>Syntax: <code>D(Rb, Ri, S)</code> </li> <li>Meaning: <code>Mem[Reg[Rb] + S * Reg[Ri] + D]</code> </li> <li>Components:  <ul> <li><code>D</code>: Displacement (\u00bd/4 bytes)  </li> <li><code>Rb</code>: Base register  </li> <li><code>Ri</code>: Index register (\u2260 <code>%rsp</code>)  </li> <li><code>S</code>: Scale (\u00bd/4/8)  </li> </ul> </li> </ul>"},{"location":"notes/CSAPP/machine-control/#special-cases","title":"Special Cases:","text":"Syntax Meaning <code>(Rb)</code> <code>Mem[Reg[Rb]]</code> <code>(Rb, Ri)</code> <code>Mem[Reg[Rb] + Reg[Ri]]</code> <code>D(Rb, Ri)</code> <code>Mem[Reg[Rb] + Reg[Ri] + D]</code> <code>(Rb, Ri, S)</code> <code>Mem[Reg[Rb] + S * Reg[Ri]]</code>"},{"location":"notes/CSAPP/machine-control/#3-lea-vs-memory-access","title":"3\ufe0f\u20e3 <code>lea</code> vs. Memory Access","text":"<ul> <li><code>lea</code> (Load Effective Address):  </li> <li>Does NOT access memory! Computes address and stores it in a register.  </li> <li>Example: GAS<pre><code>lea 6(%rbx, %rdi, 8), %rax  # rax = rbx + rdi*8 + 6\n</code></pre></li> <li>Use Cases:  <ul> <li>Pointer arithmetic (e.g., array indexing).  </li> <li>Multi-operand calculations (e.g., <code>rax = rbx * 3</code> via <code>lea (%rbx, %rbx, 2), %rax</code>).  </li> </ul> </li> </ul>"},{"location":"notes/CSAPP/machine-control/#condition-codes-eflags","title":"\ud83d\udea9 Condition Codes (EFLAGS)","text":"<p>Implicitly set by arithmetic/logical operations: - CF (Carry Flag): Unsigned overflow. - ZF (Zero Flag): Result is zero. - SF (Sign Flag): Result is negative (signed). - OF (Overflow Flag): Signed overflow.  </p>"},{"location":"notes/CSAPP/machine-control/#cmp-and-test-instructions","title":"\u2699\ufe0f <code>cmp</code> and <code>test</code> Instructions","text":"<ul> <li><code>cmp a, b</code>: Computes <code>b - a</code> and sets flags.  </li> <li><code>test a, b</code>: Computes <code>b &amp; a</code> and sets flags (SF/ZF).  </li> <li>Common use: <code>test %rax, %rax</code> to check if <code>%rax</code> is zero.  </li> </ul>"},{"location":"notes/CSAPP/machine-control/#conditional-branches","title":"\ud83d\udd00 Conditional Branches","text":""},{"location":"notes/CSAPP/machine-control/#jump-table-jx-instructions","title":"Jump Table (<code>jX</code> Instructions)","text":"Instruction Condition Description <code>jmp</code> Always Unconditional jump <code>je</code>/<code>jz</code> <code>ZF=1</code> Jump if equal/zero <code>jne</code>/<code>jnz</code> <code>ZF=0</code> Jump if not equal <code>jg</code> <code>~(SF^OF) &amp; ~ZF</code> Jump if greater (signed) <code>ja</code> <code>~CF &amp; ~ZF</code> Jump if above (unsigned)"},{"location":"notes/CSAPP/machine-control/#loops-in-assembly","title":"\ud83d\udd04 Loops in Assembly","text":""},{"location":"notes/CSAPP/machine-control/#1-do-while-loop","title":"1\ufe0f\u20e3 Do-While Loop","text":"<ul> <li>C Code: C<pre><code>long pcount_do(unsigned long x) {\n    long result = 0;\n    do {\n        result += x &amp; 0x1;\n        x &gt;&gt;= 1;\n    } while (x);\n    return result;\n}\n</code></pre></li> <li>Assembly: GAS<pre><code>movl $0, %eax       # result = 0\n.L2:\nmovq %rdi, %rdx     # t = x\nandl $1, %edx       # t &amp;= 0x1\naddq %rdx, %rax     # result += t\nshrq %rdi           # x &gt;&gt;= 1\njne .L2             # if (x != 0) goto loop\nret\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-control/#2-while-loop-jump-to-middle","title":"2\ufe0f\u20e3 While Loop (Jump-to-Middle)","text":"<ul> <li>C Code: C<pre><code>long pcount_while(unsigned long x) {\n    long result = 0;\n    while (x) {\n        result += x &amp; 0x1;\n        x &gt;&gt;= 1;\n    }\n    return result;\n}\n</code></pre></li> <li>Assembly: GAS<pre><code>movl $0, %eax       # result = 0\njmp .L2\n.L3:\nmovq %rdi, %rdx     # t = x\nandl $1, %edx       # t &amp;= 0x1\naddq %rdx, %rax     # result += t\nshrq %rdi           # x &gt;&gt;= 1\n.L2:\ntestq %rdi, %rdi    # Test x\njne .L3             # if (x != 0) goto loop\nret\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-control/#switch-statements","title":"\ud83d\udd00 Switch Statements","text":"<ul> <li>Jump Table: Maps case values to code addresses.  </li> <li> <p>Example: </p>C<pre><code>long my_switch(long x, long y, long z) {\n    long w = 1;\n    switch (x) {\n        case 1: w = y*z; break;\n        case 2: w = y/z; /* Fall through */\n        case 3: w += z; break;\n        case 5: case 6: w -= z; break;\n        default: w = 2;\n    }\n    return w;\n}\n</code></pre> </li> <li> <p>Assembly: </p>GAS<pre><code>my_switch:\n  cmpq $6, %rdi        # Compare x to 6\n  ja .L8               # If x &gt; 6, jump to default\n  jmp *.L4(,%rdi,8)    # Jump via table at .L4 + x*8\n.L3:\n  movq %rsi, %rax      # w = y\n  imulq %rdx, %rax     # w *= z\n  ret\n.L5:\n  movq %rsi, %rax\n  cqto\n  idivq %rcx           # w = y/z\n  jmp .L9\n.L9:\n  addq %rdx, %rax      # w += z\n  ret\n.L7:\n  movq $1, %rax\n  subq %rdx, %rax      # w -= z\n  ret\n.L8:\n  movq $2, %rax        # default: w = 2\n  ret\n</code></pre> </li> </ul>"},{"location":"notes/CSAPP/machine-control/#register-usage-table","title":"\ud83d\udcca Register Usage Table","text":"Register Use(s) <code>%rdi</code> Argument <code>x</code> <code>%rsi</code> Argument <code>y</code> <code>%rdx</code> Argument <code>z</code> <code>%rax</code> Return value <code>w</code>"},{"location":"notes/CSAPP/machine-control/#key-takeaways","title":"\ud83c\udfaf Key Takeaways","text":"<ol> <li>Condition Codes: Set implicitly by arithmetic operations.  </li> <li>Branches: Use <code>jX</code> instructions to control flow.  </li> <li>Loops: Translated into conditional jumps and labels.  </li> <li>Switch Statements: Implemented via jump tables for efficiency.  </li> </ol>"},{"location":"notes/CSAPP/machine-control/#activity-time","title":"\ud83d\udcdd Activity Time!","text":"<ol> <li>Parts 1-4 (Q1-Q6): Practice with condition codes and loops.  </li> <li>Parts 5-6 (Q7-Q11): Explore conditional moves and switch statements.  </li> <li>Canvas Quiz: Complete the Day 4 quiz.  </li> </ol>"},{"location":"notes/CSAPP/machine-data/","title":"6 machine-data","text":""},{"location":"notes/CSAPP/machine-data/#machine-level-programming-iv-data","title":"\ud83d\udcda Machine-Level Programming IV: Data","text":"<p> \u7ea6 226 \u4e2a\u5b57  40 \u884c\u4ee3\u7801  7 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>15-213/15-513: Introduction to Computer Systems 6<sup>th</sup> Lecture, Sept 12, 2024 </p>"},{"location":"notes/CSAPP/machine-data/#arrays","title":"\ud83e\uddee Arrays","text":""},{"location":"notes/CSAPP/machine-data/#one-dimensional-arrays","title":"One-Dimensional Arrays","text":"<ul> <li>Declaration: <code>T name[Length];</code> </li> <li>Contiguously allocated region of <code>Length * sizeof(T)</code> bytes.  </li> <li>Access:  </li> <li>Identifier <code>name</code> acts as a pointer to element 0.  </li> <li>Example: <code>val</code> translates to <code>*(val + 4)</code>.  </li> </ul>"},{"location":"notes/CSAPP/machine-data/#example-array-allocation","title":"Example: Array Allocation","text":"C<pre><code>#define ZLEN 5\ntypedef int zip_dig[ZLEN];\nzip_dig cmu = {1, 5, 2, 1, 3};\n</code></pre> - Memory layout (20-byte block):"},{"location":"notes/CSAPP/machine-data/#multi-dimensional-nested-arrays","title":"Multi-Dimensional (Nested) Arrays","text":"<ul> <li>Declaration: <code>T A[R][C];</code> </li> <li>Row-Major Order: Elements stored row-wise.  </li> <li>Row Access: <code>A[i]</code> starts at <code>A + i * (C * sizeof(T))</code>.  </li> <li>Element Access: <code>A[i][j]</code> address = <code>A + (i * C + j) * sizeof(T)</code>.  </li> </ul>"},{"location":"notes/CSAPP/machine-data/#example-2d-array","title":"Example: 2D Array","text":"C<pre><code>int pgh = {\n  {1,5,2,0,6}, {1,5,2,1,3}, \n  {1,5,2,1,7}, {1,5,2,2,1}\n};\n</code></pre> - Memory layout:"},{"location":"notes/CSAPP/machine-data/#assembly-for-element-access","title":"Assembly for Element Access","text":"Text Only<pre><code># Access pgh[index][dig]\nleaq (%rdi, %rdi, 4), %rax   # 5 * index\naddl %rax, %rsi              # 5*index + dig\nmovl pgh(, %rsi, 4), %eax    # Mem[pgh + 4*(5*index + dig)]\n</code></pre>"},{"location":"notes/CSAPP/machine-data/#multi-level-arrays","title":"Multi-Level Arrays","text":"<ul> <li>Declaration: Array of pointers to arrays. C<pre><code>int* univ = {mit, cmu, ucb};\n</code></pre></li> <li>Memory layout: </li> </ul>"},{"location":"notes/CSAPP/machine-data/#element-access","title":"Element Access","text":"<ul> <li>Requires two memory reads: Text Only<pre><code>salq $2, %rsi              # 4 * digit\naddq univ(,%rdi,8), %rsi   # p = univ[index] + 4*digit\nmovl (%rsi), %eax          # return *p\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-data/#structures","title":"\ud83c\udfd7\ufe0f Structures","text":""},{"location":"notes/CSAPP/machine-data/#memory-allocation-alignment","title":"Memory Allocation &amp; Alignment","text":"<ul> <li>Alignment Rules:  </li> <li>Primitive type of size B must have address multiple of B.  </li> <li>Example: C<pre><code>struct S1 { char c; int i; double v; };\n</code></pre> </li> </ul>"},{"location":"notes/CSAPP/machine-data/#structure-padding-example","title":"Structure Padding Example","text":"C<pre><code>struct S2 { double v; int i; char c; } a;\n</code></pre> - Memory layout (each element padded to 24 bytes):"},{"location":"notes/CSAPP/machine-data/#linked-list-example","title":"Linked List Example","text":"C<pre><code>long length(struct rec *r) {\n  long len = 0L;\n  while (r) { len++; r = r-&gt;next; }\n  return len;\n}\n</code></pre> - Assembly: Text Only<pre><code>.L11:\n  addq $1, %rax        # len++\n  movq 24(%rdi), %rdi  # r = Mem[r + 24]\n  testq %rdi, %rdi\n  jne .L11\n</code></pre>"},{"location":"notes/CSAPP/machine-data/#floating-point","title":"\ud83c\udfaf Floating Point","text":""},{"location":"notes/CSAPP/machine-data/#basics","title":"Basics","text":"<ul> <li>Registers: XMM registers (<code>%xmm0</code>, <code>%xmm1</code>, ...) for FP arguments/results.  </li> <li>Operations: Text Only<pre><code>addss %xmm1, %xmm0   # Single-precision add\naddsd %xmm1, %xmm0   # Double-precision add\n</code></pre></li> </ul>"},{"location":"notes/CSAPP/machine-data/#example-fp-function","title":"Example: FP Function","text":"C<pre><code>double dincr(double *p, double v) {\n  double x = *p;\n  *p = x + v;\n  return x;\n}\n</code></pre> - Assembly: Text Only<pre><code>movapd %xmm0, %xmm1   # Copy v\nmovsd (%rdi), %xmm0   # x = *p\naddsd %xmm0, %xmm1    # t = x + v\nmovsd %xmm1, (%rdi)   # *p = t\n</code></pre>"},{"location":"notes/CSAPP/machine-data/#quiz-examples","title":"\ud83d\udcdd Quiz &amp; Examples","text":""},{"location":"notes/CSAPP/machine-data/#understanding-pointers-arrays-1","title":"Understanding Pointers &amp; Arrays #1","text":"Decl Comp Bad Size A1/A2 Comp Bad Size <code>int A1</code> Y N 12 Y N 4 <code>int *A2</code> Y N 8 Y Y 4"},{"location":"notes/CSAPP/machine-data/#array-access-example","title":"Array Access Example","text":"C<pre><code>int result = pgh + linear_zip + *(linear_zip + 8) + zip2;\n// Result: 9\n</code></pre>"},{"location":"notes/CSAPP/machine-data/#summary","title":"\ud83d\udd0d Summary","text":"<ul> <li>Arrays: Contiguous memory, index arithmetic for access.  </li> <li>Structures: Compiler-managed padding for alignment.  </li> <li>Floating Point: XMM registers and SIMD operations.  </li> </ul> <p>\u26a0\ufe0f Key Reminder: Always consider alignment and pointer arithmetic nuances in low-level code!  </p>"},{"location":"notes/CSAPP/machine-procedures/","title":"5 machine-procedures","text":""},{"location":"notes/CSAPP/machine-procedures/#machine-level-programming-iii-procedures","title":"Machine-Level Programming III: Procedures","text":"<p> \u7ea6 405 \u4e2a\u5b57  41 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>\ud83d\udcc5 15-213/15-513: Introduction to Computer Systems | 5<sup>th</sup> Lecture, Sept 10, 2024 \ud83d\udcd6 Bryant and O\u2019Hallaron, Computer Systems: A Programmer\u2019s Perspective, Third Edition </p>"},{"location":"notes/CSAPP/machine-procedures/#todays-agenda","title":"Today\u2019s Agenda","text":"<ol> <li>Mechanisms in Procedures    - Stack Structure    - Calling Conventions    - Passing Control    - Passing Data    - Managing Local Data  </li> <li>x86-64 Implementation </li> <li>Examples &amp; Activities </li> </ol>"},{"location":"notes/CSAPP/machine-procedures/#mechanisms-in-procedures","title":"Mechanisms in Procedures","text":""},{"location":"notes/CSAPP/machine-procedures/#whats-needed","title":"What\u2019s Needed?","text":"<ul> <li>Passing Control </li> <li>Jump to the beginning of procedure code.  </li> <li>Return to the original point after execution.  </li> <li>Passing Data </li> <li>Procedure arguments.  </li> <li>Return value.  </li> <li>Memory Management </li> <li>Allocate during execution.  </li> <li>Deallocate upon return.  </li> </ul> <p>\ud83d\udccc Key Insight: All mechanisms are implemented via machine instructions, with choices defined by the Application Binary Interface (ABI). </p>"},{"location":"notes/CSAPP/machine-procedures/#x86-64-stack","title":"x86-64 Stack","text":""},{"location":"notes/CSAPP/machine-procedures/#structure-operations","title":"Structure &amp; Operations","text":"<ul> <li>Region of Memory Managed with Stack Discipline:  </li> <li>Grows toward lower addresses.  </li> <li><code>%rsp</code> (Stack Pointer) holds the address of the top element.  </li> </ul>"},{"location":"notes/CSAPP/machine-procedures/#push-operation","title":"Push Operation","text":"GAS<pre><code>pushq Src  \n# 1. Decrement %rsp by 8  \n# 2. Write operand at address %rsp  \n</code></pre>"},{"location":"notes/CSAPP/machine-procedures/#pop-operation","title":"Pop Operation","text":"GAS<pre><code>popq Dest  \n# 1. Read value at %rsp  \n# 2. Increment %rsp by 8  \n# 3. Store value in Dest  \n</code></pre>"},{"location":"notes/CSAPP/machine-procedures/#procedure-control-flow","title":"Procedure Control Flow","text":""},{"location":"notes/CSAPP/machine-procedures/#call-and-return-instructions","title":"Call and Return Instructions","text":"<ul> <li><code>call Label</code>:  </li> <li>Push return address (next instruction) onto the stack.  </li> <li>Jump to <code>Label</code>.  </li> <li><code>ret</code>:  </li> <li>Pop return address from the stack.  </li> <li>Jump to that address.  </li> </ul> <p>\ud83d\udca1 Example: </p>GAS<pre><code># Call example  \n400544: call 400550   # Push return address (400549) and jump to 400550  \n400549: mov %rax, (%rbx)  \n\n# Return example  \n400557: ret           # Pop address 400549 and jump back  \n</code></pre>"},{"location":"notes/CSAPP/machine-procedures/#code-examples","title":"Code Examples","text":""},{"location":"notes/CSAPP/machine-procedures/#example-1-multstore-and-mult2","title":"Example 1: <code>multstore</code> and <code>mult2</code>","text":"<p>C Code: </p>C<pre><code>void multstore(long x, long y, long *dest) {  \n    long t = mult2(x, y);  \n    *dest = t;  \n}  \n\nlong mult2(long a, long b) {  \n    long s = a * b;  \n    return s;  \n}  \n</code></pre> <p>Assembly: | <code>multstore</code> (Caller) | <code>mult2</code> (Callee) | |-----------------------|-------------------| | <code>asm                |</code>asm            | | 400540: push %rbx     | 400550: mov %rdi, %rax | | 400541: mov %rdx, %rbx| 400553: imul %rsi, %rax | | 400544: call 400550   | 400557: ret       | | 400549: mov %rax, (%rbx)|                 | | 40054c: pop %rbx      |                   | | 40054d: ret           |                   | <code>|</code>                |  </p> <p>\ud83d\udcdd Analysis: - <code>multstore</code> saves <code>%rbx</code> (callee-saved register) before calling <code>mult2</code>. - Return value (<code>s</code>) is stored in <code>%rax</code> and written to <code>*dest</code>.  </p>"},{"location":"notes/CSAPP/machine-procedures/#stack-frames-recursion","title":"Stack Frames &amp; Recursion","text":""},{"location":"notes/CSAPP/machine-procedures/#stack-frame-structure","title":"Stack Frame Structure","text":"<ul> <li>Contents:  </li> <li>Return address.  </li> <li>Local variables.  </li> <li>Saved registers.  </li> <li>Temporary storage.  </li> </ul>"},{"location":"notes/CSAPP/machine-procedures/#recursive-example","title":"Recursive Example","text":"C<pre><code>long pcount_r(unsigned long x) {  \n    if (x == 0) return 0;  \n    else return (x &amp; 1) + pcount_r(x &gt;&gt; 1);  \n}  \n</code></pre> <p>Assembly: </p>GAS<pre><code>pcount_r:  \n    movl $0, %eax  \n    testq %rdi, %rdi  \n    je .L6  \n    pushq %rbx  \n    movq %rdi, %rbx  \n    andl $1, %ebx  \n    shrq %rdi  \n    call pcount_r  \n    addq %rbx, %rax  \n    popq %rbx  \n.L6:  \n    rep; ret  \n</code></pre> <p>\ud83d\udccc Key Observations: - Recursion uses stack frames for isolation. - <code>%rbx</code> (callee-saved) preserves intermediate values across calls.  </p>"},{"location":"notes/CSAPP/machine-procedures/#register-usage-conventions","title":"Register Usage Conventions","text":""},{"location":"notes/CSAPP/machine-procedures/#x86-64-linux-register-roles","title":"x86-64 Linux Register Roles","text":"Register Role Saved By <code>%rax</code> Return value Caller <code>%rdi-%r9</code> Arguments Caller <code>%rbx, %r12-15</code> Callee-saved Callee <code>%rsp</code> Stack pointer Callee <p>\u26a0\ufe0f Note: Callee-saved registers must be preserved across function calls! </p>"},{"location":"notes/CSAPP/machine-procedures/#activity-time","title":"Activity Time!","text":""},{"location":"notes/CSAPP/machine-procedures/#activity-2-problems-6-9","title":"Activity 2: Problems 6-9","text":"<ol> <li>Setup: Bash<pre><code>wget http://www.cs.cmu.edu/~213/activities/machine-procedures.pdf  \nwget http://www.cs.cmu.edu/~213/activities/machine-procedures.tar  \ntar xf machine-procedures.tar  \ncd machine-procedures  \n</code></pre></li> <li>Tasks:    - Analyze stack behavior during nested calls.    - Trace register usage in recursive functions.  </li> </ol>"},{"location":"notes/CSAPP/machine-procedures/#quiz-time","title":"Quiz Time!","text":""},{"location":"notes/CSAPP/machine-procedures/#sample-question","title":"Sample Question","text":"<p>Q: What happens if you call <code>mult2(y, x)</code> instead of <code>mult2(x, y)</code> in <code>multstore</code>?  </p> <p>A: The arguments <code>x</code> and <code>y</code> are passed in <code>%rdi</code> and <code>%rsi</code>, respectively. Swapping them would reverse the multiplication order (e.g., <code>y * x</code> instead of <code>x * y</code>), but the result remains the same due to commutativity.  </p>"},{"location":"notes/CSAPP/machine-procedures/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Stack Discipline ensures proper nested execution and memory management.  </li> <li>Calling Conventions (caller/callee-saved registers) prevent data corruption.  </li> <li>Recursion leverages stack isolation for multiple instantiations.  </li> </ul> <p>\ud83d\ude80 Next: Dive into buffer overflows and advanced stack manipulation! </p>"},{"location":"notes/CSAPP/memory-hierarchy/","title":"9 memory-hierarchy","text":""},{"location":"notes/CSAPP/memory-hierarchy/#memory-hierarchy-lecture-notes","title":"Memory Hierarchy - Lecture Notes \ud83d\udcda","text":"<p> \u7ea6 600 \u4e2a\u5b57  14 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/CSAPP/memory-hierarchy/#key-concepts","title":"Key Concepts \ud83e\udde0","text":""},{"location":"notes/CSAPP/memory-hierarchy/#the-cpu-memory-gap","title":"The CPU-Memory Gap \u26a1","text":"<ul> <li>Problem: Widening gap between CPU speed and memory/disk access times.</li> <li>Memory Wall/Von Neumann Bottleneck: Performance gap between computation speed and data storage.</li> <li>Solutions:</li> <li>Memory Hierarchy (Covered in 213)</li> <li>Parallelism (346, 418)</li> <li>Computation Migration (346, 7xx?)</li> </ul>"},{"location":"notes/CSAPP/memory-hierarchy/#memory-abstraction","title":"Memory Abstraction \ud83c\udfd7\ufe0f","text":""},{"location":"notes/CSAPP/memory-hierarchy/#ram-random-access-memory","title":"RAM (Random-Access Memory) \ud83d\udcbe","text":"<ul> <li>Key Features:</li> <li>Packaged as a chip or embedded in processors.</li> <li>Basic unit: cell (1 bit per cell).</li> <li>Varieties:<ul> <li>SRAM (Static RAM): </li> <li>6-8 transistors/bit.</li> <li>Faster (1x access time), no refresh needed.</li> <li>Expensive (100x DRAM cost).</li> <li>Used for cache memories.</li> <li>DRAM (Dynamic RAM):</li> <li>1 transistor + 1 capacitor/bit.</li> <li>Slower (10x access time), requires periodic refresh.</li> <li>Cheaper (1x DRAM cost).</li> <li>Used for main memories and frame buffers.</li> </ul> </li> </ul> Feature SRAM DRAM Transistors/bit 6-8 1 Access Time 1x 10x Refresh Needed? No Yes Cost 100x 1x Applications Cache Main Memory"},{"location":"notes/CSAPP/memory-hierarchy/#locality-of-reference","title":"Locality of Reference \ud83c\udfaf","text":"<ul> <li>Principle: Programs tend to access data/instructions near recently used addresses.</li> <li>Types:   1. Temporal Locality: Recently used items are likely to be reused soon.<ul> <li>Example: Loop variable <code>sum</code> accessed repeatedly.   2. Spatial Locality: Nearby addresses are accessed close in time.</li> <li>Example: Iterating through an array in stride-1 pattern.</li> </ul> </li> </ul>"},{"location":"notes/CSAPP/memory-hierarchy/#example-1-locality-analysis","title":"Example 1: Locality Analysis \ud83d\udd0d","text":"C<pre><code>int sum_array_rows(int a[M][N]) {\n    int sum = 0;\n    for (int i = 0; i &lt; M; i++)\n        for (int j = 0; j &lt; N; j++)\n            sum += a[i][j];\n    return sum;\n}\n</code></pre> - Locality:    - Spatial: Array accessed in row-major order (stride-1).   - Temporal: Variable <code>sum</code> accessed each iteration. - Answer: \u2705 Good locality (both spatial and temporal)."},{"location":"notes/CSAPP/memory-hierarchy/#example-2-poor-locality","title":"Example 2: Poor Locality \u274c","text":"C<pre><code>int sum_array_cols(int a[M][N]) {\n    int sum = 0;\n    for (int j = 0; j &lt; N; j++)\n        for (int i = 0; i &lt; M; i++)\n            sum += a[i][j];\n    return sum;\n}\n</code></pre> - Locality:    - Stride-N pattern (non-contiguous memory access).   - Answer: \u274c Poor locality unless <code>M</code> is very small."},{"location":"notes/CSAPP/memory-hierarchy/#memory-hierarchy","title":"Memory Hierarchy \ud83d\uddc3\ufe0f","text":"<ul> <li>Goal: Create an illusion of large, fast memory using smaller, faster storage layers.</li> <li>Caches:</li> <li>Faster, smaller storage acting as a staging area for slower, larger storage.</li> <li>Hit: Data found in cache.</li> <li>Miss: Data fetched from lower levels.</li> <li>Types of Misses:<ol> <li>Cold (Compulsory) Miss: First access to a block.</li> <li>Capacity Miss: Working set exceeds cache size.</li> <li>Conflict Miss: Data maps to same cache block (e.g., blocks 0, 8, 0, 8...).</li> </ol> </li> </ul>"},{"location":"notes/CSAPP/memory-hierarchy/#cache-types","title":"Cache Types \ud83d\udce6","text":"Cache Type Cached Location Latency (cycles) Managed By Registers 4-8 byte words CPU core 0 Compiler L1 Cache 64-byte blocks On-Chip L1 4 Hardware L2 Cache 64-byte blocks On-Chip L2 10 Hardware Virtual Memory 4-KB pages Main Memory 100 Hardware + OS Disk Cache Disk sectors Disk Controller 100,000 Disk Firmware"},{"location":"notes/CSAPP/memory-hierarchy/#storage-technologies","title":"Storage Technologies \ud83d\udcbd","text":""},{"location":"notes/CSAPP/memory-hierarchy/#magnetic-disks","title":"Magnetic Disks \ud83d\udee0\ufe0f","text":"<ul> <li>Components:</li> <li>Platters, tracks, sectors.</li> <li>Access Time:<ul> <li>Seek Time: Position head over cylinder (3-9 ms).</li> <li>Rotational Latency: Wait for sector to rotate under head (4 ms @ 7200 RPM).</li> <li>Transfer Time: Read data (0.02 ms for 400 sectors/track).</li> </ul> </li> </ul> <p>Example: Disk Access Time Calculation \u23f3 - Given: 7200 RPM, 9 ms seek time, 400 sectors/track. - Total Access Time: </p>Text Only<pre><code>T_avg = 9 ms (seek) + 4 ms (rotation) + 0.02 ms (transfer) = 13.02 ms\n</code></pre>"},{"location":"notes/CSAPP/memory-hierarchy/#ssds-vs-hdds","title":"SSDs vs HDDs \ud83d\udd04","text":"Feature SSD HDD Speed Faster (no moving parts) Slower (mechanical latency) Durability Limited writes (wear leveling) No wear-out from writes Cost 1.67x more expensive (2023) Cheaper bulk storage"},{"location":"notes/CSAPP/memory-hierarchy/#memory-mountain","title":"Memory Mountain \ud83c\udfd4\ufe0f","text":"<ul> <li>Read Throughput: Measures bandwidth (MB/s) as a function of spatial/temporal locality.</li> <li>Core i7 Haswell Results:</li> <li>L1: 32 KB, 4 cycles.</li> <li>L2: 256 KB, 10 cycles.</li> <li>L3: 8 MB, 40-75 cycles.</li> <li>Key Insight: Larger strides reduce spatial locality, lowering throughput.</li> </ul>"},{"location":"notes/CSAPP/memory-hierarchy/#trends","title":"Trends \ud83d\udcc8","text":"<ul> <li>SRAM/DRAM Scaling:</li> <li>SRAM limited by transistor density.</li> <li>DRAM limited by capacitor aspect ratio.</li> <li>Storage:</li> <li>Flash memory advancing faster than DRAM/HDD.</li> <li>3D NAND allows stacking cells vertically (100+ layers).</li> </ul>"},{"location":"notes/CSAPP/memory-hierarchy/#historical-data","title":"Historical Data \ud83d\udcca","text":"Year SRAM $/MB DRAM $/MB Disk $/GB 1985 $2,900 $880 $100,000 2015 $320 $0.02 $0.03"},{"location":"notes/CSAPP/memory-hierarchy/#quiz-time","title":"Quiz Time! \ud83e\udde9","text":"<ol> <li> <p>Q: Which RAM type uses capacitors? A: DRAM (Dynamic RAM).</p> </li> <li> <p>Q: What type of cache miss occurs due to limited cache size? A: Capacity miss.</p> </li> <li> <p>Q: Which loop permutation improves spatial locality in a 3D array? A: Inner loop iterates over contiguous memory (e.g., <code>for j</code> inner loop).</p> </li> </ol> <p>Source: Bryant and O'Hallaron, Computer Systems: A Programmer's Perspective, Third Edition \ud83d\udcd6</p>"},{"location":"notes/CSAPP/overview/","title":"1 overview","text":""},{"location":"notes/CSAPP/overview/#15-21314-51315-513-introduction-to-computer-systems","title":"15-213/14-513/15-513: Introduction to Computer Systems","text":"<p> \u7ea6 362 \u4e2a\u5b57  11 \u884c\u4ee3\u7801  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>1<sup>st</sup> Lecture, Aug 27, 2024 </p>"},{"location":"notes/CSAPP/overview/#instructors","title":"\ud83d\udccc Instructors","text":"<ul> <li>15-213/15-513:   \ud83e\uddd1\ud83c\udfeb Phil Gibbons   \ud83e\uddd1\ud83d\udcbb Brian Railing  </li> <li>14-513:   \ud83e\uddd1\ud83c\udfeb Mohamed Farag   \ud83e\uddd1\ud83d\udcbb David Varodayan  </li> </ul>"},{"location":"notes/CSAPP/overview/#course-theme-systems-knowledge-is-power","title":"\ud83c\udfaf Course Theme: Systems Knowledge is Power!","text":""},{"location":"notes/CSAPP/overview/#key-outcomes","title":"Key Outcomes:","text":"<ol> <li>Become a better programmer:    - Find and eliminate bugs efficiently.    - Understand and tune program performance.  </li> <li>Prepare for advanced systems courses:    - Compilers, OS, Networks, Computer Architecture, Embedded Systems, etc.  </li> </ol>"},{"location":"notes/CSAPP/overview/#the-five-great-realities","title":"\ud83c\udf1f The Five Great Realities","text":""},{"location":"notes/CSAPP/overview/#great-reality-1-ints-integers-floats-reals","title":"Great Reality #1: Ints \u2260 Integers, Floats \u2260 Reals","text":""},{"location":"notes/CSAPP/overview/#example-1-is-x2-geq-0","title":"Example 1: Is \\( x^2 \\geq 0 \\)?","text":"<ul> <li>Floats: Always true.  </li> <li>Ints:  </li> <li>\\( 40000 \\times 40000 = 1600000000 \\) \u2705  </li> <li>\\( 50000 \\times 50000 = \\) Overflow \u274c (Result: \\(-2147483648\\) for 32-bit ints).  </li> </ul>"},{"location":"notes/CSAPP/overview/#example-2-is-x-y-z-x-y-z","title":"Example 2: Is \\( (x + y) + z = x + (y + z) \\)?","text":"<ul> <li>Ints: \u2705 (Associative).  </li> <li>Floats: \u274c  </li> <li>\\( (1e20 + -1e20) + 3.14 = 3.14 \\) </li> <li>\\( 1e20 + (-1e20 + 3.14) = 0 \\) (Catastrophic cancellation due to limited precision).  </li> </ul>"},{"location":"notes/CSAPP/overview/#great-reality-2-you-must-know-assembly","title":"Great Reality #2: You Must Know Assembly","text":"<ul> <li>Why? </li> <li>Debugging: High-level abstractions break down.  </li> <li>Performance tuning: Understand compiler optimizations.  </li> <li>System software: Compilers/OS rely on assembly.  </li> <li>Focus: x86 assembly.  </li> </ul>"},{"location":"notes/CSAPP/overview/#great-reality-3-memory-matters","title":"Great Reality #3: Memory Matters","text":""},{"location":"notes/CSAPP/overview/#memory-referencing-bug-example","title":"Memory Referencing Bug Example:","text":"C<pre><code>typedef struct {  \n    int a;  \n    double d;  \n} struct_t;  \n\ndouble fun(int i) {  \n    volatile struct_t s;  \n    s.d = 3.14;  \n    s.a[i] = 1073741824;  // Out-of-bounds access  \n    return s.d;  \n}  \n</code></pre> Results: - <code>fun(0)</code> \u2192 <code>3.14</code> \u2705 - <code>fun(3)</code> \u2192 <code>2.00000061035156</code> \u274c (Corrupted memory)."},{"location":"notes/CSAPP/overview/#great-reality-4-performance-asymptotic-complexity","title":"Great Reality #4: Performance \u2260 Asymptotic Complexity","text":"<ul> <li>Constant factors matter! </li> <li>Example: Loop unrolling, cache locality.  </li> <li>Memory Hierarchy:  </li> <li>L1/L2 cache vs. RAM vs. Disk (4.3ms vs. 81.8ms access time).  </li> </ul>"},{"location":"notes/CSAPP/overview/#great-reality-5-computers-do-more-than-execute-programs","title":"Great Reality #5: Computers Do More Than Execute Programs","text":"<ul> <li>I/O and Networking:  </li> <li>Concurrency, unreliable media, cross-platform issues.  </li> <li>Example: Web proxy lab (L7) \u2192 Handle HTTP requests concurrently.  </li> </ul>"},{"location":"notes/CSAPP/overview/#course-components","title":"\ud83d\udcda Course Components","text":""},{"location":"notes/CSAPP/overview/#labs-50-of-grade","title":"Labs (50% of Grade)","text":"<ol> <li>Data Lab: Bit manipulation.  </li> <li>Bomb Lab: Reverse engineering.  </li> <li>Attack Lab: Code injection.  </li> <li>Cache Lab: Optimize memory locality.  </li> <li>Malloc Lab: Implement <code>malloc</code>/<code>free</code>.  </li> <li>Shell Lab: Build a Unix shell.  </li> </ol>"},{"location":"notes/CSAPP/overview/#written-assignments-20","title":"Written Assignments (20%)","text":"<ul> <li>Peer-reviewed problem sets (drop lowest 2).  </li> </ul>"},{"location":"notes/CSAPP/overview/#final-exam-30","title":"Final Exam (30%)","text":"<ul> <li>Covers all course concepts.  </li> </ul>"},{"location":"notes/CSAPP/overview/#academic-integrity","title":"\u26a0\ufe0f Academic Integrity","text":""},{"location":"notes/CSAPP/overview/#cheating-examples","title":"Cheating Examples:","text":"<ul> <li>\u274c Copying code from peers/web.  </li> <li>\u274c Using AI tools (ChatGPT, Copilot) for solutions.  </li> <li>\u274c Reusing old code.  </li> </ul>"},{"location":"notes/CSAPP/overview/#consequences","title":"Consequences:","text":"<ul> <li>Failing grade, expulsion, or retroactive penalties.  </li> </ul>"},{"location":"notes/CSAPP/overview/#allowed","title":"Allowed:","text":"<ul> <li>\u2705 Discuss high-level design.  </li> <li>\u2705 Use textbook/CS:APP code (with attribution).  </li> </ul>"},{"location":"notes/CSAPP/overview/#lab-policies","title":"\ud83d\udcbb Lab Policies","text":"<ul> <li>Grace Days: 5 per semester (max 2 per lab).  </li> <li>Late Penalty: 15% per day after grace days.  </li> </ul>"},{"location":"notes/CSAPP/overview/#textbooks","title":"\ud83d\udcd6 Textbooks","text":"<ol> <li>Primary: Computer Systems: A Programmer\u2019s Perspective (Bryant &amp; O\u2019Hallaron).  </li> <li>Recommended: The C Programming Language (K&amp;R).  </li> </ol>"},{"location":"notes/CSAPP/overview/#tools-infrastructure","title":"\ud83d\udee0\ufe0f Tools &amp; Infrastructure","text":"<ul> <li>Shark Machines: <code>ssh shark.ics.cs.cmu.edu</code>.  </li> <li>Autolab: Submit labs, view scoreboards.  </li> </ul>"},{"location":"notes/CSAPP/overview/#key-advice","title":"\ud83d\ude80 Key Advice","text":"<ul> <li>Start labs early!  </li> <li>Commit code frequently (Git history matters).  </li> <li>Attend bootcamps (GDB, Makefiles, C debugging).  </li> </ul>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/","title":"3 Convex Hull&Median Finding","text":""},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#lecture-2-divide-and-conquer","title":"Lecture 2: Divide and Conquer","text":"<p> \u7ea6 473 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#paradigm","title":"Paradigm","text":"<ul> <li>Given: A problem of size \\(n\\).  </li> <li>Divide it into subproblems of size \\(\\frac{n}{b}\\), where \\(a \\geq 1\\), \\(b &gt; 1\\).  </li> <li>Solve each subproblem recursively.  </li> <li>Combine solutions to form the overall solution.  </li> </ul> <p>Recurrence Relation: $$ T(n) = a T\\left(\\frac{n}{b}\\right) + [\\text{work for merge}] $$</p>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#convex-hull","title":"Convex Hull","text":""},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#problem-definition","title":"Problem Definition","text":"<ul> <li>Input: \\(n\\) points in the plane:   $$   S = \\left{ (x_i, y_i) \\mid i = 1, 2, \\ldots, n \\right}   $$  </li> <li>Assumptions: No two points share the same \\(x\\)- or \\(y\\)-coordinate; no three points are colinear.  </li> <li>Output: Convex Hull \\(\\text{CH}(S)\\), the smallest polygon containing all points in \\(S\\).  </li> </ul>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#brute-force-approach","title":"Brute Force Approach","text":"<ul> <li>Test each line segment to determine if it is an edge of the convex hull:  </li> <li>If all other points lie on one side of the segment, the segment is part of the convex hull.  </li> <li>Complexity: \\(O(n^3)\\) (testing \\(O(n^2)\\) edges with \\(O(n)\\) checks per edge).  </li> </ul>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#divide-and-conquer-approach","title":"Divide and Conquer Approach","text":"<ol> <li>Sort points by \\(x\\)-coordinate (\\(O(n \\log n)\\)).  </li> <li>Divide \\(S\\) into left half \\(A\\) and right half \\(B\\).  </li> <li>Recursively compute \\(\\text{CH}(A)\\) and \\(\\text{CH}(B)\\).  </li> <li>Merge the two convex hulls.  </li> </ol>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#merge-step","title":"Merge Step","text":"<ol> <li>Find Upper Tangent \\((a_i, b_j)\\) and Lower Tangent \\((a_k, b_m)\\).  </li> <li>Link \\(a_i \\rightarrow b_j\\), traverse down \\(B\\) to \\(b_m\\), link \\(b_m \\rightarrow a_k\\), and return to \\(a_i\\).  </li> </ol> <p>Example:  - Upper Tangent: \\((a_4, b_2)\\). - Lower Tangent: \\((a_3, b_3)\\). - Merged Hull: \\((a_4, b_2, b_3, a_3)\\).  </p>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#finding-tangents","title":"Finding Tangents","text":"<ul> <li>Upper Tangent: Maximizes \\(y(i, j)\\), where \\(y(i, j)\\) is the \\(y\\)-coordinate of the intersection between the vertical separating line \\(L\\) and segment \\((a_i, b_j)\\).  </li> <li>Algorithm:   1. Initialize \\(i = 1\\), \\(j = 1\\).   2. While \\(y(i, j+1) &gt; y(i, j)\\) or \\(y(i-1, j) &gt; y(i, j)\\):<ul> <li>If \\(y(i, j+1) &gt; y(i, j)\\): \\(j = j + 1 \\mod q\\).</li> <li>Else: \\(i = i - 1 \\mod p\\).   3. Return \\((a_i, b_j)\\).</li> </ul> </li> <li>Time Complexity:   $$   T(n) = 2 T\\left(\\frac{n}{2}\\right) + \\Theta(n) = \\Theta(n \\log n)   $$</li> </ul>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#median-finding","title":"Median Finding","text":""},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#problem-definition_1","title":"Problem Definition","text":"<ul> <li>Rank of \\(x\\): Number of elements \\(\\leq x\\).  </li> <li>Goal: Find element with rank \\(\\left\\lfloor\\frac{n+1}{2}\\right\\rfloor\\) (lower median) or \\(\\left\\lceil\\frac{n+1}{2}\\right\\rceil\\) (upper median).  </li> </ul>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#algorithm-select","title":"Algorithm: SELECT","text":"<ol> <li>Pick \\(x \\in S\\) cleverly (median of medians).  </li> <li>Partition \\(S\\) into \\(B = \\{y \\in S \\mid y &lt; x\\}\\) and \\(C = \\{y \\in S \\mid y &gt; x\\}\\).  </li> <li>Recurse on \\(B\\) or \\(C\\) based on \\(k = \\text{rank}(x)\\):    - If \\(k = i\\), return \\(x\\).    - If \\(k &gt; i\\), return \\(\\text{SELECT}(B, i)\\).    - If \\(k &lt; i\\), return \\(\\text{SELECT}(C, i - k)\\).  </li> </ol>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#median-of-medians","title":"Median of Medians","text":"<ol> <li>Arrange \\(S\\) into columns of size 5.  </li> <li>Sort each column (linear time).  </li> <li>Recursively compute the median of medians.  </li> </ol> <p>Recurrence: $$ T(n) =  \\begin{cases} O(1), &amp; \\text{for } n \\leq 140, \\ T\\left(\\left\\lceil\\frac{n}{5}\\right\\rceil\\right) + T\\left(\\frac{7n}{10} + 6\\right) + \\Theta(n), &amp; \\text{for } n &gt; 140. \\end{cases} $$</p> <p>Proof Sketch: $$ T(n) \\leq cn \\quad \\text{(by induction, using } \\frac{n}{5} + \\frac{7n}{10} &lt; n\\text{)}. $$</p>"},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#appendix","title":"Appendix","text":""},{"location":"notes/MIT6.046/Convex%20Hull%26Median%20Finding/#example-tangent-identification","title":"Example: Tangent Identification","text":"<p> - Upper Tangent: \\(a_3, b_1\\). - Lower Tangent: \\(a_1, b_3\\). - Note: Tangents need not involve the highest/lowest points.  </p>"},{"location":"notes/MIT6.046/FFT/","title":"2 FFT","text":""},{"location":"notes/MIT6.046/FFT/#polynomial-operations-and-representation","title":"Polynomial Operations and Representation","text":"<p> \u7ea6 496 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>A polynomial \\(A(x)\\) can be written in the following forms: $$ \\begin{aligned} A(x) &amp;= a_0 + a_1x + a_2x^2 + \\cdots + a_{n-1}x^{n-1}   \\\\ &amp;= \\sum_{k=0}^{n-1} a_k x^k   \\\\ &amp;= \\left\\langle a_0, a_1, a_2, \\ldots, a_{n-1} \\right\\rangle \\quad \\text{(coefficient vector)} \\end{aligned} $$</p>"},{"location":"notes/MIT6.046/FFT/#the-degree-of-a-is-n-1","title":"The degree of \\(A\\) is \\(n-1\\)","text":""},{"location":"notes/MIT6.046/FFT/#operations-on-polynomials","title":"Operations on Polynomials","text":"<ol> <li> <p>Evaluation: Given \\( A(x) \\) and \\( x_0 \\), compute \\( A(x_0) \\).    - Horner's Rule:      $$      A(x) = a_0 + x\\left(a_1 + x\\left(a_2 + \\cdots + x\\left(a_{n-1}\\right)\\cdots\\right)\\right)      $$ Time: \\( O(n) \\).</p> </li> <li> <p>Addition: \\( C(x) = A(x) + B(x) \\).    - \\( c_k = a_k + b_k \\). Time: \\( O(n) \\).</p> </li> <li> <p>Multiplication: \\( C(x) = A(x) \\cdot B(x) \\).    - \\( c_k = \\sum_{j=0}^k a_j b_{k-j} \\).    - Naive Time: \\( O(n^2) \\).    - FFT Time: \\( O(n \\log n) \\).</p> </li> </ol>"},{"location":"notes/MIT6.046/FFT/#representations-of-polynomials","title":"Representations of Polynomials","text":"Representation Evaluation Addition Multiplication Coefficients \\( O(n) \\) \\( O(n) \\) \\( O(n^2) \\) Roots \\( O(n) \\) Impossible \\( O(n) \\) Samples \\( O(n^2) \\) \\( O(n) \\) \\( O(n) \\) <p>Key Insight: Convert between coefficients and samples in \\( O(n \\log n) \\) time using FFT.</p>"},{"location":"notes/MIT6.046/FFT/#divide-and-conquer-algorithm-for-polynomial-multiplication","title":"Divide and Conquer Algorithm for Polynomial Multiplication","text":"<ol> <li> <p>Divide: Split \\( A(x) \\) into even and odd coefficients:    $$    \\begin{aligned}    A_{\\text{even}}(x) &amp;= \\sum_{k=0}^{\\lceil n/2 \\rceil -1} a_{2k} x^k, \\\\    A_{\\text{odd}}(x) &amp;= \\sum_{k=0}^{\\lfloor n/2 \\rfloor -1} a_{2k+1} x^k.    \\end{aligned}    $$</p> </li> <li> <p>Conquer: Recursively compute \\( A_{\\text{even}}(y) \\) and \\( A_{\\text{odd}}(y) \\) for \\( y \\in X^2 \\).  </p> </li> <li> <p>Combine:    $$    A(x) = A_{\\text{even}}(x^2) + x \\cdot A_{\\text{odd}}(x^2)    $$</p> </li> </ol> <p>Recurrence: $$ T(n) = 2T\\left(\\frac{n}{2}\\right) + O(n) = O(n \\log n) $$</p>"},{"location":"notes/MIT6.046/FFT/#roots-of-unity","title":"Roots of Unity","text":"<p>Definition: The \\(n\\) -th roots of unity are \\(x\\) such that \\(x^n = 1\\). They are spaced uniformly on the unit circle in the complex plane: $$ x_k = e^{i \\tau k / n}, \\quad k = 0, 1, \\ldots, n - 1 \\quad (\\tau = 2\\pi) $$</p> <p>Collapsing Property: For \\(n = 2^\\ell\\), squaring the roots reduces the problem size by half: $$ \\left(e^{i \\tau k / n}\\right)^2 = e^{i \\tau k / (n/2)} $$</p>"},{"location":"notes/MIT6.046/FFT/#fft-and-ifft","title":"FFT and IFFT","text":""},{"location":"notes/MIT6.046/FFT/#fast-fourier-transform-fft","title":"Fast Fourier Transform (FFT)","text":"<ul> <li>DFT: Convert coefficients to samples using roots of unity:  </li> </ul> \\[ A^* = V \\cdot A \\quad \\text{where } V_{jk} = e^{i \\tau jk / n} \\] <ul> <li>Time: \\(O(n \\log n)\\)</li> </ul>"},{"location":"notes/MIT6.046/FFT/#inverse-fft-ifft","title":"Inverse FFT (IFFT)","text":"<ul> <li>IDFT: Convert samples back to coefficients:  </li> </ul> \\[ A = \\frac{1}{n} \\bar{V} \\cdot A^* \\] <ul> <li>Time: \\(O(n \\log n)\\)</li> </ul>"},{"location":"notes/MIT6.046/FFT/#polynomial-multiplication-via-fft","title":"Polynomial Multiplication via FFT","text":"<p>Steps:  </p> <ol> <li>Compute \\(A^*= \\text{FFT}(A)\\) and \\(B^* = \\text{FFT}(B)\\).  </li> <li>Multiply samples: \\(C^*= A^* \\cdot B^*\\).  </li> <li>Convert back: \\(C = \\text{IFFT}(C^*)\\).  </li> </ol> <p>Example:  </p> <ul> <li>Let \\(A(x) = 1 + 2x\\) and \\(B(x) = 3 + 4x\\).  </li> <li>FFT:  </li> <li>\\(A^*= [3, -1]\\), \\(B^* = [7, -1]\\).  </li> <li>Multiply: \\(C^* = [21, 1]\\).  </li> <li>IFFT: \\(C(x) = 3 + 10x + 8x^2\\).  </li> </ul> <p>Analysis:  </p> <ul> <li>Naive multiplication: \\(O(n^2) = O(4)\\).  </li> <li>FFT - based: \\(O(n \\log n) = O(2 \\log 2)\\).  </li> </ul>"},{"location":"notes/MIT6.046/FFT/#applications-of-fft","title":"Applications of FFT","text":"<ul> <li>Signal Processing: Filtering, compression (MP3), spectral analysis.  </li> <li>Algorithm Design: Convolution, large integer multiplication.  </li> </ul>"},{"location":"notes/MIT6.046/Interval%20Scheduling/","title":"1 Interval Scheduling","text":""},{"location":"notes/MIT6.046/Interval%20Scheduling/#course-overview","title":"Course Overview","text":"<p> \u7ea6 403 \u4e2a\u5b57  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <ul> <li>Modules Covered:   1. Divide and Conquer (FFT, Randomized algorithms)   2. Optimization (greedy, dynamic programming)   3. Network Flow   4. Intractibility and coping strategies   5. Linear Programming   6. Sublinear and Approximation Algorithms   7. Advanced Topics</li> </ul>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#key-complexity-classes","title":"Key Complexity Classes","text":"<ul> <li>P: Solvable in polynomial time (e.g., shortest paths in \\(O(V^2)\\)).</li> <li>NP: Verifiable in polynomial time (e.g., Hamiltonian Cycle detection is NP-complete, but verification is easy).</li> <li>NP-Complete: A problem in NP that is as hard as any problem in NP. Solving one in polynomial time would solve all NP problems.</li> </ul>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#interval-scheduling","title":"Interval Scheduling","text":"<p>Problem: Select a maximum subset of non-overlapping requests. Each request has: - Start time \\(s(i)\\) - Finish time \\(f(i)\\) (with \\(s(i) &lt; f(i)\\))  </p> <p>Compatibility: Two requests \\(i\\) and \\(j\\) are compatible if: \\(\\(f(i) \\leq s(j) \\quad \\text{or} \\quad f(j) \\leq s(i)\\)\\)</p> <p>Example:  Requests 2 &amp; 3 are compatible; 4, 5, 6 are compatible; 2 &amp; 4 are not.</p>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#greedy-algorithms-for-interval-scheduling","title":"Greedy Algorithms for Interval Scheduling","text":"<p>Claim: Greedy algorithm with earliest finish time yields an optimal solution.  </p>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#possible-greedy-rules","title":"Possible Greedy Rules:","text":"<ol> <li> <p>Earliest Start Time Fails for overlapping long intervals.</p> </li> <li> <p>Smallest Interval Fails if small intervals block larger compatible ones.</p> </li> <li> <p>Fewest Conflicts Computationally expensive to track conflicts.</p> </li> <li> <p>Earliest Finish Time Optimal.</p> </li> </ol>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#proof-of-optimality-for-earliest-finish-time","title":"Proof of Optimality for Earliest Finish Time","text":"<p>Inductive Proof: - Base Case: \\(k^* = 1\\) \u2013 trivial. - Inductive Step: Assume optimality holds for \\(k^*\\). For \\(k^* + 1\\):   - Let \\(S^*\\) be the optimal schedule. Greedy picks \\(i_1\\) with \\(f(i_1) \\leq f(j_1)\\).   - Construct \\(S^{**} = \\{i_1, j_2, \\ldots, j_{k^*+1}\\}\\), which is also optimal.   - Residual problem \\(L'\\) (intervals after \\(f(i_1)\\)) has optimal size \\(k^*\\). By induction, greedy on \\(L'\\) gives \\(k^*\\) intervals.   - Total schedule size: \\(1 + k^* = k^* + 1\\).  </p>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#weighted-interval-scheduling","title":"Weighted Interval Scheduling","text":"<p>Problem: Maximize total weight of non-overlapping requests. - Greedy fails due to weights. - Dynamic Programming Approach:   Define \\(R^x = \\{j \\mid s(j) \\geq x\\}\\). Recurrence: \\(\\(\\text{opt}(R) = \\max_{1 \\leq i \\leq n} \\left( w(i) + \\text{opt}(R^{f(i)}) \\right)\\)\\)   - Time: \\(O(n^2)\\) (can be optimized to \\(O(n \\log n)\\)).  </p>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#non-identical-machines","title":"Non-Identical Machines","text":"<p>Problem: Schedule jobs on \\(m\\) machines where each job \\(i\\) can only run on a subset \\(Q(i) \\subseteq \\{T_1, \\ldots, T_m\\}\\). - Complexity:   - Decision version (\"Can \\(k \\leq n\\) jobs be scheduled?\") is NP-Complete.   - Optimization version (\"Maximize scheduled jobs\") is NP-Hard.  </p>"},{"location":"notes/MIT6.046/Interval%20Scheduling/#coping-with-intractability","title":"Coping with Intractability","text":"<ol> <li>Approximation Algorithms: Guarantee near-optimal solutions in polynomial time.  </li> <li>Pruning Heuristics: Reduce search space for practical instances.  </li> <li>Greedy Heuristics: No guarantees but perform well empirically.  </li> </ol>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/","title":"4 van Emde Boas Trees","text":""},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#lecture-4-divide-and-conquer-van-emde-boas-trees","title":"Lecture 4: Divide and Conquer: van Emde Boas Trees","text":"<p> \u7ea6 780 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#series-of-improved-data-structures","title":"Series of Improved Data Structures","text":"<ul> <li>Insert, Successor</li> <li>Delete</li> <li>Space</li> </ul> <p>This lecture is based on personal communication with Michael Bender, 2001.</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#goal","title":"Goal","text":"<p>We want to maintain <code>n</code> elements in the range <code>{0, 1, 2, ..., u-1}</code> and perform Insert, Delete, and Successor operations in <code>O(log log u)</code> time.</p> <ul> <li>If <code>n = n^O(1)</code> or <code>n^(log n)^O(1)</code>, then we have <code>O(log log n)</code> time operations.</li> <li>Exponentially faster than Balanced Binary Search Trees.</li> <li>Cooler queries than hashing.</li> <li>Application: Network Routing Tables.</li> </ul> \\[ u = \\text{Range of IP Addresses} \\rightarrow \\text{port to send} \\quad (u = 2^{32} \\text{ in IPv4)} \\] <p>Where might the <code>O(log log u)</code> bound arise? - Binary search over <code>O(log u)</code> elements. - Recurrences:</p> \\[ \\begin{align*} &amp; T(\\log u) = T\\left(\\frac{\\log u}{2}\\right) + O(1) \\\\ &amp; T(u) = T(\\sqrt{u}) + O(1) \\end{align*} \\]"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#improvements","title":"Improvements","text":"<p>We will develop the van Emde Boas data structure by a series of improvements on a very simple data structure.</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#bit-vector","title":"Bit Vector","text":"<p>We maintain a vector <code>V</code> of size <code>u</code> such that <code>V[x] = 1</code> if and only if <code>x</code> is in the set. Now, inserts and deletes can be performed by just flipping the corresponding bit in the vector. However, successor/predecessor requires us to traverse through the vector to find the next 1-bit.</p> <ul> <li>Insert/Delete: <code>O(1)</code></li> <li>Successor/Predecessor: <code>O(u)</code></li> </ul> Text Only<pre><code>| 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 1 |\n</code></pre> <p>Figure 1: Bit vector for <code>u = 16</code>. The current set is <code>{1, 9, 10, 15}</code>.</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#split-universe-into-clusters","title":"Split Universe into Clusters","text":"<p>We can improve performance by splitting up the range <code>{0, 1, 2, ..., u-1}</code> into <code>sqrt(u)</code> clusters of size <code>sqrt(u)</code>. If <code>x = i * sqrt(u) + j</code>, then <code>V[x] = V.cluster[i][j]</code>.</p> \\[ \\begin{align*} &amp; \\text{low}(x) = x \\mod \\sqrt{u} = j \\\\ &amp; \\text{high}(x) = \\left\\lfloor \\frac{x}{\\sqrt{u}} \\right\\rfloor = i \\\\ &amp; \\text{index}(i, j) = i * \\sqrt{u} + j \\end{align*} \\] <p></p> <ul> <li>Insert:</li> <li>Set <code>V.cluster[high(x)][low(x)] = 1</code> <code>O(1)</code></li> <li>Mark cluster <code>high(x)</code> as non-empty <code>O(1)</code></li> <li>Successor:</li> <li>Look within cluster <code>high(x)</code> <code>O(sqrt(u))</code></li> <li>Else, find next non-empty cluster <code>i</code></li> <li>Find minimum entry <code>j</code> in that cluster <code>O(sqrt(u))</code></li> <li>Return <code>index(i, j)</code> Total <code>= O(sqrt(u))</code></li> </ul>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#recurse","title":"Recurse","text":"<p>The three operations in Successor are also Successor calls to vectors of size <code>sqrt(u)</code>. We can use recursion to speed things up.</p> <ul> <li><code>V.cluster[i]</code> is a size <code>-sqrt(u)</code> van Emde Boas structure <code>(\u2200 0 \u2264 i &lt; sqrt(u))</code></li> <li><code>V.summary</code> is a size <code>-sqrt(u)</code> van Emde Boas structure</li> <li><code>V.summary[i]</code> indicates whether <code>V.cluster[i]</code> is nonempty</li> </ul> Text Only<pre><code>INSERT(V, x)\n1 Insert(V.cluster[high(x)], low(x))\n2 Insert(V.summary, high(x))\n</code></pre> <p>So, we get the recurrence:</p> \\[ \\begin{align*} T(u) &amp;= 2 T(\\sqrt{u}) + O(1) \\\\ T'(\\log u) &amp;= 2 T'\\left(\\frac{\\log u}{2}\\right) + O(1) \\\\ \\Longrightarrow T(u) &amp;= T'(\\log u) = O(\\log u) \\end{align*} \\] Text Only<pre><code>SUCCESSOR(V, x)\n1 i = high(x)\n2 j = Successor(V.cluster[i], j)\n3 if j == \u221e\n4   i = Successor(V.summary, i)\n5   j = Successor(V.cluster[i], -\u221e)\n6 return index(i, j)\n</code></pre> \\[ \\begin{align*} T(u) &amp;= 3 T(\\sqrt{u}) + O(1) \\\\ T'(\\log u) &amp;= 3 T'\\left(\\frac{\\log u}{2}\\right) + O(1) \\\\ \\Longrightarrow T(u) &amp;= T'(\\log u) = O((\\log u)^{\\log 3}) \\approx O((\\log u)^{1.585}) \\end{align*} \\] <p>To obtain the <code>O(log log u)</code> running time, we need to reduce the number of recursions to one.</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#maintain-min-and-max","title":"Maintain Min and Max","text":"<p>We store the minimum and maximum entry in each structure. This gives an <code>O(1)</code> time overhead for each Insert operation.</p> Text Only<pre><code>SUCCESSOR(V, x)\n1 i = high(x)\n2 if low(x) &lt; V.cluster[i].max\n3   j = Successor(V.cluster[i], low(x))\n4 else\n5   i = Successor(V.summary, high(x))\n6   j = V.cluster[i].min\n7 return index(i, j)\n</code></pre> <p>$$ \\begin{align} T(u) &amp;= T(\\sqrt{u}) + O(1) \\ \\Longrightarrow T(u) &amp;= O(\\log log u) \\end{align} $$ </p>Text Only<pre><code>## Don't store Min recursively\nThe Successor call now needs to check for the min separately.\n</code></pre> if x &lt; V.min: return V.min (1) Text Only<pre><code>INSERT(V, x)\n1 if V.min == None\n2   V.min = V.max = x (O(1) time)\n3 return\n4 if x &lt; V.min\n5   swap(x \u2194 V.min)\n6 if x &gt; V.max\n7   V.max = x\n8 if V.cluster[high(x)] == None\n9   Insert(V.summary, high(x)) First Call\n10  Insert(V.cluster[high(x)], low(x)) Second Call\n</code></pre> <p>If the first call is executed, the second call only takes <code>O(1)</code> time. So</p> \\[ \\begin{align*} T(u) &amp;= T(\\sqrt{u}) + O(1) \\\\ \\Longrightarrow T(u) &amp;= O(\\log log u) \\end{align*} \\] Text Only<pre><code>DELETE(V, x)\n1 if x == V.min Find new min\n2   i = V.summary.min\n3   if i == None\n4     V.min = V.max = None (O(1) time)\n5     return\n6   V.min = index(i, V.cluster[i].min) Unstore new min\n7 Delete(V.cluster[high(x)], low(x)) First Call\n8 if V.cluster[high(x)].min == None\n9   Delete(V.summary, high(x)) Second Call\n10 Now we update V.max\n11 if x == V.max\n12   if V.summary.max == None\n13   else\n14     i = V.summary.max\n15     V.max = index(i, V.cluster[i].max)\n</code></pre> <p>If the second call is executed, the first call only takes <code>O(1)</code> time. So</p> \\[ \\begin{align*} T(u) &amp;= T(\\sqrt{u}) + O(1) \\\\ \\Longrightarrow T(u) &amp;= O(\\log log u) \\end{align*} \\]"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#lower-bound-patrascu-thorup-2007","title":"Lower Bound [Patrascu &amp; Thorup 2007]","text":"<p>Even for static queries (no Insert/Delete) - <code>\u03a9(log log u)</code> time per query for <code>u = n^(log n)^O(1)</code> - <code>O(n * poly(log n))</code> space</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#space-improvements","title":"Space Improvements","text":"<p>We can improve from <code>\u0398(u)</code> to <code>O(n log log u)</code>. - Only create nonempty clusters - If V.min becomes None, deallocate V - Store V.cluster as a hashtable of nonempty clusters - Each insert may create a new structure <code>\u0398(log log u)</code> times (each empty insert) - Can actually happen [Vladimir \u010cun\u00e1t] - Charge pointer to structure (and associated hash table entry) to the structure This gives us <code>O(n log log u)</code> space (but randomized).</p>"},{"location":"notes/MIT6.046/van%20Emde%20Boas%20Trees/#indirection","title":"Indirection","text":"<p>We can further reduce to <code>O(n)</code> space. - Store vEB structure with <code>n = O(log log u)</code> using BST or even an array <code>\u27f9 O(log log n)</code> time once in base case - We use <code>O(n / log log u)</code> such structures (disjoint)</p> \\[ \\Longrightarrow O\\left(\\frac{n}{\\log \\log u} \\cdot \\log \\log u\\right) = O(n) \\text{ space for small} \\] <ul> <li>Larger structures \"store\" pointers to them</li> </ul> \\[ \\left(\\frac{n}{\\log \\log u} \\cdot \\log \\log u\\right) = O(n) \\text{ space for large} \\]"},{"location":"notes/UCB-CS61c/1-intro/","title":"Intro","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/1-intro/#intro","title":"Intro","text":"<p> \u7ea6 154 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>title: Intro math: false tags:   - CS61C</p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/1-intro/#great-ideas","title":"Great Ideas","text":"<ol> <li>Abstraction: Levels of Representation / Interpretation </li> <li>Moore's Law: Designing through trends</li> <li>Principle of Locality: Memory Hierarchy</li> <li>Parallelism &amp; Amdahl's law</li> <li>Dependability via Redundancy</li> </ol>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/1-intro/#number-representations","title":"Number Representations","text":"<ul> <li>Bit: 0/1</li> <li>Byte: 8 bits</li> <li>Most Significant Bit (MSB)</li> <li>Least Significant Bit (LSB)</li> <li>One's Complement: <code>-x=~x</code><ul> <li>Neg: \\([-(2^{n-1}-1),-0]\\)</li> <li>Pos: \\([0, 2^{n-1}-1]\\)</li> </ul> </li> <li>Two's Complement: <code>-x=~x+1</code><ul> <li>Neg: \\([-2^{n-1},-1]\\)</li> <li>Pos: \\([0, 2^{n-1}-1]\\)</li> </ul> </li> <li>Bias encoding: \u4f8b\u5982\u60f3\u8981\u5229\u7528 4 \u4f4d bits \u4ee3\u8868 \\([-3,12]\\)\uff0c\u53ea\u9700\u53d6 bias \u4e3a \\(-3\\)\uff0c\u5229\u7528 \\([0,15]\\) \u6765\u8868\u793a<ul> <li>\u5bf9 two's complement\uff0cbias \u4e3a \\(N=-2^{n-1}+1\\)\uff0c\u4e0d\u8fc7 \\(-2^{n-1} - N=-1\\)\uff0c\u800c\u4e0d\u662f \\(0\\) </li> <li>\u8fd9\u662f\u56e0\u4e3a\u5728 floating representations \u4e2d\uff0c\u5168\u4e3a \\(1\\) \u7684\u6570\u6709\u7279\u6b8a\u7528\u9014</li> <li>\u4f8b\u5982\uff1a <code>0b1010</code> \u7684 bias \u4e3a \\(-2^{4-1}+1=-7\\), \u8fd9\u4e2a\u6570\u4e3a \\(10-(-7)=3\\)</li> </ul> </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20memory%20management/","title":"4 C memory management","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#c-memory-management-usage-comprehensive-notes","title":"\ud83e\udde0 C Memory Management &amp; Usage - Comprehensive Notes","text":"<p> \u7ea6 411 \u4e2a\u5b57  38 \u884c\u4ee3\u7801  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>C Memory Layout</li> <li>Addressing &amp; Endianness</li> <li>Dynamic Memory Allocation</li> <li>Common Memory Problems</li> <li>Linked List Example</li> <li>Memory Fragmentation &amp; K&amp;R Algorithm</li> <li>Debugging Tools</li> </ol>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#c-memory-layout","title":"\ud83d\uddfa\ufe0f C Memory Layout","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#program-address-space","title":"Program Address Space","text":"<ul> <li>4 Regions:   1. Stack \ud83d\udce5  <ul> <li>Stores local variables (declared inside functions).  </li> <li>Grows downward.  </li> <li>Freed when function returns.  </li> <li>Example: <code>int x = 5;</code> inside <code>main()</code>.</li> </ul> </li> </ul> <ol> <li> <p>Heap \ud83e\uddf1  </p> <ul> <li>Dynamically allocated via <code>malloc()</code>, <code>calloc()</code>, <code>realloc()</code>.  </li> <li>Grows upward.  </li> <li>Must be explicitly freed with <code>free()</code>.  </li> <li>Example: <code>int *arr = malloc(10 * sizeof(int));</code>.</li> </ul> </li> <li> <p>Static Data \ud83c\udf10  </p> <ul> <li>Stores global/static variables and string literals.  </li> <li>Does not grow/shrink.  </li> <li>Example: <code>char *str = \"hello\";</code> (string literal in static data).  </li> <li>\u26a0\ufe0f <code>char str[] = \"hello\";</code> stores the array on the stack!</li> </ul> </li> <li> <p>Code \ud83d\udcdc  </p> <ul> <li>Contains compiled machine code.  </li> <li>Read-only and immutable.</li> </ul> </li> </ol>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#addressing-endianness","title":"\ud83d\udd22 Addressing &amp; Endianness","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#key-concepts","title":"Key Concepts","text":"<ul> <li>Byte-Addressed Machines: Each address points to a unique byte.  </li> <li>Word-Addressed Machines: Each address points to a word (group of bytes).  </li> <li>Endianness: Order of bytes in multi-byte data types.  </li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#types-of-endianness","title":"Types of Endianness","text":"<ol> <li>Big Endian \ud83d\udc18    - Most significant byte at lowest address.    - Example: <code>0x12345678</code> stored as <code>12 34 56 78</code>.  </li> <li>Little Endian \ud83d\udc2d    - Least significant byte at lowest address.    - Example: <code>0x12345678</code> stored as <code>78 56 34 12</code>.  </li> </ol>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#example-integer-28-0x0000001c","title":"Example: Integer <code>28</code> (0x0000001C)","text":"<ul> <li>Big Endian: <code>00 00 00 1C</code> </li> <li>Little Endian: <code>1C 00 00 00</code> </li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#dynamic-memory-allocation","title":"\ud83d\udca5 Dynamic Memory Allocation","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#functions","title":"Functions","text":"<ol> <li><code>malloc(n)</code>    - Allocates <code>n</code> bytes of uninitialized memory.    - Example: C<pre><code>int *arr = (int*)malloc(5 * sizeof(int)); // Allocate space for 5 integers\n</code></pre></li> <li><code>calloc(n, size)</code>    - Allocates <code>n * size</code> bytes initialized to zero.    - Example: C<pre><code>int *arr = (int*)calloc(5, sizeof(int)); // [0, 0, 0, 0, 0]\n</code></pre></li> <li><code>realloc(ptr, new_size)</code>    - Resizes existing memory block.    - May move the block to a new address.    - Example: C<pre><code>arr = realloc(arr, 10 * sizeof(int)); // Expand to 10 integers\n</code></pre></li> <li><code>free(ptr)</code>    - Releases memory.    - \u26a0\ufe0f Never free:  <ul> <li>Stack variables.  </li> <li>Already freed memory.  </li> <li>Middle of a block (e.g., <code>free(arr + 1)</code>).</li> </ul> </li> </ol>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#common-memory-problems","title":"\ud83d\udea8 Common Memory Problems","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#1-using-uninitialized-values","title":"1. Using Uninitialized Values","text":"C<pre><code>int *p;\nprintf(\"%d\", *p); // Undefined behavior! p points to garbage.\n</code></pre>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#2-using-memory-you-dont-own","title":"2. Using Memory You Don\u2019t Own","text":"<ul> <li>Example 1: Returning a stack-allocated array. C<pre><code>char* func() {\n    char arr;\n    return arr; // \u274c arr is on the stack; invalid after function returns.\n}\n</code></pre></li> <li>Example 2: Buffer overflow. C<pre><code>char buf;\nstrcpy(buf, \"This is too long!\"); // Writes beyond buf\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#3-freeing-invalid-memory","title":"3. Freeing Invalid Memory","text":"<ul> <li>Double Free: C<pre><code>int *p = malloc(4);\nfree(p);\nfree(p); // \u274c p already freed.\n</code></pre></li> <li>Freeing Stack Variable: C<pre><code>int x = 5;\nfree(&amp;x); // \u274c x is on the stack.\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#4-memory-leaks","title":"4. Memory Leaks","text":"<ul> <li>Example: Overwriting a pointer before freeing. C<pre><code>int *p = malloc(4);\np = malloc(8); // \u274c Original 4 bytes are now unreachable.\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#linked-list-example","title":"\ud83d\udd17 Linked List Example","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#node-structure","title":"Node Structure","text":"C<pre><code>struct Node {\n    char *value;\n    struct Node *next;\n};\n</code></pre>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#adding-a-node","title":"Adding a Node","text":"C<pre><code>struct Node* addNode(char *s, struct Node *list) {\n    struct Node *newNode = (struct Node*)malloc(sizeof(struct Node));\n    newNode-&gt;value = (char*)malloc(strlen(s) + 1); // +1 for '\\0'\n    strcpy(newNode-&gt;value, s);\n    newNode-&gt;next = list;\n    return newNode;\n}\n</code></pre>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#freeing-a-node","title":"Freeing a Node","text":"C<pre><code>void freeList(struct Node *list) {\n    while (list != NULL) {\n        struct Node *temp = list;\n        list = list-&gt;next;\n        free(temp-&gt;value); // Free the string\n        free(temp);        // Free the node\n    }\n}\n</code></pre>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#visualization","title":"Visualization","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#memory-fragmentation-kr-algorithm","title":"\ud83e\udde9 Memory Fragmentation &amp; K&amp;R Algorithm","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#fragmentation-example","title":"Fragmentation Example","text":""},{"location":"notes/UCB-CS61c/C%20memory%20management/#kr-allocation-strategy","title":"K&amp;R Allocation Strategy","text":"<ul> <li>Free List: Linked list of free memory blocks.  </li> <li>Merging Adjacent Blocks: <code>free()</code> combines adjacent free blocks.  </li> <li>Allocation Policies:  </li> <li>First Fit: Use the first block that fits.  </li> <li>Best Fit: Use the smallest block that fits.  </li> <li>Next Fit: Resume search from last position.</li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#debugging-tools","title":"\ud83d\udee0\ufe0f Debugging Tools","text":"<ul> <li>Valgrind \ud83e\uddea: Detects memory leaks, invalid accesses, and more. Bash<pre><code>valgrind --leak-check=full ./your_program\n</code></pre></li> <li>Example Output: Text Only<pre><code>==12345== Invalid write of size 4\n==12345==    at 0x400ABC: main (example.c:10)\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/C%20memory%20management/#summary","title":"\ud83d\udccc Summary","text":"<ul> <li>Stack: Local variables, LIFO.  </li> <li>Heap: Dynamic, manually managed.  </li> <li>Static Data: Globals &amp; literals.  </li> <li>Code: Immutable.  </li> <li>Common Pitfalls: Leaks, invalid accesses, uninitialized values.  </li> <li>Golden Rule: Always pair <code>malloc()</code> with <code>free()</code>! \ud83d\uded1</li> </ul>"},{"location":"notes/UCB-CS61c/C%20pointers/","title":"C pointers","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#cs61c-lecture-notes-introduction-to-c-pointers","title":"\ud83d\udcda CS61C Lecture Notes: Introduction to C &amp; Pointers","text":"<p> \u7ea6 282 \u4e2a\u5b57  34 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>Instructor: Stephan Kaminsky | Date: Jun 2019  </p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#key-concepts-in-c-programming","title":"\ud83d\udccc Key Concepts in C Programming","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#1-compilation-in-c","title":"1. Compilation in C","text":"<ul> <li>Compiled Language: Converts C code directly to machine-specific instructions (0s and 1s).  </li> <li>\ud83d\ude80 Advantages: Faster execution than Java/Python (no bytecode/JVM).  </li> <li>\u26a0\ufe0f Disadvantages: Platform-dependent executables; slower edit-compile-run cycle.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#2-variable-types-declarations","title":"2. Variable Types &amp; Declarations","text":"<ul> <li>Typed Variables: Must declare type before use.  </li> <li>Example: C<pre><code>int x = 5;          // Integer\nfloat y = 1.618;    // Floating point\nchar z = 'A';       // Character\n</code></pre></li> <li>Type Sizes: Machine-dependent (e.g., <code>int</code> = 4/8 bytes).  </li> <li>Special Keywords: <code>short</code>, <code>long</code>, <code>unsigned</code>.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#3-characters-ascii","title":"3. Characters &amp; ASCII","text":"<ul> <li>ASCII Encoding: Characters stored as numbers (e.g., <code>'a'</code> = 97). C<pre><code>char c = 'a';     // Same as char c = 97;\n</code></pre></li> <li>Size: 1 byte (8 bits).  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#4-type-casting","title":"4. Type Casting","text":"<ul> <li>Weak Typing: Explicitly cast between types.  </li> <li>Example: C<pre><code>int i = -1;\nif ((unsigned int)i &lt; 0) { ... }  // False\n</code></pre></li> <li>\u26a0\ufe0f Caution: Risky casts (e.g., casting structs to integers).  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#5-functions","title":"5. Functions","text":"<ul> <li>Prototypes &amp; Definitions: C<pre><code>int add(int a, int b);   // Prototype\nint add(int a, int b) { return a + b; }  // Definition\n</code></pre></li> <li>Return Types: Must declare return type (<code>void</code> for no return).  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#6-structs-unions","title":"6. Structs &amp; Unions","text":"<ul> <li>Structs: Group related variables. C<pre><code>typedef struct {\n  int length;\n  int year;\n} Song;\nSong s = {213, 1994}; \n</code></pre></li> <li>Unions: Overlapping memory for different types. C<pre><code>union Data {\n  int i;\n  float f;\n};\n</code></pre></li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#example-struct-padding","title":"\ud83e\uddee Example: Struct Padding","text":"C<pre><code>struct foo {\n  int a;     // 4 bytes\n  char b;    // 1 byte (+3 padding)\n  struct foo* c;  // 4 bytes\n};  \n// Total size = 12 bytes (32-bit architecture)\n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#c-vs-java-comparison","title":"\ud83d\udcca C vs Java Comparison","text":"Feature C Java Language Type Function-Oriented Object-Oriented Memory Management Manual (<code>malloc</code>, <code>free</code>) Automatic (Garbage Collection) Hello World <code>printf(\"Hello\\n\");</code> <code>System.out.println(...);</code>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#pointers-address-vs-value","title":"\ud83c\udfaf Pointers: Address vs Value","text":"<ul> <li>Pointer Syntax: C<pre><code>int y = 5;\nint *p = &amp;y;   // p stores address of y\nint z = *p;    // z = value at address p (5)\n</code></pre></li> <li>Pointer Types:  </li> <li><code>int*</code>, <code>char*</code>, <code>void*</code> (generic pointer).  </li> <li>\u26a0\ufe0f Dangling Pointers: Uninitialized pointers \u2192 undefined behavior!  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#example-pointer-parameter-passing","title":"\ud83d\udd0d Example: Pointer Parameter Passing","text":"C<pre><code>void addOne(int *p) { (*p)++; }  \nint main() {\n  int y = 3;\n  addOne(&amp;y);    // y becomes 4\n  return 0;\n}\n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#quiz-4-bit-number-representations","title":"\u2753 Quiz: 4-Bit Number Representations","text":"<p>Given <code>x = 0b1010</code> (4 bits), which value does NOT represent <code>x</code>?  </p> <p>Options: (A) -4 \u2003(B) -6\u2003(C) 10\u2003(D) -2  </p> <p>Analysis: - Unsigned: \\(2^3 + 2^1 = 10\\) \u2714\ufe0f (C) - Sign &amp; Magnitude: \\(-2^1 = -2\\) \u2714\ufe0f (D) - Biased (Bias=7): \\(10 - 7 = 3\\) \u2192 Not an option. - Two\u2019s Complement: \\(-6\\) \u2714\ufe0f (B) - One\u2019s Complement: \\(-5\\) \u2192 Not an option.  </p> <p>Answer: (A) -4 \u274c  </p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#common-pointer-bugs","title":"\ud83d\uded1 Common Pointer Bugs","text":"<ul> <li>Uninitialized Pointers: C<pre><code>int *p;     // p points to garbage!\n*p = 5;     // Crash/undefined behavior\n</code></pre></li> <li>Memory Leaks: Forgetting to <code>free()</code> after <code>malloc()</code>.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20pointers/#key-takeaways","title":"\ud83d\udcd6 Key Takeaways","text":"<ul> <li>C offers low-level control but requires careful memory management.  </li> <li>Pointers = powerful but error-prone. Always initialize!  </li> <li>Structs/unions organize data; padding affects memory layout.  </li> </ul> <p>\ud83d\udd17 Resources: - K&amp;R Book (\"The C Programming Language\") - C99 Standard </p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/","title":"C strings","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#great-ideas-in-computer-architecture-c-arrays-strings-pointers","title":"\ud83d\udda5\ufe0f Great Ideas in Computer Architecture: C Arrays, Strings, &amp; Pointers","text":"<p> \u7ea6 312 \u4e2a\u5b57  45 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p> <p>Instructor: Jenny Song CS61C su20 - Lecture 3 | 6/26/2020 </p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#review-of-last-lecture","title":"\ud83d\udcda Review of Last Lecture","text":"<ul> <li>C Basics </li> <li>Variables, Functions, Control Flow, Syntax.  </li> <li>Only <code>0</code> and <code>NULL</code> evaluate to <code>FALSE</code>.  </li> <li>Pointers </li> <li>Hold memory addresses (address vs. value).  </li> <li>Enable efficient code but are error-prone.  </li> <li>Pass by Value </li> <li>C functions pass arguments by value; pointers circumvent this.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#struct-clarification","title":"\ud83c\udfd7\ufe0f Struct Clarification","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#struct-definition","title":"Struct Definition","text":"C<pre><code>struct foo { /* fields */ };  \nstruct foo name1;         // Declare variable of type struct foo  \nstruct foo* name2;        // Pointer to struct foo  \n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#typedef-with-struct","title":"Typedef with Struct","text":"C<pre><code>// Method 1  \nstruct foo { /* fields */ };  \ntypedef struct foo bar;  \nbar name1;  \n\n// Method 2 (combine definition and typedef)  \ntypedef struct foo { /* fields */ } bar;  \nbar name1;  \n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#great-idea-1-levels-of-representationinterpretation","title":"\ud83c\udf1f Great Idea #1: Levels of Representation/Interpretation","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#agenda","title":"\ud83d\udcdc Agenda","text":"<ol> <li>C Operators  </li> <li>Arrays  </li> <li>Strings  </li> <li>More Pointers (Arithmetic, Misc)  </li> </ol>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#c-operators","title":"\ud83d\udd22 C Operators","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#operator-precedence-table","title":"Operator Precedence Table","text":"Precedence Operator Description Associativity 1 <code>++</code>, <code>--</code> (post) Postfix increment/decrement Left-to-right 1 <code>()</code> Function call 1 <code>[]</code> Array subscripting 2 <code>++</code>, <code>--</code> (pre) Prefix increment/decrement Right-to-left 2 <code>*</code>, <code>&amp;</code> Dereference, Address-of","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#common-pitfalls","title":"Common Pitfalls","text":"<ul> <li>Assignment vs. Equality C<pre><code>a = b;   // Assignment  \na == b;  // Equality test  \n</code></pre></li> <li>Operator Binding </li> <li><code>-x &amp; 1 == 0</code> \u2192 <code>x &amp; (1 == 0)</code> (not <code>(x &amp; 1) == 0</code>).  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#arrays","title":"\ud83d\udce6 Arrays","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#basics","title":"Basics","text":"C<pre><code>int ar;              // Declare 2-element array  \nint ar[] = {795, 635};  // Declare and initialize  \n</code></pre> - Pitfalls: No bounds checking! Accessing <code>ar[n]</code> where <code>n &gt;= 2</code> causes undefined behavior.","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#arrays-vs-pointers","title":"Arrays vs. Pointers","text":"<ul> <li>Similarities: C<pre><code>char* buffer;  // Pointer  \nchar buffer[]; // Array (read-only pointer)  \n</code></pre></li> <li>Differences:  </li> <li><code>sizeof(ar)</code> returns array size; <code>sizeof(ptr)</code> returns pointer size.  </li> <li>Arrays cannot be reassigned (<code>ar = new_array</code> is invalid).  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#example-zeroing-an-array","title":"Example: Zeroing an Array","text":"C<pre><code>// Method 1: Array notation  \nfor (i = 0; i &lt; SIZE; i++) ar[i] = 0;  \n\n// Method 2: Pointer arithmetic  \nfor (i = 0; i &lt; SIZE; i++) *(ar + i) = 0;  \n\n// Method 3: Pointer traversal  \nfor (int* p = ar; p &lt; ar + SIZE; p++) *p = 0;  \n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#strings-in-c","title":"\ud83d\udcdc Strings in C","text":"<ul> <li>Definition: Null-terminated char array. C<pre><code>char s[] = \"abc\";  // Equivalent to {'a', 'b', 'c', '\\0'}  \n</code></pre></li> <li>Common Functions (<code>#include &lt;string.h&gt;</code>):  </li> <li><code>strlen(s)</code>: Returns length (excluding <code>\\0</code>).  </li> <li><code>strcmp(s1, s2)</code>: Returns <code>0</code> if equal.  </li> <li><code>strcpy(dest, src)</code>: Copies <code>src</code> to <code>dest</code>.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#example","title":"Example","text":"C<pre><code>char s1, s2;  \nstrcpy(s1, \"hi\");  \nstrcpy(s2, \"hi\");  \n</code></pre> - <code>strcmp(s1, s2) == 0</code> \u2192 <code>1</code> (true). - <code>s1 == s2</code> \u2192 <code>0</code> (compares addresses, not content).","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#pointers","title":"\ud83c\udfaf Pointers","text":"","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#pointer-arithmetic","title":"Pointer Arithmetic","text":"<ul> <li>Rules:  </li> <li><code>ptr + n</code> adds <code>n * sizeof(*ptr)</code> to the address.  </li> <li>Valid operations: <code>ptr \u00b1 int</code>, subtract pointers, compare pointers.  </li> <li>Example: C<pre><code>int A[] = {5, 10};  \nint* p = A;  \np++;  // Moves to A (address += sizeof(int))  \n</code></pre></li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#pointers-to-pointers","title":"Pointers to Pointers","text":"C<pre><code>void IncrementPtr(int** h) { *h = *h + 1; }  \nint A[] = {50, 60, 70};  \nint* q = A;  \nIncrementPtr(&amp;q);  // q now points to A  \n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#struct-alignment","title":"\ud83e\udde9 Struct Alignment","text":"<ul> <li>Rules:  </li> <li>Members aligned to their size (e.g., <code>int</code> aligned to 4 bytes).  </li> <li>Padding added to meet alignment requirements.  </li> </ul>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#example_1","title":"Example","text":"C<pre><code>struct hello {  \n  int a;     // 4 bytes  \n  char b;    // 1 byte (+3 padding)  \n  short c;   // 2 bytes  \n  char* d;   // 4 bytes  \n  char e;    // 1 byte (+3 padding)  \n};  \n// Total size: 4 + (1+3) + 2 + 4 + (1+3) = 16 bytes  \n</code></pre>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/C%20strings/#common-pitfalls-tips","title":"\ud83d\udea8 Common Pitfalls &amp; Tips","text":"<ol> <li>Uninitialized Pointers: C<pre><code>int* ptr;  // Points to garbage! Always initialize.  \n</code></pre></li> <li>Array Decay: When passed to functions, arrays decay to pointers (losing size info).  </li> <li>Null Terminator: Forgot <code>\\0</code> in strings? <code>strlen</code> may read garbage!  </li> </ol> <p>\u2728 Key Takeaways: - Arrays and pointers are powerful but error-prone. - Always manage memory carefully and use <code>sizeof()</code> for portability. - Understand alignment to optimize struct layouts!  </p>","tags":["CS61C"]},{"location":"notes/UCB-CS61c/RISC-V/","title":"6 RISC-V","text":""},{"location":"notes/UCB-CS61c/RISC-V/#lecture-notes-risc-v-machine-language","title":"Lecture Notes: RISC-V Machine Language","text":"<p> \u7ea6 266 \u4e2a\u5b57  21 \u884c\u4ee3\u7801  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/UCB-CS61c/RISC-V/#registers-in-risc-v","title":"\ud83d\udda5\ufe0f Registers in RISC-V","text":"<ul> <li>32 Registers (<code>x0</code>-<code>x31</code>), each 32-bit wide.</li> <li>Special Registers:</li> <li><code>x0</code> (zero): Always <code>0</code>. </li> <li><code>x1</code> (ra): Return address.</li> <li><code>x2</code> (sp): Stack pointer.</li> <li><code>x8</code> (s0/fp): Saved register/Frame pointer.</li> <li><code>x10</code>-<code>x17</code> (a0-a7): Function arguments/return values.</li> </ul> Register Name Use x0 zero Constant 0 x1 ra Return address x2 sp Stack pointer x8 s0/fp Saved register/Frame pointer x10-x11 a0-a1 Function args/Return values"},{"location":"notes/UCB-CS61c/RISC-V/#basic-risc-v-instructions","title":"\ud83d\udd27 Basic RISC-V Instructions","text":""},{"location":"notes/UCB-CS61c/RISC-V/#1-arithmetic-instructions","title":"1\ufe0f\u20e3 Arithmetic Instructions","text":"<ul> <li>Syntax: <code>op dst, src1, src2</code></li> <li>Examples: GAS<pre><code>add s1, s2, s3   # s1 = s2 + s3\nsub s0, t2, t1   # s0 = t2 - t1\naddi s1, s2, 5   # s1 = s2 + 5 (immediate)\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/RISC-V/#2-data-transfer-instructions","title":"2\ufe0f\u20e3 Data Transfer Instructions","text":"<ul> <li>Load/Store Syntax: <code>memop reg, offset(base)</code></li> <li>Examples: GAS<pre><code>lw t0, 12(s3)    # t0 = Memory[s3 + 12]\nsw t0, 40(s3)    # Memory[s3 + 40] = t0\nlb s1, 1(s0)     # Load byte (sign-extended)\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/RISC-V/#3-control-flow-instructions","title":"3\ufe0f\u20e3 Control Flow Instructions","text":"<ul> <li>Branch/Jump Syntax: <code>beq/bne/blt/bge/j label</code></li> <li>Example (If-Else): GAS<pre><code># C: if (i == j) a = b; else a = -b;\nbeq s0, s1, then   # Branch if i == j\nj else\nthen:\n  add s2, s3, x0   # a = b\n  j end\nelse:\n  sub s2, x0, s3   # a = -b\nend:\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/RISC-V/#example-translating-c-to-risc-v","title":"\ud83e\uddee Example: Translating C to RISC-V","text":""},{"location":"notes/UCB-CS61c/RISC-V/#c-code","title":"C Code:","text":"C<pre><code>a = (b + c) - (d + e);\n</code></pre>"},{"location":"notes/UCB-CS61c/RISC-V/#risc-v-assembly","title":"RISC-V Assembly:","text":"GAS<pre><code>add t1, s3, s4   # t1 = d + e\nadd t2, s1, s2   # t2 = b + c\nsub s0, t2, t1   # a = (b+c) - (d+e)\n</code></pre> - Registers Used:   - <code>a \u2192 s0</code>, <code>b \u2192 s1</code>, <code>c \u2192 s2</code>, <code>d \u2192 s3</code>, <code>e \u2192 s4</code>."},{"location":"notes/UCB-CS61c/RISC-V/#shifting-instructions","title":"\ud83d\udd04 Shifting Instructions","text":"<ul> <li>Examples: GAS<pre><code>slli s0, s1, 3   # s0 = s1 &lt;&lt; 3 (logical left shift)\nsrai s2, t0, 8   # s2 = t0 &gt;&gt; 8 (arithmetic right shift)\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/RISC-V/#risc-v-green-card-key-instructions","title":"\ud83d\udcca RISC-V Green Card (Key Instructions)","text":"Mnemonic Description Example <code>add</code> Add registers <code>add s1, s2, s3</code> <code>addi</code> Add immediate <code>addi s1, s2, 5</code> <code>lw</code> Load word from memory <code>lw t0, 12(s3)</code> <code>sw</code> Store word to memory <code>sw t0, 40(s3)</code> <code>beq</code> Branch if equal <code>beq s0, s1, L1</code> <code>jal</code> Jump and link <code>jal ra, proc</code>"},{"location":"notes/UCB-CS61c/RISC-V/#key-concepts","title":"\ud83e\udde9 Key Concepts","text":"<ol> <li> <p>RISC vs. CISC:    - RISC focuses on simple instructions executed quickly (e.g., ARM, RISC-V).    - CISC uses complex instructions (e.g., x86).  </p> </li> <li> <p>Memory Hierarchy:    - Registers (fastest) \u2192 Cache \u2192 RAM \u2192 Disk (slowest).  </p> </li> <li> <p>Endianness:    - RISC-V uses little-endian (LSB at lowest address).  </p> </li> </ol>"},{"location":"notes/UCB-CS61c/RISC-V/#summary","title":"\ud83d\udcdd Summary","text":"<ul> <li>Registers: Fast, limited storage for variables.  </li> <li>Immediates: Constants embedded in instructions (e.g., <code>addi</code>).  </li> <li>Control Flow: Branches (<code>beq</code>, <code>bne</code>) and jumps (<code>j</code>, <code>jal</code>).  </li> <li>Data Transfer: Load/store instructions for memory access.  </li> </ul> <p>\ud83d\ude80 RISC-V is dominant in embedded systems, academia, and modern computing!</p> <p>\ud83d\udcf8 PPT Screenshots (Hypothetical Links): </p> <p>Note: Replace image links with actual screenshots of full PPT slides.</p>"},{"location":"notes/UCB-CS61c/float%20point/","title":"5 float points","text":""},{"location":"notes/UCB-CS61c/float%20point/#instructor-jenny-song","title":"Instructor: Jenny Song \ud83d\udc69\ud83c\udfeb","text":"<p> \u7ea6 297 \u4e2a\u5b57  9 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>"},{"location":"notes/UCB-CS61c/float%20point/#table-of-contents","title":"Table of Contents \ud83d\udcda","text":"<ol> <li>Review of C Memory Layout</li> <li>Floating Point Representation</li> <li>IEEE 754 Standard</li> <li>Special Cases &amp; Limitations</li> <li>Examples &amp; Practice</li> </ol>"},{"location":"notes/UCB-CS61c/float%20point/#review-c-memory-layout","title":"Review: C Memory Layout \ud83e\udde0","text":"C<pre><code>+------------------+\n|       Stack      | \ud83d\udc49 Local variables (LIFO)\n+------------------+\n|    Static Data   | \ud83d\udc49 Global variables &amp; string literals\n+------------------+\n|       Code       | \ud83d\udc49 Machine code copy\n+------------------+\n|       Heap       | \ud83d\udc49 Dynamic storage (malloc/free)\n+------------------+\n</code></pre> <ul> <li>Memory Bugs often arise from stack/heap collisions (OS prevents via virtual memory).</li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#floating-point-representation","title":"Floating Point Representation \ud83c\udf0c","text":""},{"location":"notes/UCB-CS61c/float%20point/#key-ideas","title":"Key Ideas:","text":"<ul> <li>Scientific Notation: Normalized form ensures one non-zero digit left of the decimal point.</li> <li>Example: <code>1.0 \u00d7 10\u207b\u2079</code> (normalized) vs. <code>0.1 \u00d7 10\u207b\u2078</code> (not normalized).</li> <li>Binary Scientific Notation: Text Only<pre><code>1.0101_{two} \\times 2^4 = 10110_{two} = 22_{ten}\n</code></pre></li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#6-bit-fixed-binary-point-example","title":"6-Bit Fixed Binary Point Example:","text":"<ul> <li>Representation: <code>XX.XXXX</code> (e.g., <code>10.1010_{two} = 2.625_{ten}</code>).</li> <li>Range: <code>0</code> to <code>3.9375</code> (smallest difference = <code>2\u207b\u2074 = 1/16</code>).</li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#ieee-754-floating-point-standard","title":"IEEE 754 Floating Point Standard \ud83c\udfdb\ufe0f","text":""},{"location":"notes/UCB-CS61c/float%20point/#single-precision-32-bits","title":"Single Precision (32 bits):","text":"Text Only<pre><code>(-1)^S \\times (1.\\text{Significand}) \\times 2^{\\text{(Exponent - 127)}}\n</code></pre> Bit 31 Bits 30-23 (Exponent) Bits 22-0 (Significand) S (1) 8 bits (Biased) 23 bits (Fraction) <ul> <li>Exponent Bias: <code>127</code> (actual exponent = <code>Exponent field - 127</code>).</li> <li>Implicit Leading 1: Significand assumes <code>1.xxx...</code>, e.g., <code>1.1010...</code>.</li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#double-precision-64-bits","title":"Double Precision (64 bits):","text":"<ul> <li>Larger significand (52 bits) and exponent bias <code>1023</code>.</li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#special-cases-limitations","title":"Special Cases &amp; Limitations \u26a0\ufe0f","text":""},{"location":"notes/UCB-CS61c/float%20point/#encodings-summary","title":"Encodings Summary:","text":"Exponent Significand Meaning Example (Hex) 0 0 \u00b10 <code>0x00000000</code> (\uff0b0) 0 \u22600 Denormalized Gradual underflow 1-254 Any Normalized Float <code>0x40400000</code> = <code>3.0</code> 255 0 \u00b1\u221e <code>0x7F800000</code> (\uff0b\u221e) 255 \u22600 NaN Result of <code>0/0</code> or <code>\u221a(-1)</code>"},{"location":"notes/UCB-CS61c/float%20point/#key-notes","title":"Key Notes:","text":"<ul> <li>Two Zeros: <code>+0</code> and <code>-0</code> (same value, different sign bits).</li> <li>Infinity: Result of overflow (e.g., division by zero).</li> <li>NaN: \"Not a Number\" for undefined operations.</li> </ul>"},{"location":"notes/UCB-CS61c/float%20point/#examples-practice","title":"Examples &amp; Practice \ud83d\udca1","text":""},{"location":"notes/UCB-CS61c/float%20point/#example-1-convert-to-single-precision","title":"Example 1: Convert to Single-Precision","text":"<p>Value: <code>-3.75</code> 1. Sign: <code>S = 1</code> (negative). 2. Binary Fraction: <code>3.75 = 11.11_{two} = 1.111_{two} \u00d7 2^1</code>. 3. Exponent: <code>1 + 127 = 128</code> \u2192 <code>10000000_{two}</code>. 4. Significand: <code>111000...0</code> (23 bits).</p> <p>Encoding: </p>Text Only<pre><code>1 10000000 11100000000000000000000\n</code></pre>"},{"location":"notes/UCB-CS61c/float%20point/#example-2-decode-single-precision","title":"Example 2: Decode Single-Precision","text":"<p>Hex: <code>0xC0A00000</code> 1. Binary: <code>1 10000001 01000000000000000000000</code>. 2. Sign: Negative (<code>S=1</code>). 3. Exponent: <code>129 - 127 = 2</code>. 4. Significand: <code>1.010000... = 1.25_{ten}</code>. 5. Value: <code>-1.25 \u00d7 2^2 = -5.0</code>.</p>"},{"location":"notes/UCB-CS61c/float%20point/#practice-problems","title":"Practice Problems \ud83d\udcdd","text":"<ol> <li> <p>Convert <code>12.375</code> to IEEE 754 single-precision.    - Answer: <code>0x41460000</code>.</p> </li> <li> <p>Decode <code>0x3F800000</code>.    - Answer: <code>1.0</code> (S=0, Exponent=127, Significand=1.0).</p> </li> </ol>"},{"location":"notes/UCB-CS61c/float%20point/#key-takeaways","title":"Key Takeaways \ud83d\ude80","text":"<ul> <li>Floating point trades precision for range.</li> <li>IEEE 754 ensures consistency across systems.</li> <li>Special values (<code>\u00b10</code>, <code>\u00b1\u221e</code>, <code>NaN</code>) handle edge cases gracefully.</li> </ul>"},{"location":"summary/","title":"index","text":""},{"location":"summary/#summaries","title":"Summaries \ud83d\uddd3\ufe0f","text":"\u300e \u0915\u093f\u0928\u094d\u0928\u0930\u093f\u092f \u092e\u092e \u0924\u0923\u094d\u0939\u093e \u300f"},{"location":"summary/2025/summary-1/","title":"2025 \u5468\u7ed3 1","text":"<p> \u7ea6 0 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f  \u5171\u88ab\u8bfb\u8fc7  \u6b21</p>","tags":["summary"]},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tags","title":"Tags","text":"<p>{{ tag_content }}</p>"}]}